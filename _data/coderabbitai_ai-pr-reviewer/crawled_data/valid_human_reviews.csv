PR_URL,Comment_URL,Comment_Author,Original_Commit_id,Commit_id,Diff_hunk,Diff_path,Created_At,Updated_At,Body,Start_Line,Original_Start_Line,Start_Side,Line,Original_Line,Side,Original_Position,Position,Subject_Type,Affiliated_PR_URL,Repository,Merge_Commit_SHA
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/321,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1476796216,JaerongA,6745de069ef16939630ce0229a847a5f53842d54,85b4c978d32feab003d4b8380a2c9b5c48cd1dcc,"@@ -71,7 +74,8 @@ def ingest_environment_visits():
     worker_schema_name=worker_schema_name,
     db_prefix=db_prefix,
     run_duration=-1,
-    sleep_duration=10,
+    max_idled_cycle=500,",aeon/dj_pipeline/populate/worker.py,2024-02-02 22:14:54+00:00,2024-02-02T22:23:17Z,why not just make this default to -1?,,,,,77,RIGHT,36,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/321,SainsburyWellcomeCentre/aeon_mecha,804c77fe29ecbd7a11b467f1fe890fdc31fc9758
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/321,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1476803084,JaerongA,6745de069ef16939630ce0229a847a5f53842d54,85b4c978d32feab003d4b8380a2c9b5c48cd1dcc,"@@ -101,7 +106,9 @@ def ingest_environment_visits():
     worker_schema_name=worker_schema_name,
     db_prefix=db_prefix,
     run_duration=-1,
-    sleep_duration=3600,
+    max_idled_cycle=WORKER_MAX_IDLED_CYCLE,
+    sleep_duration=60,
 )
 
-analysis_worker(block_analysis.BlockAnalysis)
+analysis_worker(block_analysis.BlockAnalysis, max_calls=4)
+analysis_worker(block_analysis.BlockPlots, max_calls=4)",aeon/dj_pipeline/populate/worker.py,2024-02-02 22:23:07+00:00,2024-02-02T22:23:17Z,no BlockDetection?,,,,,114,RIGHT,62,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/321,SainsburyWellcomeCentre/aeon_mecha,804c77fe29ecbd7a11b467f1fe890fdc31fc9758
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/376,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1664288098,jkbhagatio,5f64e9043bfc0bc09752157e362a426bbca0b70c,4196b1c8f1ca8935b0f1ef01d1fc853e84b9ec96,"@@ -75,8 +75,8 @@ Repository = ""https://github.com/sainsburyWellcomeCentre/aeon_mecha""
 Documentation = ""https://sainsburywellcomecentre.github.io/aeon_docs/""
 DataJoint = ""https://docs.datajoint.org/""
 
-[tool.setuptools]
-packages = [""aeon""]
+[tool.setuptools.packages.find]",pyproject.toml,2024-07-03 14:27:24+00:00,2024-07-03T14:27:24Z,"Apparently this pattern can also be used. Not sure if one is preferred, / if the * wildcard is necessary?

```
[tool.setuptools.packages.find]
where = [""aeon""]
```

",,,,78.0,78,RIGHT,6,6.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/376,SainsburyWellcomeCentre/aeon_mecha,abdbb918a3afb802b49bcb5a1d8e1dbb5e482387
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/397,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1756902017,glopesdev,aa03752a0c063d0a04cef6d9592c1dfe99ee4d7e,9880eb681aa041f42629ff3bf717125894a07714,"@@ -6,3 +8,19 @@ class Pose(Stream):
 
     def __init__(self, path):
         super().__init__(_reader.Pose(f""{path}_202_*""))
+
+
+class EnvActiveConfigReader(_reader.JsonList):",aeon/schema/social_03.py,2024-09-12 13:42:33+00:00,2024-09-12T13:45:15Z,"Pulling out specific attributes from the JSON into columns might be a common enough operation that we could provide it at the level of the general reader, i.e. provide a `columns` property to specify which values to pull out from each record.",,,,,13,RIGHT,12,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/397,SainsburyWellcomeCentre/aeon_mecha,9fedabc731d2efbfd76db9b4e51c4562c0bc7e6f
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/397,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1756904873,glopesdev,aa03752a0c063d0a04cef6d9592c1dfe99ee4d7e,9880eb681aa041f42629ff3bf717125894a07714,"@@ -6,3 +8,19 @@ class Pose(Stream):
 
     def __init__(self, path):
         super().__init__(_reader.Pose(f""{path}_202_*""))
+
+
+class EnvActiveConfigReader(_reader.JsonList):",aeon/schema/social_03.py,2024-09-12 13:44:02+00:00,2024-09-12T13:45:15Z,"```suggestion
class ActiveConfigurationReader(_reader.JsonList):
```

The names of the reader and stream don't line up, since one is `EnvActiveConfig` and the other is `ActiveConfiguration`. Why not just rename the reader as `ActiveConfigurationReader`? I think the `Env` prefix might be unnecessary in this context.",,,,,13,RIGHT,12,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/397,SainsburyWellcomeCentre/aeon_mecha,9fedabc731d2efbfd76db9b4e51c4562c0bc7e6f
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/397,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1756906917,glopesdev,aa03752a0c063d0a04cef6d9592c1dfe99ee4d7e,9880eb681aa041f42629ff3bf717125894a07714,"@@ -563,6 +563,47 @@ def make(self, key):
             )
 
 
+@schema
+class EnvironmentActiveConfig(dj.Imported):",aeon/dj_pipeline/acquisition.py,2024-09-12 13:45:11+00:00,2024-09-12T13:45:15Z,Would be nice if we can agree on whether to use `Config` or `Configuration` as a common suffix for all classes dealing with these files. I think I am fine either way.,,,,,567,RIGHT,5,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/397,SainsburyWellcomeCentre/aeon_mecha,9fedabc731d2efbfd76db9b4e51c4562c0bc7e6f
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/397,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1756965535,jkbhagatio,aa03752a0c063d0a04cef6d9592c1dfe99ee4d7e,9880eb681aa041f42629ff3bf717125894a07714,"@@ -6,3 +8,19 @@ class Pose(Stream):
 
     def __init__(self, path):
         super().__init__(_reader.Pose(f""{path}_202_*""))
+
+
+class EnvActiveConfigReader(_reader.JsonList):
+    def __init__(self, pattern):
+        super().__init__(pattern)
+
+    def read(self, file):
+        data = super().read(file)
+        data[""name""] = data[""value""].apply(lambda x: x[""name""])
+        return data
+
+
+class ActiveConfiguration(Stream):",aeon/schema/social_03.py,2024-09-12 14:17:08+00:00,2024-09-12T14:17:08Z,would actually add `Env` here too,,,,,23,RIGHT,22,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/397,SainsburyWellcomeCentre/aeon_mecha,9fedabc731d2efbfd76db9b4e51c4562c0bc7e6f
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/397,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1757543203,glopesdev,a1f46009b2f176d422b6713c5a2f49268d94818a,9880eb681aa041f42629ff3bf717125894a07714,"@@ -6,3 +8,9 @@ class Pose(Stream):
 
     def __init__(self, path):
         super().__init__(_reader.Pose(f""{path}_202_*""))
+
+
+class EnvActiveConfiguration(Stream):",aeon/schema/social_03.py,2024-09-12 20:30:44+00:00,2024-09-12T20:30:56Z,"All looks great, I would just rename this stream to be called `EnvironmentActiveConfiguration` rather than the shorthand version, but not critical either way.",,,,,13,RIGHT,12,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/397,SainsburyWellcomeCentre/aeon_mecha,9fedabc731d2efbfd76db9b4e51c4562c0bc7e6f
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1296956552,lochhh,c86d7b09f7074a615cb9737d94857461ffefd9e1,c6bafb47cc357d81bb6d4169cfdaaacabb1125c7,"@@ -1,7 +1,7 @@
 default_language_version:
-  python: python3.9
+  python: python3.11
 
-default_stages: [commit, push]
+#default_stages: [commit, push]",.pre-commit-config.yaml,2023-08-17 09:44:26+00:00,2023-08-17T09:44:27Z,"Since we're doing a clean-up, do we also want to update the repo revs? add a few more pre-commit hooks (e.g., check-docstring-first, check-merge-conflict, check-toml, mixed-line-ending, trailing-whitespace)",,,,,4,RIGHT,6,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,SainsburyWellcomeCentre/aeon_mecha,f1ab685e3701d9a830524ec16350cbd6f56cca32
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1296989343,lochhh,c86d7b09f7074a615cb9737d94857461ffefd9e1,c6bafb47cc357d81bb6d4169cfdaaacabb1125c7,"@@ -0,0 +1,56 @@
+# Builds the aeon environment, flakes via flake8, checks type annotations via mypy, tests via pytest, 
+# reports test coverage via pytest-cov and codecov, and reports security vulnerabilities via bandit.
+
+name: build_env_run_tests
+on:
+  push:
+    branches: [ main, reorg, jai_dev, config ]
+  pull_request:
+    branches: [ main ]
+  workflow_dispatch:  # Allows running manually from Github's 'Actions' tab
+jobs:
+  build_env_run_tests:
+    name: Build env and run tests on ${{ matrix.os }}
+    runs-on: ${{ matrix.os }}
+    strategy:
+      matrix:",.github/workflows/build_env_run_tests.yml,2023-08-17 09:55:55+00:00,2023-08-17T09:55:55Z,different python versions? ,,,,42.0,42,RIGHT,16,42.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,SainsburyWellcomeCentre/aeon_mecha,f1ab685e3701d9a830524ec16350cbd6f56cca32
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1310024090,glopesdev,7937d07eac10f40c7bcdadde3c92043fc7088be8,c6bafb47cc357d81bb6d4169cfdaaacabb1125c7,"@@ -0,0 +1,89 @@
+# Builds the aeon environment; lints formatting and smells via ruff; checks type annotations via pyright;
+# tests via pytest; reports test coverage via pytest-cov and codecov.
+
+name: build_env_run_tests
+on:
+  pull_request:
+    branches: [ main ]
+    types: [opened, reopened, synchronize]
+  workflow_dispatch:  # allows running manually from Github's 'Actions' tab
+jobs:
+  build_env_pip_pyproject:  # checks only for building env using pip and pyproject.toml
+    name: Build env using pip and pyproject.toml
+    runs-on: ubuntu-latest
+    strategy:
+      matrix:
+        os: [ubuntu-latest, windows-latest, macos-latest]
+        python-version: [3.11]
+        #include:  # test other python versions only on ubuntu
+          #- os: ubuntu-latest
+          #  python-version: [3.9, 3.10]
+      fail-fast: false
+    defaults:
+      run:
+        shell: bash -l {0}  # reset shell for each step
+    steps:
+      - name: Checkout code
+        uses: actions/checkout@v2
+      - name: Set up Python
+        uses: actions/setup-python@v2
+        with:
+          python-version: ${{ matrix.python-version }}
+      - name: Create venv and install dependencies
+        run: |
+          python -m venv .venv
+          source .venv/bin/activate
+          pip install -e .[dev]
+          pip list
+          .venv/bin/python -c ""import aeon""
+  
+  build_env_run_tests:  # checks for building env using mamba and runs codebase checks and tests
+    name: Build env and run tests on ${{ matrix.os }}
+    runs-on: ${{ matrix.os }}
+    strategy:
+      matrix:
+        os: [ubuntu-latest, windows-latest, macos-latest]
+        python-version: [3.11]
+      fail-fast: false
+    defaults:
+      run:
+        shell: bash -l {0}  # reset shell for each step
+    steps:
+      - name: checkout repo
+        uses: actions/checkout@v2
+      - name: set up conda env
+        uses: conda-incubator/setup-miniconda@v2
+        with:
+          use-mamba: true
+          miniforge-variant: Mambaforge
+          python-version: ${{ matrix.python-version }}
+          environment-file: ./env_config/env.yml
+          activate-environment: aeon
+      - name: Update conda env with dev reqs
+        run: mamba env update -f ./env_config/env_dev.yml
+
+      # Only run codebase checks and tests for ubuntu.
+      - name: ruff
+        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'",.github/workflows/build_env_run_tests.yml,2023-08-30 10:03:48+00:00,2023-08-30T10:42:00Z,"Could we replace all instances of string `3.11` below with an environment variable to make it easier to change the python version for all the steps in the future?

It should be possible to do this using workflow environment variables: https://docs.github.com/en/actions/learn-github-actions/variables#defining-environment-variables-for-a-single-workflow",,,,,67,RIGHT,67,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,SainsburyWellcomeCentre/aeon_mecha,f1ab685e3701d9a830524ec16350cbd6f56cca32
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1310038617,glopesdev,7937d07eac10f40c7bcdadde3c92043fc7088be8,c6bafb47cc357d81bb6d4169cfdaaacabb1125c7,"@@ -9,16 +9,17 @@
 	- Ensure you add anaconda as a path environment variable (even if it says this option is not recommended)
 	- Ensure you do *not* register anaconda as the default version of Python.
 	- _Note_: These installation settings can always be changed posthoc.
-
-2) Create conda environment and install the code dependencies from the `env.yml` file:
+2. Create conda environment and install the code dependencies from the `env.yml` file:
 ```
 conda update conda
 conda init
-conda env create --file env.yml
+conda env create --file env_config/env.yml
 ```
-
-3) Using the virtual environment:
-
-`conda activate aeon`: activates the virtual environment; any commands now run within this terminal will take place within the virtual environment.
-
-`conda deactivate aeon`: deactivates the virtual environment.
+3. Optionally install development dependencies:
+```
+conda activate aeon
+conda env update --file env_config/env_dev.yml
+```
+4. Using the virtual environment:
+	- `conda activate aeon`: activates the virtual environment; any commands now run within this terminal will take place within the virtual environment.",docs/env_setup/local/miniconda_conda_local_setup.md,2023-08-30 10:16:18+00:00,2023-08-30T10:42:00Z,Large indentation?,,,,24.0,24,RIGHT,33,33.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,SainsburyWellcomeCentre/aeon_mecha,f1ab685e3701d9a830524ec16350cbd6f56cca32
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1310056003,glopesdev,7937d07eac10f40c7bcdadde3c92043fc7088be8,c6bafb47cc357d81bb6d4169cfdaaacabb1125c7,"@@ -1 +1,6 @@
-#
\ No newline at end of file
+# Miscellaneous points developers should know and follow
+
+- Ensure dev dependencies are installed in your Aeon Python environment
+- Ensure pre-commit hooks are installed in your Aeon Python environment: run `pre-commit install` in the activated environment
+- Use [pyan3](https://github.com/Technologicat/pyan) for generating callgraphs",docs/devs/readme.md,2023-08-30 10:31:33+00:00,2023-08-30T10:42:00Z,"Can we elaborate here on what we are supposed to do with the output of `pyan3`? I can see how call graphs might be useful when reading the code base in some cases, but do we need to generate them when developing? Or is it more of a general tooling recommendation?",,,,,5,RIGHT,7,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,SainsburyWellcomeCentre/aeon_mecha,f1ab685e3701d9a830524ec16350cbd6f56cca32
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1311261540,glopesdev,8b661bd56fae560f4420350417e785f5712be191,c6bafb47cc357d81bb6d4169cfdaaacabb1125c7,"@@ -5,8 +5,11 @@ build-backend = ""setuptools.build_meta""
 [project]
 name = ""aeon_mecha""
 version = ""0.1.0""
-requires-python = "">=3.9.4""
-description = ""Code for managing acquired data from Project Aeon experiments. Includes general file IO, data QC, querying, and analysis modules.""
+requires-python = "">=3.11""
+description = '''
+    Code for managing acquired data from Project Aeon experiments. Includes general file IO,
+    data QC, querying, and analysis modules.
+'''
 authors = [
   { name = ""Jai Bhagat"", email = ""jkbhagatio@gmail.com"" },
   { name = ""Goncalo Lopes"", email = ""goncaloclopes@gmail.com"" },",pyproject.toml,2023-08-31 08:12:45+00:00,2023-08-31T08:15:30Z,Can you change my email here to g.lopes AT neurogears.org?,,,,,15,RIGHT,13,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/228,SainsburyWellcomeCentre/aeon_mecha,f1ab685e3701d9a830524ec16350cbd6f56cca32
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/339,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1519962330,ttngu207,edff5012b2332cb67c63fa25ecc7368bd34b1f58,bdd6e05fdf8b6a22daacbf994db8fc9828e85306,"@@ -541,6 +541,50 @@ SciViz:
                     aeon_report = aeon_archived_exp02_report
                     return dict(query=aeon_report.VisitDailySummaryPlot(), fetch_args=['region_time_fraction_hourly_plotly'])
 
+    SocialExperiment:
+      route: /social_experiment
+      grids:
+        grid1:
+          type: fixed
+          columns: 1
+          row_height: 700
+          components:
+            SocialExperiment:
+              route: /social_experiment_grid
+              link: /per_social_experiment
+              x: 0
+              y: 0
+              height: 1
+              width: 1
+              type: antd-table
+              restriction: >
+                def restriction(**kwargs):
+                    return dict(**kwargs)
+              dj_query: >
+                def dj_query(aeon_acquisition, aeon_block_analysis, aeon_tracking):
+
+                    import pandas as pd
+                    acquisition = aeon_acquisition
+                    block_analysis = aeon_block_analysis
+                    tracking = aeon_tracking
+
+                    query = acquisition.Experiment.aggr(block_analysis.Block, block_count=""COUNT(experiment_name)"") + acquisition.Experiment.aggr(acquisition.Chunk, chunk_count=""COUNT(experiment_name)"", latest_chunk_start=""MAX(chunk_start)"")
+
+                    df = tracking.SLEAPTracking.PoseIdentity.proj(""identity_name"").fetch(format=""frame"")
+                    df = df.groupby('experiment_name')['identity_name'].unique().reset_index()
+
+                    subject_query = None
+
+                    for exp in query.fetch(""experiment_name""):
+                        # get identity names for each experiment
+                        identities = df[df['experiment_name'] == exp]['identity_name'].values[0]
+                        if not subject_query:
+                            subject_query = dj.U(""experiment_name"", ""subject"") & (query & f""experiment_name = '{exp}'"").proj(subject=f""CONCAT('{', '.join(identities)}')"")
+                        else:
+                            subject_query += dj.U(""experiment_name"", ""subject"") & (query & f""experiment_name = '{exp}'"").proj(subject=f""CONCAT('{', '.join(identities)}')"")",aeon/dj_pipeline/webapps/sciviz/specsheet.yaml,2024-03-11 15:54:17+00:00,2024-03-11T15:54:17Z,"I think you can use `.aggr()` with ""GROUP_CONCAT()` to achieve the same thing here, simplify this a bit further ",,573.0,RIGHT,,584,RIGHT,44,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/339,SainsburyWellcomeCentre/aeon_mecha,cefffb50fe9bb73c279a4e58a2eae4314763a029
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/406,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1767284005,glopesdev,ddd59037fe8586917b4f9625e5f6df62369148e7,ddd59037fe8586917b4f9625e5f6df62369148e7,"@@ -47,22 +47,44 @@ jobs:
       fail-fast: false
     defaults:
       run:
-        shell: bash -l {0}  # reset shell for each step
+        shell: ${{ matrix.os == 'windows-latest' && 'cmd' || 'bash' }} -l {0}
     steps:
-      - name: checkout repo
+      - name: Checkout repo
         uses: actions/checkout@v2
-      - name: set up conda env
+
+      - name: Set up conda env (Linux, Windows)
+        if: ${{ matrix.os != 'macos-latest' }}
         uses: conda-incubator/setup-miniconda@v2
         with:
           use-mamba: true
           miniforge-variant: Mambaforge
           python-version: ${{ matrix.python-version }}
           environment-file: ./env_config/env.yml
           activate-environment: aeon
+
+      - name: Set up conda env (macOS)
+        if: ${{ matrix.os == 'macos-latest' }}
+        uses: conda-incubator/setup-miniconda@v2
+        with:
+          use-mamba: true
+          miniforge-variant: Mambaforge
+          python-version: ${{ matrix.python-version }}
+          environment-file: ./env_config/env_macos.yml
+          activate-environment: aeon
+          architecture: arm64
+          miniconda-version: ""latest""
+
+      - name: Install datajoint wheel build with pip flag (macOS)
+        if: ${{ matrix.os == 'macos-latest' }}
+        run: |
+          source $CONDA/bin/activate aeon
+          pip install --use-pep517 datajoint git+https://github.com/datajoint-company/datajoint-utilities.git",.github/workflows/build_env_run_tests.yml,2024-09-19 17:11:20+00:00,2024-09-19T17:11:38Z,I guess this partly answers my earlier comment. Would it work if we just use `--use-pep517` to setup the environment for all OSes?,72.0,72.0,RIGHT,81.0,81,RIGHT,84,84.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/406,SainsburyWellcomeCentre/aeon_mecha,81bbfa19e54beddb53ffb6740ef2da1797ed9919
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/271,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1379092988,JaerongA,0ffaa1fd1cd5b3975f0582c9b1659c066e747e6b,6b16fe7e3d03276ffd4002ac2ba9b7c56a342c96,"@@ -64,27 +66,45 @@ def make(self, key):
             ""eartag"": eartag_or_id,
         }
         animal_resp = get_pyrat_data(endpoint=f""animals"", params=params)
-        assert len(animal_resp) == 1, f""Found {len(animal_resp)} with eartag {eartag_or_id}, expect one""
-        animal_resp = animal_resp[0]
+        if not animal_resp:",aeon/dj_pipeline/subject.py,2023-11-01 17:20:55+00:00,2023-11-01T17:21:33Z,"```suggestion
        if len(animal_resp) == 0:
```

I think this more explicitly filters ""no animal"" conditions since response may return an error dictionary.",,,,,69,RIGHT,28,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/271,SainsburyWellcomeCentre/aeon_mecha,6a52fe200702bdb375f403cbe7689414f079197e
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/271,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1379093094,JaerongA,0ffaa1fd1cd5b3975f0582c9b1659c066e747e6b,6b16fe7e3d03276ffd4002ac2ba9b7c56a342c96,"@@ -142,6 +162,14 @@ class SubjectComment(dj.Imported):
     """"""
 
 
+@schema
+class ExperimentSubject(dj.Manual):
+    definition = """"""
+    -> Subject
+    experiment_name: varchar(32)  # e.g. social-AEON3",aeon/dj_pipeline/subject.py,2023-11-01 17:21:00+00:00,2023-11-01T17:21:33Z,would having this in a separate table make it less error-prone?,,,,,169,RIGHT,82,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/271,SainsburyWellcomeCentre/aeon_mecha,6a52fe200702bdb375f403cbe7689414f079197e
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/410,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1768752783,jkbhagatio,7f5b51a7ac8f131cbe4fc51ca796d6f0c4821891,fc375d6797fcdf4b57dee2bba3622cf32d953891,"@@ -798,3 +798,116 @@ class AnalysisNote(dj.Manual):
     note_type='': varchar(64)
     note: varchar(3000)
     """"""
+
+
+""""""Foraging bout function.""""""
+
+
+def get_foraging_bouts(
+    key: dict,
+    min_pellets: int = 3,
+    max_inactive_time: pd.Timedelta | None = None,  # seconds
+    min_wheel_movement: float = 10,  # cm
+) -> pd.DataFrame:
+    """"""Gets foraging bouts for all subjects across all patches within a block.
+
+    Args:
+        key: Block key - dict containing keys for 'experiment_name', 'block_start', 'block_end'.
+        min_pellets: Minimum number of pellets for a foraging bout.
+        max_inactive_time: Maximum time between `min_wheel_movement`s for a foraging bout.
+        min_wheel_movement: Minimum wheel movement for a foraging bout.
+
+    Returns:
+        DataFrame containing foraging bouts. Columns: duration, n_pellets, cum_wheel_dist, subject.
+    """"""
+    max_inactive_time = pd.Timedelta(seconds=60) if max_inactive_time is None else max_inactive_time
+    subject_patch_data = (BlockSubjectAnalysis.Patch() & key).fetch(format=""frame"")
+    subject_patch_data.reset_index(level=[""experiment_name""], drop=True, inplace=True)
+    subject_names = subject_patch_data.index.get_level_values(""subject_name"").unique()
+    wheel_ts = (BlockAnalysis.Patch & key).fetch(""wheel_timestamps"")[0]
+    # For each subject:
+    #   - Create cumulative wheel distance spun sum df combining all patches
+    #     - Columns: timestamp, wheel distance, patch
+    #   - Discretize into 'possible foraging events' based on `max_inactive_time`, and `min_wheel_movement`
+    #   - Filter out events with < `min_pellets`
+    #   - For final events, get: duration, n_pellets, cum_wheel_distance -> add to returned DF
+    bout_data = pd.DataFrame(columns=[""start"", ""end"", ""n_pellets"", ""cum_wheel_dist"", ""subject""])
+    for subject in subject_names:
+        cur_subject_data = subject_patch_data.xs(subject, level=""subject_name"")
+        # Create combined cumulative wheel distance spun: ensure equal length wheel vals across patches
+        wheel_vals = cur_subject_data[""wheel_cumsum_distance_travelled""].values
+        min_len = min(len(arr) for arr in wheel_vals)
+        comb_cum_wheel_dist = np.sum([arr[:min_len] for arr in wheel_vals], axis=0)
+        wheel_ts, comb_cum_wheel_dist = (  # ensure equal length wheel vals and wheel ts
+            arr[: min(len(wheel_ts), len(comb_cum_wheel_dist))] for arr in [wheel_ts, comb_cum_wheel_dist]
+        )
+        # For each wheel_ts, get the correspdoning patch that was spun
+        patch_spun = np.empty(len(wheel_ts), dtype=""<U20"")
+        patch_spun[:] = """"
+        wheel_spun_thresh = 0.03  # threshold for wheel movement (cm)
+        for _, row in cur_subject_data.iterrows():
+            patch_name = row.name[1]
+            diff = np.diff(row[""wheel_cumsum_distance_travelled""], prepend=0)
+            spun_indices = np.where(diff > wheel_spun_thresh)[0]
+            patch_spun[spun_indices] = patch_name
+        patch_spun_df = pd.DataFrame(index=wheel_ts, columns=[""cum_wheel_dist"", ""patch_spun""])
+        patch_spun_df[""cum_wheel_dist""] = comb_cum_wheel_dist
+        patch_spun_df[""patch_spun""] = patch_spun
+        wheel_s_r = pd.Timedelta(wheel_ts[1] - wheel_ts[0], unit=""ns"")
+        win_len = int(max_inactive_time / wheel_s_r)
+        # Find times when foraging
+        max_windowed_wheel_vals = (
+            patch_spun_df[""cum_wheel_dist""]
+            .shift(-(win_len - 1))
+            .rolling(window=win_len, min_periods=1)
+            .max()
+        )
+        foraging_mask = max_windowed_wheel_vals > (patch_spun_df[""cum_wheel_dist""] + min_wheel_movement)
+        # Discretize into foraging bouts
+        bout_start_indxs = np.where(np.diff(foraging_mask.astype(int), prepend=0) == 1)[0]",aeon/dj_pipeline/analysis/block_analysis.py,2024-09-20 14:42:26+00:00,2024-09-20T14:42:26Z,these should be shifted up by `win_len`,,,,,865,RIGHT,70,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/410,SainsburyWellcomeCentre/aeon_mecha,775e0cabc19bd070b372d6f3d1856acdbbd66aeb
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/410,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1768761688,jkbhagatio,7f5b51a7ac8f131cbe4fc51ca796d6f0c4821891,fc375d6797fcdf4b57dee2bba3622cf32d953891,"@@ -798,3 +798,116 @@ class AnalysisNote(dj.Manual):
     note_type='': varchar(64)
     note: varchar(3000)
     """"""
+
+
+""""""Foraging bout function.""""""
+
+
+def get_foraging_bouts(
+    key: dict,
+    min_pellets: int = 3,
+    max_inactive_time: pd.Timedelta | None = None,  # seconds
+    min_wheel_movement: float = 10,  # cm
+) -> pd.DataFrame:
+    """"""Gets foraging bouts for all subjects across all patches within a block.
+
+    Args:
+        key: Block key - dict containing keys for 'experiment_name', 'block_start', 'block_end'.
+        min_pellets: Minimum number of pellets for a foraging bout.
+        max_inactive_time: Maximum time between `min_wheel_movement`s for a foraging bout.
+        min_wheel_movement: Minimum wheel movement for a foraging bout.
+
+    Returns:
+        DataFrame containing foraging bouts. Columns: duration, n_pellets, cum_wheel_dist, subject.
+    """"""
+    max_inactive_time = pd.Timedelta(seconds=60) if max_inactive_time is None else max_inactive_time
+    subject_patch_data = (BlockSubjectAnalysis.Patch() & key).fetch(format=""frame"")
+    subject_patch_data.reset_index(level=[""experiment_name""], drop=True, inplace=True)
+    subject_names = subject_patch_data.index.get_level_values(""subject_name"").unique()
+    wheel_ts = (BlockAnalysis.Patch & key).fetch(""wheel_timestamps"")[0]
+    # For each subject:
+    #   - Create cumulative wheel distance spun sum df combining all patches
+    #     - Columns: timestamp, wheel distance, patch
+    #   - Discretize into 'possible foraging events' based on `max_inactive_time`, and `min_wheel_movement`
+    #   - Filter out events with < `min_pellets`
+    #   - For final events, get: duration, n_pellets, cum_wheel_distance -> add to returned DF
+    bout_data = pd.DataFrame(columns=[""start"", ""end"", ""n_pellets"", ""cum_wheel_dist"", ""subject""])
+    for subject in subject_names:
+        cur_subject_data = subject_patch_data.xs(subject, level=""subject_name"")
+        # Create combined cumulative wheel distance spun: ensure equal length wheel vals across patches
+        wheel_vals = cur_subject_data[""wheel_cumsum_distance_travelled""].values
+        min_len = min(len(arr) for arr in wheel_vals)
+        comb_cum_wheel_dist = np.sum([arr[:min_len] for arr in wheel_vals], axis=0)
+        wheel_ts, comb_cum_wheel_dist = (  # ensure equal length wheel vals and wheel ts
+            arr[: min(len(wheel_ts), len(comb_cum_wheel_dist))] for arr in [wheel_ts, comb_cum_wheel_dist]
+        )
+        # For each wheel_ts, get the correspdoning patch that was spun
+        patch_spun = np.empty(len(wheel_ts), dtype=""<U20"")
+        patch_spun[:] = """"
+        wheel_spun_thresh = 0.03  # threshold for wheel movement (cm)
+        for _, row in cur_subject_data.iterrows():
+            patch_name = row.name[1]
+            diff = np.diff(row[""wheel_cumsum_distance_travelled""], prepend=0)
+            spun_indices = np.where(diff > wheel_spun_thresh)[0]
+            patch_spun[spun_indices] = patch_name
+        patch_spun_df = pd.DataFrame(index=wheel_ts, columns=[""cum_wheel_dist"", ""patch_spun""])
+        patch_spun_df[""cum_wheel_dist""] = comb_cum_wheel_dist
+        patch_spun_df[""patch_spun""] = patch_spun
+        wheel_s_r = pd.Timedelta(wheel_ts[1] - wheel_ts[0], unit=""ns"")
+        win_len = int(max_inactive_time / wheel_s_r)
+        # Find times when foraging
+        max_windowed_wheel_vals = (
+            patch_spun_df[""cum_wheel_dist""]
+            .shift(-(win_len - 1))
+            .rolling(window=win_len, min_periods=1)
+            .max()
+        )
+        foraging_mask = max_windowed_wheel_vals > (patch_spun_df[""cum_wheel_dist""] + min_wheel_movement)
+        # Discretize into foraging bouts
+        bout_start_indxs = np.where(np.diff(foraging_mask.astype(int), prepend=0) == 1)[0]
+        bout_end_indxs = np.where(np.diff(foraging_mask.astype(int), prepend=0) == -1)[0]",aeon/dj_pipeline/analysis/block_analysis.py,2024-09-20 14:49:11+00:00,2024-09-20T14:49:12Z,Need to account for final pellet delivery in bout: time for bonsai to deliver pellet / beambreak to occur after threshold crossing,,,,,866,RIGHT,71,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/410,SainsburyWellcomeCentre/aeon_mecha,775e0cabc19bd070b372d6f3d1856acdbbd66aeb
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/410,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1776930394,anayapouget,c98a16310cfebaf8255c828aa7afe45876fa7a41,fc375d6797fcdf4b57dee2bba3622cf32d953891,"@@ -866,7 +866,7 @@ def get_foraging_bouts(
         foraging_mask = max_windowed_wheel_vals > (patch_spun_df[""cum_wheel_dist""] + min_wheel_movement)
         # Discretize into foraging bouts
         bout_start_indxs = np.where(np.diff(foraging_mask, prepend=0) == 1)[0] + (win_len - 1)
-        n_samples_in_1s = int(1 / ((wheel_ts[1] - wheel_ts[0]).astype(int) / 1e9))
+        n_samples_in_1s = int(1 / wheel_s_r.total_seconds())
         bout_end_indxs = np.where(np.diff(foraging_mask, prepend=0) == -1)[0] + n_samples_in_1s",aeon/dj_pipeline/analysis/block_analysis.py,2024-09-26 12:11:03+00:00,2024-09-26T12:11:29Z,"You may want to add something like this to avoid the last bout end being out of range of the wheel ts df
```python
bout_end_indxs[-1] = min(bout_end_indxs[-1], len(wheel_ts) - 1)
```",,,,,870,RIGHT,6,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/410,SainsburyWellcomeCentre/aeon_mecha,775e0cabc19bd070b372d6f3d1856acdbbd66aeb
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/398,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1736222201,lochhh,e3337f705867f45aa3ae4abe125e7d920e32dc8e,61d173d139b28e8c3637752cc864e5ab25ddb5f3,"@@ -798,3 +774,57 @@ class AnalysisNote(dj.Manual):
     note_type='': varchar(64)
     note: varchar(3000)
     """"""
+
+# ---- Helper Functions ----
+
+
+def get_threshold_associated_pellets(patch_key, start, end):
+    """"""
+    Retrieve the pellet delivery timestamps associated with each patch threshold update within the specified start-end time.
+    1. Get all patch state update timestamps (DepletionState): let's call these events ""A""
+        - Remove all events within 1 second of each other
+        - Remove all events without threshold value (NaN)
+    2. Get all pellet delivery timestamps (DeliverPellet): let's call these events ""B""
+    3. For each event ""A"", find the nearest event ""B"" within 100ms before or after the event ""A""
+        - These are the pellet delivery events ""B"" associated with the previous threshold update event ""A""
+    4. Shift back the pellet delivery timestamps by 1 to match the pellet delivery with the previous threshold update
+    5. Remove all threshold updates events ""A"" without a corresponding pellet delivery event ""B""
+    """"""
+    chunk_restriction = acquisition.create_chunk_restriction(
+        patch_key[""experiment_name""], start, end
+    )
+    # pellet delivery and patch threshold data
+    delivered_pellet_df = fetch_stream(
+        streams.UndergroundFeederDeliverPellet & patch_key & chunk_restriction
+    )[start:end]
+    depletion_state_df = fetch_stream(
+        streams.UndergroundFeederDepletionState & patch_key & chunk_restriction
+    )[start:end]
+    # remove NaNs from threshold column
+    depletion_state_df = depletion_state_df.dropna(subset=[""threshold""])
+    # identify & remove invalid indices where the time difference is less than 1 second
+    invalid_indices = np.where(depletion_state_df.index.to_series().diff().dt.total_seconds() < 1)[0]
+    depletion_state_df = depletion_state_df.drop(depletion_state_df.index[invalid_indices])",aeon/dj_pipeline/analysis/block_analysis.py,2024-08-29 13:32:57+00:00,2024-08-29T14:02:54Z,"```suggestion
    # remove invalid rows where the time difference is less than 1 second
    depletion_state_df = depletion_state_df[~(depletion_state_df.index.diff().total_seconds() < 1)]
```
If the DateTimeIndex at `invalid_indices` are duplicated,  `depletion_state_df.index[invalid_indices]` (i.e. dropping by DateTimeIndex)  will remove all rows having the same DateTimeIndex - we want to keep at least the first occurrence. For instance, all rows with `Timestamp(""2024-02-02 11:09:57.012000084"")` will be removed in the dataframe below:

![image](https://github.com/user-attachments/assets/623d9edb-8e81-4539-9d70-bd568544147f)",,805.0,RIGHT,,807,RIGHT,104,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/398,SainsburyWellcomeCentre/aeon_mecha,07fe4c2a54d737cbf6a2ae06a3fbbd3e268dfd1d
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/398,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1736276782,lochhh,e3337f705867f45aa3ae4abe125e7d920e32dc8e,61d173d139b28e8c3637752cc864e5ab25ddb5f3,"@@ -798,3 +774,57 @@ class AnalysisNote(dj.Manual):
     note_type='': varchar(64)
     note: varchar(3000)
     """"""
+
+# ---- Helper Functions ----
+
+
+def get_threshold_associated_pellets(patch_key, start, end):
+    """"""
+    Retrieve the pellet delivery timestamps associated with each patch threshold update within the specified start-end time.
+    1. Get all patch state update timestamps (DepletionState): let's call these events ""A""
+        - Remove all events within 1 second of each other
+        - Remove all events without threshold value (NaN)
+    2. Get all pellet delivery timestamps (DeliverPellet): let's call these events ""B""
+    3. For each event ""A"", find the nearest event ""B"" within 100ms before or after the event ""A""
+        - These are the pellet delivery events ""B"" associated with the previous threshold update event ""A""
+    4. Shift back the pellet delivery timestamps by 1 to match the pellet delivery with the previous threshold update
+    5. Remove all threshold updates events ""A"" without a corresponding pellet delivery event ""B""
+    """"""
+    chunk_restriction = acquisition.create_chunk_restriction(
+        patch_key[""experiment_name""], start, end
+    )
+    # pellet delivery and patch threshold data
+    delivered_pellet_df = fetch_stream(
+        streams.UndergroundFeederDeliverPellet & patch_key & chunk_restriction
+    )[start:end]
+    depletion_state_df = fetch_stream(
+        streams.UndergroundFeederDepletionState & patch_key & chunk_restriction
+    )[start:end]
+    # remove NaNs from threshold column
+    depletion_state_df = depletion_state_df.dropna(subset=[""threshold""])
+    # identify & remove invalid indices where the time difference is less than 1 second
+    invalid_indices = np.where(depletion_state_df.index.to_series().diff().dt.total_seconds() < 1)[0]
+    depletion_state_df = depletion_state_df.drop(depletion_state_df.index[invalid_indices])
+
+    # find pellet times approximately coincide with each threshold update
+    # i.e. nearest pellet delivery within 100ms before or after threshold update
+    delivered_pellet_ts = delivered_pellet_df.index
+    pellet_ts_threshold_df = depletion_state_df.copy()
+    pellet_ts_threshold_df[""pellet_timestamp""] = pd.NaT
+    for threshold_idx in range(len(pellet_ts_threshold_df)):
+        threshold_time = pellet_ts_threshold_df.index[threshold_idx]
+        within_range_pellet_ts = np.logical_and(delivered_pellet_ts >= threshold_time - pd.Timedelta(milliseconds=100),
+                                                delivered_pellet_ts <= threshold_time + pd.Timedelta(milliseconds=100))
+        if not within_range_pellet_ts.any():
+            continue
+        pellet_time = delivered_pellet_ts[within_range_pellet_ts][-1]
+        pellet_ts_threshold_df.pellet_timestamp.iloc[threshold_idx] = pellet_time
+
+    # remove rows of threshold updates without corresponding pellet times from i.e. pellet_timestamp is NaN
+    pellet_ts_threshold_df = pellet_ts_threshold_df.dropna(subset=[""pellet_timestamp""])",aeon/dj_pipeline/analysis/block_analysis.py,2024-08-29 14:01:54+00:00,2024-08-29T14:02:54Z,"```suggestion
    pellet_ts_threshold_df = (
        pd.merge_asof(
            depletion_state_df.reset_index(),
            delivered_pellet_df.reset_index().rename(columns={""time"": ""pellet_timestamp""}),
            left_on=""time"",
            right_on=""pellet_timestamp"",
            tolerance=pd.Timedelta(""100ms""),
            direction=""nearest"",
        )
        .set_index(""time"")
        .dropna(subset=[""pellet_timestamp""])
    )
    pellet_ts_threshold_df = pellet_ts_threshold_df.drop(columns=[""event""])
```",,811.0,RIGHT,,824,RIGHT,121,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/398,SainsburyWellcomeCentre/aeon_mecha,07fe4c2a54d737cbf6a2ae06a3fbbd3e268dfd1d
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/398,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1764812030,jkbhagatio,b05bc0788de0e6f0d99f8d245ef148c3d4ef104e,61d173d139b28e8c3637752cc864e5ab25ddb5f3,"@@ -798,3 +780,90 @@ class AnalysisNote(dj.Manual):
     note_type='': varchar(64)
     note: varchar(3000)
     """"""
+
+# ---- Helper Functions ----
+
+
+def get_threshold_associated_pellets(patch_key, start, end):
+    """"""
+    Retrieve the pellet delivery timestamps associated with each patch threshold update within the specified start-end time.
+    1. Get all patch state update timestamps (DepletionState): let's call these events ""A""",aeon/dj_pipeline/analysis/block_analysis.py,2024-09-18 10:29:03+00:00,2024-09-18T10:29:03Z,"We need to also remove all manual pellet delivery events
",,,,795.0,790,RIGHT,281,377.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/398,SainsburyWellcomeCentre/aeon_mecha,07fe4c2a54d737cbf6a2ae06a3fbbd3e268dfd1d
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/398,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1765179469,jkbhagatio,773996bee952dc45e9821266872b15a348af62dc,61d173d139b28e8c3637752cc864e5ab25ddb5f3,"@@ -798,3 +786,97 @@ class AnalysisNote(dj.Manual):
     note_type='': varchar(64)
     note: varchar(3000)
     """"""
+
+
+# ---- Helper Functions ----
+
+
+def get_threshold_associated_pellets(patch_key, start, end):
+    """"""
+    Retrieve the pellet delivery timestamps associated with each patch threshold update within the specified start-end time.
+    1. Get all patch state update timestamps (DepletionState): let's call these events ""A""
+        - Remove all events within 1 second of each other
+        - Remove all events without threshold value (NaN)
+    2. Get all pellet delivery timestamps (DeliverPellet): let's call these events ""B""
+        - Find matching beam break timestamps within 500ms after each pellet delivery
+    3. For each event ""A"", find the nearest event ""B"" within 100ms before or after the event ""A""
+        - These are the pellet delivery events ""B"" associated with the previous threshold update event ""A""
+    4. Shift back the pellet delivery timestamps by 1 to match the pellet delivery with the previous threshold update
+    5. Remove all threshold updates events ""A"" without a corresponding pellet delivery event ""B""
+
+    Args:
+        patch_key (dict): primary key for the patch
+        start (datetime): start timestamp
+        end (datetime): end timestamp
+
+    Returns:
+        pd.DataFrame: DataFrame with the following columns:
+        - threshold_update_timestamp (index)
+        - pellet_timestamp
+        - beam_break_timestamp
+        - offset
+        - rate
+    """"""
+    chunk_restriction = acquisition.create_chunk_restriction(patch_key[""experiment_name""], start, end)
+    # pellet delivery and beam break data
+    delivered_pellet_df = fetch_stream(
+        streams.UndergroundFeederDeliverPellet & patch_key & chunk_restriction
+    )[start:end]
+    beam_break_df = fetch_stream(streams.UndergroundFeederBeamBreak & patch_key & chunk_restriction)[
+        start:end
+    ]
+
+    if delivered_pellet_df.empty or beam_break_df.empty:
+        return acquisition.io_api._empty(
+            [""threshold"", ""offset"", ""rate"", ""pellet_timestamp"", ""beam_break_timestamp""]
+        )
+
+    # patch threshold data
+    depletion_state_df = fetch_stream(
+        streams.UndergroundFeederDepletionState & patch_key & chunk_restriction
+    )[start:end]
+    # remove NaNs from threshold column
+    depletion_state_df = depletion_state_df.dropna(subset=[""threshold""])
+    # remove invalid rows where the time difference is less than 1 second
+    invalid_rows = depletion_state_df.index.to_series().diff().dt.total_seconds() < 1
+    depletion_state_df = depletion_state_df[~invalid_rows]
+
+    # find pellet times with matching beam break times (within 500ms after pellet times)
+    pellet_beam_break_df = (",aeon/dj_pipeline/analysis/block_analysis.py,2024-09-18 14:34:55+00:00,2024-09-18T14:34:55Z,"Should we remove near-in-time pellet delivery events before doing this `merge_asof`, to reduce the tolerance specified here? Does it make a difference?

I'll look at this briefly",,,,848.0,845,RIGHT,336,430.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/398,SainsburyWellcomeCentre/aeon_mecha,07fe4c2a54d737cbf6a2ae06a3fbbd3e268dfd1d
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/398,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1773764875,lochhh,c69b78ea3a84abff51985f2f506670f854571b04,61d173d139b28e8c3637752cc864e5ab25ddb5f3,"@@ -188,37 +183,14 @@ def make(self, key):
         )
         patch_keys, patch_names = patch_query.fetch(""KEY"", ""underground_feeder_name"")",aeon/dj_pipeline/analysis/block_analysis.py,2024-09-24 17:33:25+00:00,2024-09-24T17:39:32Z,Should we exclude Dummy patches here or is this already handled elsewhere and we can assume dummy patches will never be fetched?,,,,184.0,184,RIGHT,166,166.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/398,SainsburyWellcomeCentre/aeon_mecha,07fe4c2a54d737cbf6a2ae06a3fbbd3e268dfd1d
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/432,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1787760107,jkbhagatio,747232bc21d3b9c88f11f59bcca42b15545c6796,24061c5d18e5576d519995a8b684b2ae0dbdf376,"@@ -1496,6 +1496,46 @@ def make(self, key):
         self.insert1(entry)
 
 
+# ---- Foraging Bout Analysis ----
+
+@schema
+class BlockForaging(dj.Computed):
+    definition = """"""
+    -> BlockSubjectAnalysis
+    ---
+    bout_count: int  # number of foraging bouts in the block
+    """"""
+
+    class Bout(dj.Part):
+        definition = """"""
+        -> master
+        -> BlockAnalysis.Subject
+        bout_start: datetime(6)
+        ---
+        bout_end: datetime(6)
+        bout_duration: float  # (seconds)",aeon/dj_pipeline/analysis/block_analysis.py,2024-10-04 13:56:02+00:00,2024-10-04T13:57:28Z,I'm happy to remove duration here and in the foraging_bouts function as it is trivial to recompute from the start and end times,,,,,1516,RIGHT,21,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/432,SainsburyWellcomeCentre/aeon_mecha,5dacb450d6db83e0fb8158c8c76476a4ffb6a828
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/421,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1782530630,jkbhagatio,6b32583f40753edc082637943750e831d0bd1c71,f925d750cd1278c5d902410ec342ebf4248dfd86,"@@ -312,10 +312,22 @@ def __init__(self, pattern: str, model_root: str = ""/ceph/aeon/aeon/data/process
     def read(self, file: Path) -> pd.DataFrame:
         """"""Reads data from the Harp-binarized tracking file.""""""
         # Get config file from `file`, then bodyparts from config file.
-        model_dir = Path(*Path(file.stem.replace(""_"", ""/"")).parent.parts[-4:])
-        config_file_dir = Path(self._model_root) / model_dir
-        if not config_file_dir.exists():
-            raise FileNotFoundError(f""Cannot find model dir {config_file_dir}"")
+        model_dir = Path(*Path(file.stem.replace(""_"", ""/"")).parent.parts[1:])",aeon/io/reader.py,2024-10-01 10:31:09+00:00,2024-10-01T10:31:09Z,"Are we sure this will always work? I think there was a reason I was counting dirs backwards from the end of the file, maybe if locations change it's important? 

But you can confirm?",,,,,315,RIGHT,8,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/421,SainsburyWellcomeCentre/aeon_mecha,83cd9056b5434b830384c61211752035990e1738
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/351,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1581104089,lochhh,5276cc1a4e96add9c54da83ecccdebd38d487001,f9ae80a092cdb2c0518d0632f644731257558053,"@@ -0,0 +1,185 @@
+""""""
+# run all tests:
+# pytest -sv --cov-report term-missing --cov=aeon_mecha -p no:warnings tests/dj_pipeline
+
+# run one test, debug:
+# pytest [above options] --pdb tests/dj_pipeline/test_ingestion.py -k <function_name>
+
+# run test on marker:
+# pytest -m <marker_name>
+""""""
+
+import os
+import pathlib
+
+import datajoint as dj
+import pytest
+
+_tear_down = True  # always set to True since most fixtures are session-scoped
+_populate_settings = {""suppress_errors"": True}
+
+
+def data_dir():
+    """"""
+    Returns test data directory
+    """"""
+    return os.path.join(os.path.dirname(os.path.realpath(__file__)), ""data"")
+
+
+@pytest.fixture(autouse=True, scope=""session"")
+def test_params():
+
+    return {
+        ""start_ts"": ""2022-06-22 08:51:10"",
+        ""end_ts"": ""2022-06-22 14:00:00"",
+        ""experiment_name"": ""exp0.2-r0"",
+        ""raw_dir"": ""aeon/data/raw/AEON2/experiment0.2"",
+        ""qc_dir"": ""aeon/data/qc/AEON2/experiment0.2"",
+        ""test_dir"": data_dir(),
+        ""subject_count"": 5,
+        ""epoch_count"": 1,
+        ""chunk_count"": 7,
+        ""experiment_log_message_count"": 0,
+        ""subject_enter_exit_count"": 0,
+        ""subject_weight_time_count"": 0,
+        ""camera_qc_count"": 40,
+        ""camera_tracking_object_count"": 5,
+    }
+
+
+@pytest.fixture(autouse=True, scope=""session"")
+def dj_config():
+    """"""If dj_local_config exists, load""""""
+    dj_config_fp = pathlib.Path(""dj_local_conf.json"")
+    assert dj_config_fp.exists()
+    dj.config.load(dj_config_fp)
+    dj.config[""safemode""] = False
+    assert ""custom"" in dj.config
+    dj.config[""custom""][
+        ""database.prefix""
+    ] = f""u_{dj.config['database.user']}_testsuite_""
+    return",tests/conftest.py,2024-04-26 14:17:08+00:00,2024-04-26T15:01:15Z,Can we drop the `return` statements in the fixtures that do not return anything?,,,,,61,RIGHT,61,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/351,SainsburyWellcomeCentre/aeon_mecha,25cc4b724d0451bf1171a70791bc3a3ed7d8d698
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/351,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1581121186,lochhh,5276cc1a4e96add9c54da83ecccdebd38d487001,f9ae80a092cdb2c0518d0632f644731257558053,"@@ -0,0 +1,115 @@
+import datajoint as dj
+from datajoint_utilities.dj_worker import DataJointWorker, ErrorLog, WorkerLog
+from datajoint_utilities.dj_worker.worker_schema import is_djtable
+
+from aeon.dj_pipeline import db_prefix
+from aeon.dj_pipeline import subject, acquisition, tracking, qc
+from aeon.dj_pipeline.analysis import block_analysis
+from aeon.dj_pipeline.utils import streams_maker
+
+streams = streams_maker.main()
+
+__all__ = [
+    ""acquisition_worker"",
+    ""analysis_worker"",
+    ""pyrat_worker"",
+    ""streams_worker"",
+    ""WorkerLog"",
+    ""ErrorLog"",
+    ""logger"",
+    ""AutomatedExperimentIngestion"",
+]
+
+# ---- Some constants ----
+logger = dj.logger
+worker_schema_name = db_prefix + ""worker""
+
+# ---- Manage experiments for automated ingestion ----
+
+schema = dj.Schema(worker_schema_name)
+
+
+@schema
+class AutomatedExperimentIngestion(dj.Manual):
+    definition = """"""  # experiments to undergo automated ingestion
+    -> acquisition.Experiment
+    """"""
+
+
+def ingest_epochs_chunks():
+    """"""Ingest epochs and chunks for experiments specified in AutomatedExperimentIngestion.""""""
+    experiment_names = AutomatedExperimentIngestion.fetch(""experiment_name"")
+    for experiment_name in experiment_names:
+        acquisition.Epoch.ingest_epochs(experiment_name)
+        acquisition.Chunk.ingest_chunks(experiment_name)
+
+
+def ingest_environment_visits():
+    """"""Extract and insert complete visits for experiments specified in AutomatedExperimentIngestion.""""""
+    experiment_names = AutomatedExperimentIngestion.fetch(""experiment_name"")
+    # analysis.ingest_environment_visits(experiment_names)
+    pass",aeon/dj_pipeline/populate/worker.py,2024-04-26 14:30:06+00:00,2024-04-26T14:30:07Z,"```suggestion
```",,,,51.0,51,RIGHT,51,51.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/351,SainsburyWellcomeCentre/aeon_mecha,25cc4b724d0451bf1171a70791bc3a3ed7d8d698
https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/38,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1609815493,saiqulhaq,275ffeb2971e2e36f84b6ac3cffb46911772ceb9,33d257275a47f12639c83be53c6bd7284a485a9d,"@@ -22,7 +22,7 @@ class Configuration
     #       config.async_processing = false # or true. if true, the shortening process will be done asynchronously using ActiveJob
     #       config.redis_counter_config = RedisConfig.new # see RedisConfig documentation for more details
     #       # if you use Redis
-    #       config.cache_store = ActiveSupport::Cache::RedisStore.new('redis://localhost:6379/0/cache')
+    #       config.cache_store = ActiveSupport::Cache::RedisCacheStore.new(url: 'redis://localhost:6379/0/cache')",lib/dynamic_links/configuration.rb,2024-05-22 11:54:09+00:00,2024-05-22T12:08:43Z,nice one ,,,,25.0,25,RIGHT,5,5.0,line,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/38,saiqulhaq/dynamic_links,b185949d02319db80a4db7af6d853351edf0b0e4
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1822847464,lochhh,907808593960317fa64d5e5eda43986de1c2c058,b0952eb0f413243953e19698d27488a51647c777,"@@ -30,11 +31,17 @@ def dict_to_uuid(key) -> uuid.UUID:
     return uuid.UUID(hex=hashed.hexdigest())
 
 
-def fetch_stream(query, drop_pk=True):
+def fetch_stream(query, drop_pk=True, round_microseconds=True):
     """"""Fetches data from a Stream table based on a query and returns it as a DataFrame.
 
     Provided a query containing data from a Stream table,
     fetch and aggregate the data into one DataFrame indexed by ""time""
+
+    Args:
+        query (datajoint.Query): A query object containing data from a Stream table
+        drop_pk (bool, optional): Drop primary key columns. Defaults to True.
+        round_microseconds (bool, optional): Round timestamps to microseconds. Defaults to False.",aeon/dj_pipeline/__init__.py,2024-10-30 15:13:38+00:00,2024-10-30T15:13:38Z,Defaults to `True`? ,,,,,43,RIGHT,20,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,SainsburyWellcomeCentre/aeon_mecha,c2e90b6890583ec01418c5c5e2b88ed7fa0cdb58
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1823047548,jkbhagatio,907808593960317fa64d5e5eda43986de1c2c058,b0952eb0f413243953e19698d27488a51647c777,"@@ -181,17 +182,27 @@ def make(self, key):
             streams.UndergroundFeederDepletionState,
             streams.UndergroundFeederDeliverPellet,
             streams.UndergroundFeederEncoder,
-            tracking.SLEAPTracking,
         )
         for streams_table in streams_tables:
             if len(streams_table & chunk_keys) < len(streams_table.key_source & chunk_keys):
                 raise ValueError(
                     f""BlockAnalysis Not Ready - {streams_table.__name__} not yet fully ingested for block: {key}. Skipping (to retry later)...""
                 )
 
+        # Check if SLEAPTracking is ready, if not, see if BlobPosition can be used instead
+        use_blob_position = False
+        if len(tracking.SLEAPTracking & chunk_keys) < len(tracking.SLEAPTracking.key_source & chunk_keys):
+            if len(tracking.BlobPosition & chunk_keys) < len(tracking.BlobPosition.key_source & chunk_keys):
+                raise ValueError(
+                    f""BlockAnalysis Not Ready - SLEAPTracking (and BlobPosition) not yet fully ingested for block: {key}. Skipping (to retry later)...""
+                )
+            else:
+                use_blob_position = True
+
         # Patch data - TriggerPellet, DepletionState, Encoder (distancetravelled)
         # For wheel data, downsample to 10Hz
-        final_encoder_fs = 10
+        final_encoder_hz = 10",aeon/dj_pipeline/analysis/block_analysis.py,2024-10-30 16:58:14+00:00,2024-10-30T16:58:15Z,"I think we actually want this to be 50 hz, not 10 hz",,,,,204,RIGHT,55,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,SainsburyWellcomeCentre/aeon_mecha,c2e90b6890583ec01418c5c5e2b88ed7fa0cdb58
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1823050082,jkbhagatio,907808593960317fa64d5e5eda43986de1c2c058,b0952eb0f413243953e19698d27488a51647c777,"@@ -233,51 +244,51 @@ def make(self, key):
                 encoder_df, maintenance_period, block_end, dropna=True
             )
 
-            if depletion_state_df.empty:
-                raise ValueError(f""No depletion state data found for block {key} - patch: {patch_name}"")
-
-            encoder_df[""distance_travelled""] = -1 * analysis_utils.distancetravelled(encoder_df.angle)
+            # if all dataframes are empty, skip
+            if pellet_ts_threshold_df.empty and depletion_state_df.empty and encoder_df.empty:
+                continue
 
-            if len(depletion_state_df.rate.unique()) > 1:
-                # multiple patch rates per block is unexpected, log a note and pick the first rate to move forward
-                AnalysisNote.insert1(
-                    {
-                        ""note_timestamp"": datetime.utcnow(),
-                        ""note_type"": ""Multiple patch rates"",
-                        ""note"": f""Found multiple patch rates for block {key} - patch: {patch_name} - rates: {depletion_state_df.rate.unique()}"",
-                    }
-                )
+            if encoder_df.empty:
+                encoder_df[""distance_travelled""] = 0
+            else:
+                encoder_df[""distance_travelled""] = -1 * analysis_utils.distancetravelled(encoder_df.angle)",aeon/dj_pipeline/analysis/block_analysis.py,2024-10-30 16:59:57+00:00,2024-10-30T16:59:58Z,"maybe add a comment saying something like -1 is for placement of magnetic encoder, where wheel movement actually decreases encoder value?",,,,255.0,254,RIGHT,84,91.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,SainsburyWellcomeCentre/aeon_mecha,c2e90b6890583ec01418c5c5e2b88ed7fa0cdb58
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1823053362,jkbhagatio,907808593960317fa64d5e5eda43986de1c2c058,b0952eb0f413243953e19698d27488a51647c777,"@@ -233,51 +244,51 @@ def make(self, key):
                 encoder_df, maintenance_period, block_end, dropna=True
             )
 
-            if depletion_state_df.empty:
-                raise ValueError(f""No depletion state data found for block {key} - patch: {patch_name}"")
-
-            encoder_df[""distance_travelled""] = -1 * analysis_utils.distancetravelled(encoder_df.angle)
+            # if all dataframes are empty, skip
+            if pellet_ts_threshold_df.empty and depletion_state_df.empty and encoder_df.empty:
+                continue
 
-            if len(depletion_state_df.rate.unique()) > 1:
-                # multiple patch rates per block is unexpected, log a note and pick the first rate to move forward
-                AnalysisNote.insert1(
-                    {
-                        ""note_timestamp"": datetime.utcnow(),
-                        ""note_type"": ""Multiple patch rates"",
-                        ""note"": f""Found multiple patch rates for block {key} - patch: {patch_name} - rates: {depletion_state_df.rate.unique()}"",
-                    }
-                )
+            if encoder_df.empty:
+                encoder_df[""distance_travelled""] = 0
+            else:
+                encoder_df[""distance_travelled""] = -1 * analysis_utils.distancetravelled(encoder_df.angle)
+                encoder_df = encoder_df.resample(f""{freq}ms"").first()
 
-            patch_rate = depletion_state_df.rate.iloc[0]
-            patch_offset = depletion_state_df.offset.iloc[0]
-            # handles patch rate value being INF
-            patch_rate = 999999999 if np.isinf(patch_rate) else patch_rate
+            if not depletion_state_df.empty:
+                if len(depletion_state_df.rate.unique()) > 1:
+                    # multiple patch rates per block is unexpected, log a note and pick the first rate to move forward
+                    AnalysisNote.insert1(
+                        {
+                            ""note_timestamp"": datetime.utcnow(),
+                            ""note_type"": ""Multiple patch rates"",
+                            ""note"": f""Found multiple patch rates for block {key} - patch: {patch_name} - rates: {depletion_state_df.rate.unique()}"",
+                        }
+                    )
 
-            encoder_fs = (
-                1 / encoder_df.index.to_series().diff().dt.total_seconds().median()
-            )  # mean or median?
-            wheel_downsampling_factor = int(encoder_fs / final_encoder_fs)
+                patch_rate = depletion_state_df.rate.iloc[0]
+                patch_offset = depletion_state_df.offset.iloc[0]
+                # handles patch rate value being INF
+                patch_rate = 999999999 if np.isinf(patch_rate) else patch_rate",aeon/dj_pipeline/analysis/block_analysis.py,2024-10-30 17:02:12+00:00,2024-10-30T17:02:12Z,is it actually an issue if patch rate is inf? Does it cause some downstream issue? We do this as default when no env is loaded.,,,,272.0,271,RIGHT,109,112.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,SainsburyWellcomeCentre/aeon_mecha,c2e90b6890583ec01418c5c5e2b88ed7fa0cdb58
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1823057400,jkbhagatio,907808593960317fa64d5e5eda43986de1c2c058,b0952eb0f413243953e19698d27488a51647c777,"@@ -288,27 +299,50 @@ def make(self, key):
             & f'chunk_start <= ""{chunk_keys[-1][""chunk_start""]}""'
         )[:block_start]
         subject_visits_df = subject_visits_df[subject_visits_df.region == ""Environment""]
+        subject_visits_df = subject_visits_df[~subject_visits_df.id.str.contains(""Test"", case=False)]",aeon/dj_pipeline/analysis/block_analysis.py,2024-10-30 17:04:29+00:00,2024-10-30T17:04:30Z,"sometimes we use other, non ""Test"" subjects as test subjects. Maybe the check should be, if the subject does not begin with 'baa' (can str.lower to check for regardless of case) ?",,,,303.0,302,RIGHT,144,147.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,SainsburyWellcomeCentre/aeon_mecha,c2e90b6890583ec01418c5c5e2b88ed7fa0cdb58
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1823059889,jkbhagatio,907808593960317fa64d5e5eda43986de1c2c058,b0952eb0f413243953e19698d27488a51647c777,"@@ -288,27 +299,50 @@ def make(self, key):
             & f'chunk_start <= ""{chunk_keys[-1][""chunk_start""]}""'
         )[:block_start]
         subject_visits_df = subject_visits_df[subject_visits_df.region == ""Environment""]
+        subject_visits_df = subject_visits_df[~subject_visits_df.id.str.contains(""Test"", case=False)]
         subject_names = []
         for subject_name in set(subject_visits_df.id):
             _df = subject_visits_df[subject_visits_df.id == subject_name]
             if _df.type.iloc[-1] != ""Exit"":
                 subject_names.append(subject_name)
 
+        if use_blob_position and len(subject_names) > 1:
+            raise ValueError(
+                f""Without SLEAPTracking, BlobPosition can only handle single-subject block. Found {len(subject_names)} subjects.""
+            )
+
         block_subject_entries = []
         for subject_name in subject_names:
             # positions - query for CameraTop, identity_name matches subject_name,
-            pos_query = (
-                streams.SpinnakerVideoSource
-                * tracking.SLEAPTracking.PoseIdentity.proj(""identity_name"", part_name=""anchor_part"")
-                * tracking.SLEAPTracking.Part
-                & key
-                & {
-                    ""spinnaker_video_source_name"": ""CameraTop"",
-                    ""identity_name"": subject_name,
-                }
-                & chunk_restriction
-            )
-            pos_df = fetch_stream(pos_query)[block_start:block_end]
+            if use_blob_position:
+                pos_query = (
+                    streams.SpinnakerVideoSource
+                    * tracking.BlobPosition.Object
+                    & key
+                    & chunk_restriction
+                    & {
+                        ""spinnaker_video_source_name"": ""CameraTop"",
+                        ""identity_name"": subject_name
+                    }
+                )
+                pos_df = fetch_stream(pos_query)[block_start:block_end]
+                pos_df[""likelihood""] = np.nan
+                # keep only rows with area between 0 and 1000",aeon/dj_pipeline/analysis/block_analysis.py,2024-10-30 17:06:01+00:00,2024-10-30T17:06:01Z,"is this because areas of > 1000 is likely an experimenter, or some other artifact? Maybe specify that in the comment?",,,,,330,RIGHT,184,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,SainsburyWellcomeCentre/aeon_mecha,c2e90b6890583ec01418c5c5e2b88ed7fa0cdb58
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1823086530,jkbhagatio,907808593960317fa64d5e5eda43986de1c2c058,b0952eb0f413243953e19698d27488a51647c777,"@@ -76,9 +75,12 @@ def read(self, file):
         if self.columns is not None and payloadshape[1] < len(self.columns):
             data = pd.DataFrame(payload, index=seconds, columns=self.columns[: payloadshape[1]])
             data[self.columns[payloadshape[1] :]] = math.nan
-            return data
         else:
-            return pd.DataFrame(payload, index=seconds, columns=self.columns)
+            data = pd.DataFrame(payload, index=seconds, columns=self.columns)
+
+        # remove rows where the index is zero (why? corrupted data in harp files?)
+        data = data[data.index != 0]",aeon/io/reader.py,2024-10-30 17:22:33+00:00,2024-10-30T17:22:33Z,This I guess will be fixed in the next PR targeting a new Encoder reader in ingestion_schemas.py ?,,,,82.0,82,RIGHT,20,20.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,SainsburyWellcomeCentre/aeon_mecha,c2e90b6890583ec01418c5c5e2b88ed7fa0cdb58
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1823096837,jkbhagatio,907808593960317fa64d5e5eda43986de1c2c058,b0952eb0f413243953e19698d27488a51647c777,"@@ -48,6 +48,12 @@ def __init__(self, path):
         super().__init__(_reader.Pose(f""{path}_test-node1*""))
 
 
+class Pose03(Stream):",aeon/schema/social_02.py,2024-10-30 17:29:28+00:00,2024-10-30T17:29:28Z,made add a comment that this is necessary due to changing registers for the pose streams for social02 in particular? And that 03 corresponds to the fact that this is because this pattern is what we're going with for social03 and moving forward? Or call this class something else?,,,,51.0,51,RIGHT,4,4.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/438,SainsburyWellcomeCentre/aeon_mecha,c2e90b6890583ec01418c5c5e2b88ed7fa0cdb58
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/456,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1868322747,ttngu207,a8528bce77a1d556960d22d83496d78c1813fc07,94ef78ad6de925ae23c214d1b5793ba3592e536f,"@@ -0,0 +1,68 @@
+# Pipeline Deployment (On-Premises)
+
+This page describes the processes and required resources to deploy the Project Aeon data pipeline on-premises.
+
+## Prerequisites
+
+On the most basic level, in order to deploy and operate a DataJoint pipeline, you will need:
+
+1. A MySQL database server (version 8.0) with configured to be DataJoint compatible
+   - see [here](https://github.com/datajoint/mysql-docker/blob/master/config/my.cnf) for configuration of the MySQL server to be DataJoint compatible
+2. If you want to use a preconfigured Docker container ([install Docker](https://docs.docker.com/engine/install/)), run the following command:
+      ```bash
+         docker run -d \
+           --name db \
+           -p 3306:3306 \
+           -e MYSQL_ROOT_PASSWORD=simple \
+           -v ./mysql/data:/var/lib/mysql \
+           datajoint/mysql:8.0 \
+           mysqld --default-authentication-plugin=mysql_native_password
+      ```
+   
+    A new MySQL server will be launched in a Docker Container with the following credentials: 
+    - host: `localhost`
+    - username: `root`
+    - password: `simple`
+    
+   To stop the container, run the following command:
+   
+    ```bash
+       docker stop db
+    ```
+   
+3. a GitHub repository with the [codebase](https://github.com/SainsburyWellcomeCentre/aeon_mecha) of the DataJoint pipeline
+   - this repository is the codebase, no additional modifications are needed to deploy this codebase locally
+4. file storage
+   - the pipeline requires a location to access/store the data files (this can be a local directory or mounted network storage)
+5. compute
+   - you need some form of a compute environment with the right software installed to run the pipeline (this could be a laptop, local work station or an HPC cluster)
+
+## Download the data
+
+The released data for Project Aeon can be downloaded from the data repository [here](https://zenodo.org/records/13881885)",aeon/dj_pipeline/docs/PIPELINE_LOCAL_DEPLOYMENT.md,2024-12-03 20:25:02+00:00,2024-12-03T20:25:03Z,The download link will be updated once we have the new dataset released for the paper,,,,42.0,42,RIGHT,42,42.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/456,SainsburyWellcomeCentre/aeon_mecha,bf4e56c57d2085797cbc74984a05cbd89e6e7c03
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/456,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1869244679,MilagrosMarin,a8528bce77a1d556960d22d83496d78c1813fc07,94ef78ad6de925ae23c214d1b5793ba3592e536f,"@@ -0,0 +1,68 @@
+# Pipeline Deployment (On-Premises)
+
+This page describes the processes and required resources to deploy the Project Aeon data pipeline on-premises.
+
+## Prerequisites
+
+On the most basic level, in order to deploy and operate a DataJoint pipeline, you will need:
+
+1. A MySQL database server (version 8.0) with configured to be DataJoint compatible
+   - see [here](https://github.com/datajoint/mysql-docker/blob/master/config/my.cnf) for configuration of the MySQL server to be DataJoint compatible
+2. If you want to use a preconfigured Docker container ([install Docker](https://docs.docker.com/engine/install/)), run the following command:
+      ```bash
+         docker run -d \
+           --name db \
+           -p 3306:3306 \
+           -e MYSQL_ROOT_PASSWORD=simple \
+           -v ./mysql/data:/var/lib/mysql \
+           datajoint/mysql:8.0 \
+           mysqld --default-authentication-plugin=mysql_native_password
+      ```
+   
+    A new MySQL server will be launched in a Docker Container with the following credentials: 
+    - host: `localhost`
+    - username: `root`
+    - password: `simple`
+    
+   To stop the container, run the following command:
+   
+    ```bash
+       docker stop db
+    ```
+   
+3. a GitHub repository with the [codebase](https://github.com/SainsburyWellcomeCentre/aeon_mecha) of the DataJoint pipeline
+   - this repository is the codebase, no additional modifications are needed to deploy this codebase locally
+4. file storage
+   - the pipeline requires a location to access/store the data files (this can be a local directory or mounted network storage)
+5. compute
+   - you need some form of a compute environment with the right software installed to run the pipeline (this could be a laptop, local work station or an HPC cluster)
+
+## Download the data
+
+The released data for Project Aeon can be downloaded from the data repository [here](https://zenodo.org/records/13881885)
+
+
+## Pipeline Installation & Configuration
+
+### Installation Instructions
+
+In order to run the pipeline, follow the instruction to install this codebase in the ""Local set-up"" section",aeon/dj_pipeline/docs/PIPELINE_LOCAL_DEPLOYMENT.md,2024-12-04 11:05:10+00:00,2024-12-04T11:07:46Z,"We can add directly the link here for reference. Something similar to this: 

`[""Local set-up"" section](../../README.md#Local-set-up)`",,,,,49,RIGHT,49,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/456,SainsburyWellcomeCentre/aeon_mecha,bf4e56c57d2085797cbc74984a05cbd89e6e7c03
https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/43,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1665791828,saiqulhaq,76acfb1a8d3d58a0ad32483f607beb8c74c187f8,f02a00c9e27d71eaac9d4e5668cca85dae978b74,"@@ -12,6 +12,8 @@ gem 'pg', '>= 0.18', '< 2.0'
 
 gem 'sprockets-rails'
 
+gem 'ahoy_matey'",Gemfile,2024-07-04 14:30:39+00:00,2024-07-04T14:40:07Z,"it should be in the gemspec file
because it's a dependency of this gem",,,,15.0,15,RIGHT,4,4.0,line,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/43,saiqulhaq/dynamic_links,8cd8984b1205ca62cbd111fe6cd0ee8395c6f814
https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/43,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1665798860,saiqulhaq,76acfb1a8d3d58a0ad32483f607beb8c74c187f8,f02a00c9e27d71eaac9d4e5668cca85dae978b74,"@@ -5,6 +5,12 @@ def show
       link = ShortenedUrl.find_by(short_url: short_url)
 
       if link
+        ahoy.track ""ShortenedUrl Visit"", {",app/controllers/dynamic_links/redirects_controller.rb,2024-07-04 14:36:54+00:00,2024-07-04T14:40:07Z,"need to track more metrics, maybe like this

```
ahoy.track ""ShortenedUrl Visit"", {
  shortened_url: short_url,
  user_agent: request.user_agent,
  referrer: request.referrer,
  ip: request.ip,
  device_type: ahoy.request.device_type,
  os: ahoy.request.os,
  browser: ahoy.request.browser,
  utm_source: params[:utm_source],
  utm_medium: params[:utm_medium],
  utm_campaign: params[:utm_campaign],
  landing_page: request.original_url,
}
```",,,,,8,RIGHT,4,,line,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/43,saiqulhaq/dynamic_links,8cd8984b1205ca62cbd111fe6cd0ee8395c6f814
https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/43,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1665801004,saiqulhaq,76acfb1a8d3d58a0ad32483f607beb8c74c187f8,f02a00c9e27d71eaac9d4e5668cca85dae978b74,"@@ -0,0 +1,8 @@
+class Ahoy::Event < ApplicationRecord
+  include Ahoy::QueryMethods
+
+  self.table_name = ""ahoy_events""
+
+  belongs_to :visit
+  belongs_to :user, optional: true",app/models/ahoy/event.rb,2024-07-04 14:38:49+00:00,2024-07-04T14:40:07Z,"why there is a relation to `user`?
I think we don't have `user` model",,,,7.0,7,RIGHT,7,7.0,line,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/43,saiqulhaq/dynamic_links,8cd8984b1205ca62cbd111fe6cd0ee8395c6f814
https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/43,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/comments/1665802061,saiqulhaq,76acfb1a8d3d58a0ad32483f607beb8c74c187f8,f02a00c9e27d71eaac9d4e5668cca85dae978b74,"@@ -0,0 +1,62 @@
+class CreateAhoyVisitsAndEvents < ActiveRecord::Migration[7.1]
+  def change
+    create_table :ahoy_visits do |t|
+      t.string :visit_token
+      t.string :visitor_token
+
+      # the rest are recommended but optional
+      # simply remove any you don't want
+
+      # user
+      t.references :user",db/migrate/20240529173554_create_ahoy_visits_and_events.rb,2024-07-04 14:39:47+00:00,2024-07-04T14:40:08Z,"there is no `user` object in this gem
![image](https://github.com/saiqulhaq/dynamic_links/assets/1275215/185963ae-b4ba-4afa-bd93-248cbc651255)
",,,,11.0,11,RIGHT,11,11.0,line,https://api.github.com/repos/saiqulhaq/dynamic_links/pulls/43,saiqulhaq/dynamic_links,8cd8984b1205ca62cbd111fe6cd0ee8395c6f814
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/455,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1868119732,ttngu207,60f33dd71ff0bca2a59d3d64ead36afd8ba16b4f,b2cd47953177a701b4f531528ad09c9a3f2aee40,"@@ -1,93 +1,89 @@
 # DataJoint Pipeline for Project Aeon
 
-This pipeline models the data organization and data flow custom-built for Project Aeon. You can find Aeon acquisition system here: [aeon_aquisition](https://github.com/SainsburyWellcomeCentre/aeon_acquisition)
+This DataJoint pipeline models the data organization and data flow tailored to the project's Aeon requirements. You can access the Aeon acquisition system here: [aeon_aquisition](https://github.com/SainsburyWellcomeCentre/aeon_acquisition)
 
 
-## Pipeline architecture
+## Pipeline Architecture
 
-The diagram below shows the high level overview of the diagram (only the subset of the tables that are most relevant).
+The following diagrams provide a high-level overview of the pipeline's components and processes:
 
-![datajoint_pipeline](./docs/datajoint_overview_diagram.svg)
+The diagram below illustrates the structure of the **acquisition-related tasks within the pipeline**, focusing on the most relevant subset of tables.
 
+<img src=""./docs/datajoint_overview_acquisition_related_diagram.svg"" width=""800"" height=""400"" />
 
-The diagram below shows the analysis portion of the pipeline (work in progress).
+The diagram below represents the **data stream flow within the pipeline**, highlighting the subset of tables critical to understanding the process.
 
-![datajoint_analysis_pipeline](./docs/datajoint_analysis_diagram.svg)
+<img src=""./docs/datajoint_overview_data_stream_diagram.svg"" width=""12000"" height=""100"" />  
 
+The diagram below illustrates the **Pyrat synchronization process within the pipeline**, highlighting the key tables involved in syncing data across different components.
 
-From the diagram above, we can see that the pipeline is organized in layers of
-tables, going top down, from `lookup`-tier (in gray) and `manual`-tier (in green) tables
-to `imported`-tier (in purple) and `computed`-tier (in red) tables.
+<img src=""./docs/datajoint_overview_pyrat_related_diagram.svg"" width=""200"" height=""200"" />
+
+The diagram below shows the **analysis portion of the pipeline**.
+
+<img src=""./docs/datajoint_analysis_diagram.svg"" width=""800"" height=""400"" />
+
+
+The pipeline is structured into hierarchical layers of tables, which are depicted in the diagrams above. These layers include:
+
++ `lookup`-tier tables (gray): Define static reference information
++ `manual`-tier tables (green): Contain user-inputted data
++ `imported`-tier tables (purple): Store data ingested from external sources
++ `computed`-tier tables (red): Represent results of automated computations
+
+Data flows through the pipeline in a top-down manner, driven by a combination of ingestion and computation routines. This layered organization facilitates efficient data processing and modular analysis.
 
-Such is also the way the data flows through the pipeline, by a combination of ingestion and
-computation routines.
 
 ## Core tables
 
 #### Experiment and data acquisition
 
-1. `Experiment` - the `aquisition.Experiment` table stores meta information about the experiments
++ `Experiment` - the `aquisition.Experiment` table stores meta information about the experiments
 done in Project Aeon, with secondary information such as the lab/room the experiment is carried out,
 which animals participating, the directory storing the raw data, etc.
 
-2. `Epoch` - A recording period reflecting on/off of the hardware acquisition system.
++ `Epoch` - A recording period reflecting on/off of the hardware acquisition system.
 The `aquisition.Epoch` table records all acquisition epochs and their associated configuration for
 any particular experiment (in the above `aquisition.Experiment` table).
 
-3.`Chunk` - the raw data are acquired by Bonsai and stored as
++ `Chunk` - the raw data are acquired by Bonsai and stored as
 a collection of files every one hour - we call this one-hour a time chunk.
 The `aquisition.Chunk` table records all time chunks and their associated raw data files for
 any particular experiment (in the above `aquisition.Experiment` table). A chunk must belong to one epoch.
 
-#### Devices
-
-5. `ExperimentCamera` - the cameras and associated specifications used for this experiment -
-e.g. camera serial number, frame rate, location, time of installation and removal, etc.
-
-6. `ExperimentFoodPatch` - the food-patches and associated specifications used for this experiment -
-e.g. patch serial number, sampling rate of the wheel, location, time of installation and removal, etc.
-
-7. `ExperimentWeightScale` - the scales for measuring animal weights, usually placed at the nest, one per nest
-
-#### Data streams
-
-8. `FoodPatchEvent` - all events (e.g. pellet triggered, pellet delivered, etc.)
-from a particular `ExperimentFoodPatch`
+#### Position data
 
-9. `FoodPatchWheel` - wheel data (angle, intensity) from a particular `ExperimentFoodPatch`
++ `qc.CameraQC` - quality control procedure applied to each `ExperimentCamera` (e.g. missing frame, etc.)
 
-10. `WheelState` - wheel states (threshold, d1, delta) associated with a given `ExperimentFoodPatch`
++ `tracking.SLEAPTracking` - position tracking for object(s), from a particular `VideoSource` per chunk",aeon/dj_pipeline/README.md,2024-12-03 17:20:00+00:00,2024-12-03T17:20:00Z,"This is good.
Please expand more on the 2 part tables
- `PoseIdentity` - identified Subject (i.e. Identity) and stores the name of the body part used as ""anchor_part""
- `Part` - inferred x,y position over time for all body parts from SLEAP model ",,,,,58,RIGHT,88,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/455,SainsburyWellcomeCentre/aeon_mecha,6ed933aef30449bd8d50ead67d82a2e7a5be8927
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/402,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1766872761,lochhh,6bacc43e93826f9a3ffa8e1c8c9189abc0bf4c14,1de5c2554cb7254c54031370845031c61cb7408b,"@@ -44,13 +44,6 @@ def ingest_epochs_chunks():
         acquisition.Chunk.ingest_chunks(experiment_name)
 
 
-def ingest_environment_visits():",aeon/dj_pipeline/populate/worker.py,2024-09-19 13:46:52+00:00,2024-09-19T13:46:52Z,Remove also https://github.com/SainsburyWellcomeCentre/aeon_mecha/blob/6bacc43e93826f9a3ffa8e1c8c9189abc0bf4c14/aeon/dj_pipeline/populate/worker.py#L59,,,,47.0,47,LEFT,4,4.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/402,SainsburyWellcomeCentre/aeon_mecha,a889dba13c07c7eb6142a8265b8d8de8c60cef9c
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820592131,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -29,11 +29,15 @@
 def gen_hex_grad(hex_col, vals, min_l=0.3):
     """"""Generates an array of hex color values based on a gradient defined by unit-normalized values.""""""
     # Convert hex to rgb to hls
-    h, l, s = rgb_to_hls(*[int(hex_col.lstrip(""#"")[i : i + 2], 16) / 255 for i in (0, 2, 4)])  # noqa: E741
+    h, ll, s = rgb_to_hls(",aeon/analysis/block_plotting.py,2024-10-29 11:08:19+00:00,2024-10-29T11:08:19Z," E741: ambiguous variable name -> Renamed the variable from `l` to `ll` in `gen_hex_grad` in `aeon/analysis/block_plotting.py`.
",,,,,32,RIGHT,5,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820593406,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -55,19 +59,21 @@ def conv2d(arr, kernel):
 
 def gen_subject_colors_dict(subject_names):
     """"""Generates a dictionary of subject colors based on a list of subjects.""""""
-    return {s: c for s, c in zip(subject_names, subject_colors)}
+    return dict(zip(subject_names, subject_colors, strict=False))",aeon/analysis/block_plotting.py,2024-10-29 11:09:10+00:00,2024-10-29T11:09:10Z,Refactored to dict,,,,62.0,62,RIGHT,24,30.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820593778,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -55,19 +59,21 @@ def conv2d(arr, kernel):
 
 def gen_subject_colors_dict(subject_names):
     """"""Generates a dictionary of subject colors based on a list of subjects.""""""
-    return {s: c for s, c in zip(subject_names, subject_colors)}
+    return dict(zip(subject_names, subject_colors, strict=False))
 
 
 def gen_patch_style_dict(patch_names):
-    """"""Based on a list of patches, generates a dictionary of:
+    """"""Based on a list of patches, generates a dictionary of the following items.
+
     - patch_colors_dict: patch name to color
     - patch_markers_dict: patch name to marker
     - patch_symbols_dict: patch name to symbol
     - patch_linestyles_dict: patch name to linestyle
+
     """"""
     return {
-        ""colors"": {p: c for p, c in zip(patch_names, patch_colors)},
-        ""markers"": {p: m for p, m in zip(patch_names, patch_markers)},
-        ""symbols"": {p: s for p, s in zip(patch_names, patch_markers_symbols)},
-        ""linestyles"": {p: ls for p, ls in zip(patch_names, patch_markers_linestyles)},
+        ""colors"": dict(zip(patch_names, patch_colors, strict=False)),",aeon/analysis/block_plotting.py,2024-10-29 11:09:24+00:00,2024-10-29T11:09:25Z,Refactored to dict.,,,,77.0,75,RIGHT,42,54.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820595194,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -23,11 +27,11 @@ def get_schema_name(name) -> str:
 
 def dict_to_uuid(key) -> uuid.UUID:
     """"""Given a dictionary `key`, returns a hash string as UUID.""""""
-    hashed = hashlib.md5()
+    hashed = hashlib.sha256()",aeon/dj_pipeline/__init__.py,2024-10-29 11:10:16+00:00,2024-10-29T11:10:17Z,Security: Replaced `hashlib.md5` with `hashlib.sha256` due to known vulnerabilities in the MD5 hashing algorithm. ,,,,,30,RIGHT,22,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820596662,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -57,5 +68,5 @@ def fetch_stream(query, drop_pk=True):
         from .utils import streams_maker
 
         streams = dj.VirtualModule(""streams"", streams_maker.schema_name)
-    except:
+    except ImportError:",aeon/dj_pipeline/__init__.py,2024-10-29 11:11:23+00:00,2024-10-29T11:11:23Z,bare-except (E722) fixed,,,,,71,RIGHT,61,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820597621,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -145,7 +146,8 @@ def get_data_directory(cls, experiment_key, directory_type=""raw"", as_posix=False
 
         dir_path = pathlib.Path(dir_path)
         if dir_path.exists():
-            assert dir_path.is_relative_to(paths.get_repository_path(repo_name))
+            if not dir_path.is_relative_to(paths.get_repository_path(repo_name)):",aeon/dj_pipeline/acquisition.py,2024-10-29 11:12:06+00:00,2024-10-29T11:12:06Z,Replaced assertions with exceptions to ensure expected behavior in all scenarios.,,,,151.0,149,RIGHT,67,78.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820602066,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -234,17 +255,26 @@ def make(self, key):
             )
 
             if depletion_state_df.empty:
-                raise ValueError(f""No depletion state data found for block {key} - patch: {patch_name}"")
+                raise ValueError(
+                    f""No depletion state data found for block {key} - patch: {patch_name}""
+                )
 
-            encoder_df[""distance_travelled""] = -1 * analysis_utils.distancetravelled(encoder_df.angle)
+            encoder_df[""distance_travelled""] = -1 * analysis_utils.distancetravelled(
+                encoder_df.angle
+            )
 
             if len(depletion_state_df.rate.unique()) > 1:
-                # multiple patch rates per block is unexpected, log a note and pick the first rate to move forward
+                # multiple patch rates per block is unexpected
+                # log a note and pick the first rate to move forward
                 AnalysisNote.insert1(
                     {
-                        ""note_timestamp"": datetime.utcnow(),
+                        ""note_timestamp"": datetime.now(timezone.utc),",aeon/dj_pipeline/analysis/block_analysis.py,2024-10-29 11:15:26+00:00,2024-10-29T12:00:50Z,Fix deprecated `datetime.utcnow()`,,,,,271,RIGHT,153,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820604679,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -555,46 +613,75 @@ def make(self, key):
         for subject_name in subject_names:
             # Get sum of subj cum wheel dists and cum in patch time
             all_cum_dist = np.sum(
-                [all_subj_patch_pref_dict[p][subject_name][""cum_dist""][-1] for p in patch_names]
+                [
+                    all_subj_patch_pref_dict[p][subject_name][""cum_dist""][-1]
+                    for p in patch_names
+                ]
             )
             all_cum_time = np.sum(
-                [all_subj_patch_pref_dict[p][subject_name][""cum_time""][-1] for p in patch_names]
+                [
+                    all_subj_patch_pref_dict[p][subject_name][""cum_time""][-1]
+                    for p in patch_names
+                ]
             )
             for patch_name in patch_names:
                 cum_pref_dist = (
-                    all_subj_patch_pref_dict[patch_name][subject_name][""cum_dist""] / all_cum_dist
+                    all_subj_patch_pref_dict[patch_name][subject_name][""cum_dist""]
+                    / all_cum_dist
+                )
+                CUM_PREF_DIST_MIN = 1e-3",aeon/dj_pipeline/analysis/block_analysis.py,2024-10-29 11:17:05+00:00,2024-10-29T12:00:50Z," PLR2004: Replaced magic values with constant variables.
",,,,,632,RIGHT,396,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820608209,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1600,19 +1841,29 @@ def get_threshold_associated_pellets(patch_key, start, end):
         )
 
     # Step 2 - Remove invalid rows (back-to-back events)
-    # pellet delivery trigger - time difference is less than 1.2 seconds
-    invalid_rows = delivered_pellet_df.index.to_series().diff().dt.total_seconds() < 1.2
+    BTB_TIME_DIFF = (",aeon/dj_pipeline/analysis/block_analysis.py,2024-10-29 11:19:42+00:00,2024-10-29T12:00:50Z," PLR2004: Replaced magic values with constant variables.
",,,,,1844,RIGHT,1139,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820609472,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1722,38 +1985,58 @@ def get_foraging_bouts(
         spun_indices = np.where(diffs > wheel_spun_thresh)
         patch_spun[spun_indices[1]] = patch_names[spun_indices[0]]
         patch_spun_df = pd.DataFrame(
-            {""cum_wheel_dist"": comb_cum_wheel_dist, ""patch_spun"": patch_spun}, index=wheel_ts
+            {""cum_wheel_dist"": comb_cum_wheel_dist, ""patch_spun"": patch_spun},
+            index=wheel_ts,
         )
         wheel_s_r = pd.Timedelta(wheel_ts[1] - wheel_ts[0], unit=""ns"")
         max_inactive_win_len = int(max_inactive_time / wheel_s_r)
         # Find times when foraging
-        max_windowed_wheel_vals = patch_spun_df[""cum_wheel_dist""].shift(-(max_inactive_win_len - 1)).ffill()
-        foraging_mask = max_windowed_wheel_vals > (patch_spun_df[""cum_wheel_dist""] + min_wheel_movement)
+        max_windowed_wheel_vals = (
+            patch_spun_df[""cum_wheel_dist""].shift(-(max_inactive_win_len - 1)).ffill()
+        )
+        foraging_mask = max_windowed_wheel_vals > (
+            patch_spun_df[""cum_wheel_dist""] + min_wheel_movement
+        )
         # Discretize into foraging bouts
-        bout_start_indxs = np.where(np.diff(foraging_mask, prepend=0) == 1)[0] + (max_inactive_win_len - 1)
+        bout_start_indxs = np.where(np.diff(foraging_mask, prepend=0) == 1)[0] + (
+            max_inactive_win_len - 1
+        )
         n_samples_in_1s = int(1 / wheel_s_r.total_seconds())
         bout_end_indxs = (
             np.where(np.diff(foraging_mask, prepend=0) == -1)[0]
             + (max_inactive_win_len - 1)
             + n_samples_in_1s
         )
-        bout_end_indxs[-1] = min(bout_end_indxs[-1], len(wheel_ts) - 1)  # ensure last bout ends in block
+        bout_end_indxs[-1] = min(
+            bout_end_indxs[-1], len(wheel_ts) - 1
+        )  # ensure last bout ends in block
         # Remove bout that starts at block end
         if bout_start_indxs[-1] >= len(wheel_ts):
             bout_start_indxs = bout_start_indxs[:-1]
             bout_end_indxs = bout_end_indxs[:-1]
-        assert len(bout_start_indxs) == len(bout_end_indxs)
-        bout_durations = (wheel_ts[bout_end_indxs] - wheel_ts[bout_start_indxs]).astype(  # in seconds
+        if len(bout_start_indxs) != len(bout_end_indxs):",aeon/dj_pipeline/analysis/block_analysis.py,2024-10-29 11:20:35+00:00,2024-10-29T12:00:50Z,S101: Replaced assertions with exceptions to ensure expected behavior in all scenarios,,,,1827.0,2017,RIGHT,1267,505.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820610908,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -131,7 +143,7 @@ def ingest_environment_visits(experiment_names: list | None = None):
             .fetch(""last_visit"")
         )
         start = min(subjects_last_visits) if len(subjects_last_visits) else ""1900-01-01""
-        end = datetime.datetime.now() if start else ""2200-01-01""
+        end = datetime.now(timezone.utc) if start else ""2200-01-01""",aeon/dj_pipeline/analysis/visit.py,2024-10-29 11:21:37+00:00,2024-10-29T12:00:50Z,Updated `datetime.utcnow()` due to deprecation issue,,,,,146,RIGHT,92,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820612055,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,23 +1,27 @@
+""""""Module for visit analysis.""""""
+
 import datetime
 from datetime import time
 
 import datajoint as dj
 import numpy as np
 import pandas as pd
 
-from aeon.dj_pipeline import get_schema_name
 from aeon.dj_pipeline import acquisition, lab, tracking
 from aeon.dj_pipeline.analysis.visit import (
     Visit,
     VisitEnd,
-    get_maintenance_periods,
     filter_out_maintenance_periods,
+    get_maintenance_periods,
 )
 
 logger = dj.logger
 # schema = dj.schema(get_schema_name(""analysis""))
 schema = dj.schema()
 
+# Constants values",aeon/dj_pipeline/analysis/visit_analysis.py,2024-10-29 11:22:31+00:00,2024-10-29T12:00:50Z, PLR2004: Replaced magic values with constant variables.,,,,23.0,22,RIGHT,24,25.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820613090,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -83,33 +86,37 @@ class TimeSlice(dj.Part):
 
     @property
     def key_source(self):
-        """"""Chunk for all visits:
+        """"""Chunk for all visits as the following conditions.
+
         + visit_start during this Chunk - i.e. first chunk of the visit
         + visit_end during this Chunk - i.e. last chunk of the visit
         + chunk starts after visit_start and ends before visit_end (or NOW() - i.e. ongoing visits).
         """"""
         return (
-            Visit.join(VisitEnd, left=True).proj(visit_end=""IFNULL(visit_end, NOW())"") * acquisition.Chunk
+            Visit.join(VisitEnd, left=True).proj(visit_end=""IFNULL(visit_end, NOW())"")
+            * acquisition.Chunk
             & acquisition.SubjectEnterExit
             & [
                 ""visit_start BETWEEN chunk_start AND chunk_end"",
                 ""visit_end BETWEEN chunk_start AND chunk_end"",
                 ""chunk_start >= visit_start AND chunk_end <= visit_end"",
             ]
-            & ""chunk_start < chunk_end""  # in some chunks, end timestamp comes before start (timestamp error)
+            & ""chunk_start < chunk_end""
+            # in some chunks, end timestamp comes before start (timestamp error)
         )
 
     def make(self, key):
-        chunk_start, chunk_end = (acquisition.Chunk & key).fetch1(""chunk_start"", ""chunk_end"")
+        """"""Populate VisitSubjectPosition for each visit.""""""
+        chunk_start, chunk_end = (acquisition.Chunk & key).fetch1(
+            ""chunk_start"", ""chunk_end""
+        )
 
         # -- Determine the time to start time_slicing in this chunk
-        if chunk_start < key[""visit_start""] < chunk_end:
-            # For chunk containing the visit_start - i.e. first chunk of this visit
-            start_time = key[""visit_start""]
-        else:
-            # For chunks after the first chunk of this visit
-            start_time = chunk_start
-
+        start_time = (",aeon/dj_pipeline/analysis/visit_analysis.py,2024-10-29 11:23:20+00:00,2024-10-29T12:00:50Z, SIM108: Refactored `visit_analysis` to use the ternary operator.,,,,113.0,115,RIGHT,81,72.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820613962,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -190,17 +202,27 @@ def make(self, key):
 
     @classmethod
     def get_position(cls, visit_key=None, subject=None, start=None, end=None):
-        """"""Given a key to a single Visit, return a Pandas DataFrame for the position data of the subject for the specified Visit time period.""""""
+        """"""Return a Pandas df of the subject's position data for a specified Visit given its key.
+
+        Given a key to a single Visit, return a Pandas DataFrame for
+        the position data of the subject for the specified Visit time period.
+        """"""
         if visit_key is not None:
-            assert len(Visit & visit_key) == 1
+            if len(Visit & visit_key) != 1:",aeon/dj_pipeline/analysis/visit_analysis.py,2024-10-29 11:23:59+00:00,2024-10-29T12:00:50Z,S101: Replaced assertions with exceptions to ensure expected behavior in all scenarios,,,,216.0,211,RIGHT,126,113.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820617034,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -190,17 +202,27 @@ def make(self, key):
 
     @classmethod
     def get_position(cls, visit_key=None, subject=None, start=None, end=None):
-        """"""Given a key to a single Visit, return a Pandas DataFrame for the position data of the subject for the specified Visit time period.""""""
+        """"""Return a Pandas df of the subject's position data for a specified Visit given its key.
+
+        Given a key to a single Visit, return a Pandas DataFrame for
+        the position data of the subject for the specified Visit time period.
+        """"""
         if visit_key is not None:
-            assert len(Visit & visit_key) == 1
+            if len(Visit & visit_key) != 1:
+                raise ValueError(
+                    ""The `visit_key` must correspond to exactly one Visit.""
+                )
             start, end = (
-                Visit.join(VisitEnd, left=True).proj(visit_end=""IFNULL(visit_end, NOW())"") & visit_key
+                Visit.join(VisitEnd, left=True).proj(
+                    visit_end=""IFNULL(visit_end, NOW())""
+                )
+                & visit_key
             ).fetch1(""visit_start"", ""visit_end"")
             subject = visit_key[""subject""]
         elif all((subject, start, end)):
-            start = start
-            end = end
-            subject = subject
+            start = start  # noqa PLW0127",aeon/dj_pipeline/analysis/visit_analysis.py,2024-10-29 11:26:10+00:00,2024-10-29T12:00:50Z,PLW0127: Variables are assigned to themselves. Could this code block be improved?,,,,,223,RIGHT,142,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820617555,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -282,12 +309,16 @@ def make(self, key):
                 subject=key[""subject""], start=day_start, end=day_end
             )
             # filter out maintenance period based on logs
-            position = filter_out_maintenance_periods(position, maintenance_period, day_end)
+            position = filter_out_maintenance_periods(
+                position, maintenance_period, day_end
+            )
 
             # filter for objects of the correct size
-            valid_position = (position.area > 0) & (position.area < 1000)
+            valid_position = (position.area > MIN_AREA) & (position.area < MAX_AREA)",aeon/dj_pipeline/analysis/visit_analysis.py,2024-10-29 11:26:31+00:00,2024-10-29T12:00:50Z,PLR2004: Replaced magic values with constant variables.,,,,306.0,317,RIGHT,190,156.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820618145,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -428,12 +466,18 @@ def make(self, key):
                 subject=key[""subject""], start=day_start, end=day_end
             )
             # filter out maintenance period based on logs
-            position = filter_out_maintenance_periods(position, maintenance_period, day_end)
+            position = filter_out_maintenance_periods(
+                position, maintenance_period, day_end
+            )
             # filter for objects of the correct size",aeon/dj_pipeline/analysis/visit_analysis.py,2024-10-29 11:26:59+00:00,2024-10-29T12:00:50Z,PLR2004: Replaced magic values with constant variables.,,,,451.0,472,RIGHT,273,189.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820625134,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -148,19 +162,21 @@ def fixID(subjid, valid_ids=None, valid_id_file=None):
     if "";"" in subjid:
         subjidA, subjidB = subjid.split("";"")
         return (
-            f""{fixID(subjidA.strip(), valid_ids=valid_ids)};{fixID(subjidB.strip(), valid_ids=valid_ids)}""
+            f""{fixID(subjidA.strip(), valid_ids=valid_ids)};""
+            f""{fixID(subjidB.strip(), valid_ids=valid_ids)}""
         )
 
     if ""vs"" in subjid:
         subjidA, tmp, subjidB = subjid.split("" "")[1:]
         return (
-            f""{fixID(subjidA.strip(), valid_ids=valid_ids)};{fixID(subjidB.strip(), valid_ids=valid_ids)}""
+            f""{fixID(subjidA.strip(), valid_ids=valid_ids)};""
+            f""{fixID(subjidB.strip(), valid_ids=valid_ids)}""
         )
 
     try:
         ld = [jl.levenshtein_distance(subjid, x[-len(subjid) :]) for x in valid_ids]
         return valid_ids[np.argmin(ld)]
-    except:
+    except ValueError:",aeon/dj_pipeline/create_experiments/create_socialexperiment_0.py,2024-10-29 11:32:25+00:00,2024-10-29T12:00:50Z,Fixed bare except (E722) ,,,,170.0,179,RIGHT,84,51.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820627416,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,9 +1,14 @@
+""""""This module defines the workers for the AEON pipeline.""""""
+
 import datajoint as dj
-from datajoint_utilities.dj_worker import DataJointWorker, ErrorLog, WorkerLog, RegisteredWorker
+from datajoint_utilities.dj_worker import (
+    DataJointWorker,
+    ErrorLog,
+    WorkerLog,
+)",aeon/dj_pipeline/populate/worker.py,2024-10-29 11:34:01+00:00,2024-10-29T12:00:50Z,Removed `RegisteredWorker` since it is unused,,,,,8,RIGHT,9,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820630817,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,14 +1,18 @@
-""""""July 2022
-Upgrade all timestamps longblob fields with datajoint 0.13.7.
-""""""
+""""""July 2022. Upgrade all timestamps longblob fields with datajoint 0.13.7.""""""
 
 from datetime import datetime
 
 import datajoint as dj
 import numpy as np
 from tqdm import tqdm
 
-assert dj.__version__ >= ""0.13.7""
+logger = dj.logger
+
+
+if dj.__version__ < ""0.13.7"":",aeon/dj_pipeline/scripts/update_timestamps_longblob.py,2024-10-29 11:36:47+00:00,2024-10-29T12:00:50Z,S101: Replaced assertions with exceptions,,,,12.0,12,RIGHT,16,16.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820631210,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -54,7 +65,10 @@ def main():
                         if not len(ts) or isinstance(ts[0], np.datetime64):
                             TimestampFix.insert1(fix_key)
                             continue
-                        assert isinstance(ts[0], datetime)
+                        if not isinstance(ts[0], datetime):",aeon/dj_pipeline/scripts/update_timestamps_longblob.py,2024-10-29 11:37:04+00:00,2024-10-29T12:00:50Z,S101: Replaced assertions with exceptions,,,,60.0,68,RIGHT,47,34.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820637111,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -450,7 +486,7 @@ def get_pyrat_data(endpoint: str, params: dict = None, **kwargs):
     if params is not None:
         params_str_list = []
         for k, v in params.items():
-            if isinstance(v, (list, tuple)):
+            if isinstance(v, (list | tuple)):",aeon/dj_pipeline/subject.py,2024-10-29 11:41:33+00:00,2024-10-29T12:00:50Z,"UP038: Used the new X | Y syntax for isinstance calls, as introduced in Python 3.10.",,,,483.0,489,RIGHT,231,174.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820637748,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -461,7 +497,9 @@ def get_pyrat_data(endpoint: str, params: dict = None, **kwargs):
 
     response = session.get(base_url + endpoint + params_str, **kwargs)
 
-    if response.status_code != 200:
+    RESPONSE_STATUS_CODE_OK = 200",aeon/dj_pipeline/subject.py,2024-10-29 11:42:04+00:00,2024-10-29T12:00:50Z,PLR2004: Replaced magic values with constant variables.,,,,494.0,500,RIGHT,240,183.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820638624,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -224,15 +256,20 @@ def make(self, key):
 
 # ---------- HELPER ------------------
 
+TARGET_LENGTH = 2",aeon/dj_pipeline/tracking.py,2024-10-29 11:42:50+00:00,2024-10-29T12:00:50Z,PLR2004: Replaced magic values with constant variables.,,,,,259,RIGHT,134,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820638993,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -224,15 +256,20 @@ def make(self, key):
 
 # ---------- HELPER ------------------
 
+TARGET_LENGTH = 2
+
 
 def compute_distance(position_df, target, xcol=""x"", ycol=""y""):
-    assert len(target) == 2
+    """"""Compute the distance of the position data from a target point.""""""
+    if len(target) != TARGET_LENGTH:",aeon/dj_pipeline/tracking.py,2024-10-29 11:43:07+00:00,2024-10-29T12:00:50Z,S101: Replaced assertions with exceptions ,,,,,264,RIGHT,140,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820640077,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -141,15 +155,23 @@ def extract_epoch_config(experiment_name: str, devices_schema: DotMap, metadata_
     if isinstance(commit, float) and np.isnan(commit):
         commit = epoch_config[""metadata""][""Revision""]
 
-    assert commit, f'Neither ""Commit"" nor ""Revision"" found in {metadata_yml_filepath}'
+    if not commit:",aeon/dj_pipeline/utils/load_metadata.py,2024-10-29 11:44:00+00:00,2024-10-29T12:00:50Z,S101: Replaced assertions with exceptions ,,,,147.0,158,RIGHT,83,64.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820641373,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -44,14 +46,14 @@ def find_root_directory(
 
     Returns:
         pathlib.Path: The full path to the discovered root directory.
-    """"""
+    """"""  # noqa E501
     full_path = pathlib.Path(full_path)
 
     if not full_path.exists():
         raise FileNotFoundError(f""{full_path} does not exist!"")
 
     # turn to list if only a single root directory is provided
-    if isinstance(root_directories, (str, pathlib.Path)):
+    if isinstance(root_directories, (str | pathlib.Path)):",aeon/dj_pipeline/utils/paths.py,2024-10-29 11:45:04+00:00,2024-10-29T12:00:50Z,"UP038: Used the new X | Y syntax for isinstance calls, as introduced in Python 3.10.",,,,56.0,56,RIGHT,19,20.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820641889,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -61,7 +63,8 @@ def find_root_directory(
             if pathlib.Path(root_dir) in set(full_path.parents)
         )
 
-    except StopIteration:
+    except StopIteration as err:",aeon/dj_pipeline/utils/paths.py,2024-10-29 11:45:30+00:00,2024-10-29T12:00:50Z,B904: Enhanced exception handling by using as err and raising exceptions with raise ... from err to differentiate errors.,,,,66.0,66,RIGHT,28,29.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820643418,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -511,24 +566,30 @@ def plot_visit_time_distribution(visit_key, freq=""D""):
     return fig
 
 
-def _get_region_data(visit_key, attrs=[""in_nest"", ""in_arena"", ""in_corridor"", ""in_patch""]):
+def _get_region_data(visit_key, attrs=None):
     """"""Retrieve region data from VisitTimeDistribution tables.
 
     Args:
         visit_key (dict): Key from the Visit table
-        attrs (list, optional): List of column names (in VisitTimeDistribution tables) to retrieve. Defaults to all.
+        attrs (list, optional): List of column names (in VisitTimeDistribution tables) to retrieve.
+        Defaults is None, which will create a new list with the desired default values inside the function.
 
     Returns:
         region (pd.DataFrame): Timestamped region info
     """"""
+    if attrs is None:",aeon/dj_pipeline/utils/plotting.py,2024-10-29 11:46:44+00:00,2024-10-29T12:00:50Z,B006: Fixed mutable default argument in plotting.py.,,,,548.0,580,RIGHT,306,158.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820644944,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -134,30 +147,42 @@ class DeviceDataStream(dj.Imported):
 
         @property
         def key_source(self):
-            f""""""
-            Only the combination of Chunk and {device_type} with overlapping time
-            +  Chunk(s) that started after {device_type} install time and ended before {device_type} remove time
-            +  Chunk(s) that started after {device_type} install time for {device_type} that are not yet removed
+            """"""Only the combination of Chunk and device_type with overlapping time.",aeon/dj_pipeline/utils/streams_maker.py,2024-10-29 11:47:50+00:00,2024-10-29T12:00:50Z,"B021: Removed dynamic references and made the docstring static in DeviceDataStream.key_source, ensuring it remains informative.",,,,,150,RIGHT,105,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820646910,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -209,6 +235,10 @@ def main(create_tables=True):
                 device_table_def = inspect.getsource(table_class).lstrip()
                 full_def = ""@schema \n"" + device_table_def + ""\n\n""
                 f.write(full_def)
+    else:",aeon/dj_pipeline/utils/streams_maker.py,2024-10-29 11:49:13+00:00,2024-10-29T12:00:50Z,Enhanced the condition here by adding an `else`,,,,,238,RIGHT,165,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820647368,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -22,8 +24,8 @@ def retrieve_video_frames(
 ):
     """"""Retrive video trames from the raw data directory.""""""
     raw_data_dir = Path(raw_data_dir)
-    assert raw_data_dir.exists()
-
+    if not raw_data_dir.exists():",aeon/dj_pipeline/utils/video.py,2024-10-29 11:49:34+00:00,2024-10-29T12:00:50Z,S101: Replaced assertions with exceptions ,,,,27.0,27,RIGHT,12,12.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820650333,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -138,22 +159,21 @@ def read(self, file):
 
 
 class JsonList(Reader):
-    """"""Extracts data from json list (.jsonl) files, where the key ""seconds""
-    stores the Aeon timestamp, in seconds.
-    """"""
+    """"""Extracts data from .jsonl files, where the key ""seconds"" stores the Aeon timestamp (s).""""""
 
     def __init__(self, pattern, columns=(), root_key=""value"", extension=""jsonl""):
+        """"""Initialize the object with the specified pattern, columns, and root key.""""""
         super().__init__(pattern, columns, extension)
         self.columns = columns
         self.root_key = root_key
 
     def read(self, file):
         """"""Reads data from the specified jsonl file.""""""
-        with open(file, ""r"") as f:
+        with open(file) as f:",aeon/io/reader.py,2024-10-29 11:51:59+00:00,2024-10-29T12:00:50Z,UP015 Unnecessary open mode parameters,,,,160.0,172,RIGHT,107,88.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820652338,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -138,22 +159,21 @@ def read(self, file):
 
 
 class JsonList(Reader):
-    """"""Extracts data from json list (.jsonl) files, where the key ""seconds""
-    stores the Aeon timestamp, in seconds.
-    """"""
+    """"""Extracts data from .jsonl files, where the key ""seconds"" stores the Aeon timestamp (s).""""""
 
     def __init__(self, pattern, columns=(), root_key=""value"", extension=""jsonl""):
+        """"""Initialize the object with the specified pattern, columns, and root key.""""""
         super().__init__(pattern, columns, extension)
         self.columns = columns
         self.root_key = root_key
 
     def read(self, file):
         """"""Reads data from the specified jsonl file.""""""
-        with open(file, ""r"") as f:
+        with open(file) as f:
             df = pd.read_json(f, lines=True)
         df.set_index(""seconds"", inplace=True)
         for column in self.columns:
-            df[column] = df[self.root_key].apply(lambda x: x[column])
+            df[column] = df[self.root_key].apply(lambda x, col=column: x[col])",aeon/io/reader.py,2024-10-29 11:53:32+00:00,2024-10-29T12:00:50Z,Refactor: Updated the `read` method in the `JsonList` class within `aeon/io/reader.py.`,,,,,176,RIGHT,112,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820655585,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,15 +1,17 @@
-import json
-import pandas as pd
+""""""This module contains the schema for the social_03 dataset.""""""
+",aeon/schema/social_03.py,2024-10-29 11:56:02+00:00,2024-10-29T12:00:50Z,deleted unused dependencies,,,,2.0,2,RIGHT,4,4.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820656508,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -47,17 +48,37 @@ def test_params():
 
 @pytest.fixture(autouse=True, scope=""session"")
 def dj_config():
-    """"""Configures DataJoint connection and loads custom settings.""""""
+    """"""Configures DataJoint connection and loads custom settings.
+
+    This fixture sets up the DataJoint configuration using the
+    'dj_local_conf.json' file. It raises FileNotFoundError if the file
+    does not exist, and KeyError if 'custom' is not found in the
+    DataJoint configuration.
+    """"""
     dj_config_fp = pathlib.Path(""dj_local_conf.json"")
-    assert dj_config_fp.exists()
+    if not dj_config_fp.exists():",tests/dj_pipeline/conftest.py,2024-10-29 11:56:46+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,59,RIGHT,22,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820656629,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -47,17 +48,37 @@ def test_params():
 
 @pytest.fixture(autouse=True, scope=""session"")
 def dj_config():
-    """"""Configures DataJoint connection and loads custom settings.""""""
+    """"""Configures DataJoint connection and loads custom settings.
+
+    This fixture sets up the DataJoint configuration using the
+    'dj_local_conf.json' file. It raises FileNotFoundError if the file
+    does not exist, and KeyError if 'custom' is not found in the
+    DataJoint configuration.
+    """"""
     dj_config_fp = pathlib.Path(""dj_local_conf.json"")
-    assert dj_config_fp.exists()
+    if not dj_config_fp.exists():
+        raise FileNotFoundError(
+            f""DataJoint configuration file not found: {dj_config_fp}""
+        )
     dj.config.load(dj_config_fp)
     dj.config[""safemode""] = False
-    assert ""custom"" in dj.config
-    dj.config[""custom""][""database.prefix""] = f""u_{dj.config['database.user']}_testsuite_""
+    if ""custom"" not in dj.config:",tests/dj_pipeline/conftest.py,2024-10-29 11:56:53+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,65,RIGHT,30,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820657240,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,33 +1,63 @@
-from pytest import mark
+""""""Tests for the acquisition pipeline.""""""
 
+import datajoint as dj
+import pytest",tests/dj_pipeline/test_acquisition.py,2024-10-29 11:57:17+00:00,2024-10-29T12:00:51Z,fixed import of pytest,,,,3.0,4,RIGHT,5,4.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820657620,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,33 +1,63 @@
-from pytest import mark
+""""""Tests for the acquisition pipeline.""""""
 
+import datajoint as dj
+import pytest
 
-@mark.ingestion
+logger = dj.logger
+
+
+@pytest.mark.ingestion
 def test_epoch_chunk_ingestion(test_params, pipeline, epoch_chunk_ingestion):
     acquisition = pipeline[""acquisition""]
-
-    assert (
-        len(acquisition.Epoch & {""experiment_name"": test_params[""experiment_name""]})
-        == test_params[""epoch_count""]
+    epoch_count = len(",tests/dj_pipeline/test_acquisition.py,2024-10-29 11:57:34+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,12,RIGHT,18,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820657843,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,33 +1,63 @@
-from pytest import mark
+""""""Tests for the acquisition pipeline.""""""
 
+import datajoint as dj
+import pytest
 
-@mark.ingestion
+logger = dj.logger
+
+
+@pytest.mark.ingestion
 def test_epoch_chunk_ingestion(test_params, pipeline, epoch_chunk_ingestion):
     acquisition = pipeline[""acquisition""]
-
-    assert (
-        len(acquisition.Epoch & {""experiment_name"": test_params[""experiment_name""]})
-        == test_params[""epoch_count""]
+    epoch_count = len(
+        acquisition.Epoch & {""experiment_name"": test_params[""experiment_name""]}
     )
-    assert (
-        len(acquisition.Chunk & {""experiment_name"": test_params[""experiment_name""]})
-        == test_params[""chunk_count""]
+    chunk_count = len(
+        acquisition.Chunk & {""experiment_name"": test_params[""experiment_name""]}
     )
+    if epoch_count != test_params[""epoch_count""]:
+        raise AssertionError(
+            f""Expected {test_params['epoch_count']} epochs, but got {epoch_count}.""
+        )
 
+    if chunk_count != test_params[""chunk_count""]:
+        raise AssertionError(
+            f""Expected {test_params['chunk_count']} chunks, but got {chunk_count}.""
+        )
 
-@mark.ingestion
-def test_experimentlog_ingestion(test_params, pipeline, epoch_chunk_ingestion, experimentlog_ingestion):
+
+@pytest.mark.ingestion
+def test_experimentlog_ingestion(
+    test_params, pipeline, epoch_chunk_ingestion, experimentlog_ingestion
+):
     acquisition = pipeline[""acquisition""]
 
-    assert (
-        len(acquisition.ExperimentLog.Message & {""experiment_name"": test_params[""experiment_name""]})
-        == test_params[""experiment_log_message_count""]
+    exp_log_message_count = len(",tests/dj_pipeline/test_acquisition.py,2024-10-29 11:57:45+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,35,RIGHT,49,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820658039,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,33 +1,63 @@
-from pytest import mark
+""""""Tests for the acquisition pipeline.""""""
 
+import datajoint as dj
+import pytest
 
-@mark.ingestion
+logger = dj.logger
+
+
+@pytest.mark.ingestion
 def test_epoch_chunk_ingestion(test_params, pipeline, epoch_chunk_ingestion):
     acquisition = pipeline[""acquisition""]
-
-    assert (
-        len(acquisition.Epoch & {""experiment_name"": test_params[""experiment_name""]})
-        == test_params[""epoch_count""]
+    epoch_count = len(
+        acquisition.Epoch & {""experiment_name"": test_params[""experiment_name""]}
     )
-    assert (
-        len(acquisition.Chunk & {""experiment_name"": test_params[""experiment_name""]})
-        == test_params[""chunk_count""]
+    chunk_count = len(
+        acquisition.Chunk & {""experiment_name"": test_params[""experiment_name""]}
     )
+    if epoch_count != test_params[""epoch_count""]:
+        raise AssertionError(
+            f""Expected {test_params['epoch_count']} epochs, but got {epoch_count}.""
+        )
 
+    if chunk_count != test_params[""chunk_count""]:
+        raise AssertionError(
+            f""Expected {test_params['chunk_count']} chunks, but got {chunk_count}.""
+        )
 
-@mark.ingestion
-def test_experimentlog_ingestion(test_params, pipeline, epoch_chunk_ingestion, experimentlog_ingestion):
+
+@pytest.mark.ingestion
+def test_experimentlog_ingestion(
+    test_params, pipeline, epoch_chunk_ingestion, experimentlog_ingestion
+):
     acquisition = pipeline[""acquisition""]
 
-    assert (
-        len(acquisition.ExperimentLog.Message & {""experiment_name"": test_params[""experiment_name""]})
-        == test_params[""experiment_log_message_count""]
+    exp_log_message_count = len(
+        acquisition.ExperimentLog.Message
+        & {""experiment_name"": test_params[""experiment_name""]}
     )
-    assert (
-        len(acquisition.SubjectEnterExit.Time & {""experiment_name"": test_params[""experiment_name""]})
-        == test_params[""subject_enter_exit_count""]
+    if exp_log_message_count != test_params[""experiment_log_message_count""]:
+        raise AssertionError(
+            f""Expected {test_params['experiment_log_message_count']} log messages,""
+            f""but got {exp_log_message_count}.""
+        )
+
+    subject_enter_exit_count = len(
+        acquisition.SubjectEnterExit.Time
+        & {""experiment_name"": test_params[""experiment_name""]}
     )
-    assert (
-        len(acquisition.SubjectWeight.WeightTime & {""experiment_name"": test_params[""experiment_name""]})
-        == test_params[""subject_weight_time_count""]
+    if subject_enter_exit_count != test_params[""subject_enter_exit_count""]:",tests/dj_pipeline/test_acquisition.py,2024-10-29 11:57:55+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,49,RIGHT,69,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820658303,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,26 +1,67 @@
-from pytest import mark
+""""""Tests for pipeline instantiation and experiment creation.""""""
 
+import datajoint as dj
+import pytest",tests/dj_pipeline/test_pipeline_instantiation.py,2024-10-29 11:58:09+00:00,2024-10-29T12:00:51Z,fixed import pytest,,,,3.0,4,RIGHT,5,4.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820658460,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,26 +1,67 @@
-from pytest import mark
+""""""Tests for pipeline instantiation and experiment creation.""""""
 
+import datajoint as dj
+import pytest
 
-@mark.instantiation
+logger = dj.logger
+
+
+@pytest.mark.instantiation
 def test_pipeline_instantiation(pipeline):
-    assert hasattr(pipeline[""acquisition""], ""FoodPatchEvent"")
-    assert hasattr(pipeline[""lab""], ""Arena"")
-    assert hasattr(pipeline[""qc""], ""CameraQC"")
-    assert hasattr(pipeline[""report""], ""InArenaSummaryPlot"")
-    assert hasattr(pipeline[""subject""], ""Subject"")
-    assert hasattr(pipeline[""tracking""], ""CameraTracking"")
+    if not hasattr(pipeline[""acquisition""], ""FoodPatchEvent""):",tests/dj_pipeline/test_pipeline_instantiation.py,2024-10-29 11:58:17+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,11,RIGHT,19,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820658716,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,26 +1,67 @@
-from pytest import mark
+""""""Tests for pipeline instantiation and experiment creation.""""""
 
+import datajoint as dj
+import pytest
 
-@mark.instantiation
+logger = dj.logger
+
+
+@pytest.mark.instantiation
 def test_pipeline_instantiation(pipeline):
-    assert hasattr(pipeline[""acquisition""], ""FoodPatchEvent"")
-    assert hasattr(pipeline[""lab""], ""Arena"")
-    assert hasattr(pipeline[""qc""], ""CameraQC"")
-    assert hasattr(pipeline[""report""], ""InArenaSummaryPlot"")
-    assert hasattr(pipeline[""subject""], ""Subject"")
-    assert hasattr(pipeline[""tracking""], ""CameraTracking"")
+    if not hasattr(pipeline[""acquisition""], ""FoodPatchEvent""):
+        raise AssertionError(
+            ""Pipeline acquisition does not have 'FoodPatchEvent' attribute.""
+        )
+
+    if not hasattr(pipeline[""lab""], ""Arena""):
+        raise AssertionError(""Pipeline lab does not have 'Arena' attribute."")
+
+    if not hasattr(pipeline[""qc""], ""CameraQC""):
+        raise AssertionError(""Pipeline qc does not have 'CameraQC' attribute."")
+
+    if not hasattr(pipeline[""report""], ""InArenaSummaryPlot""):
+        raise AssertionError(
+            ""Pipeline report does not have 'InArenaSummaryPlot' attribute.""
+        )
 
+    if not hasattr(pipeline[""subject""], ""Subject""):
+        raise AssertionError(""Pipeline subject does not have 'Subject' attribute."")
 
-@mark.instantiation
+    if not hasattr(pipeline[""tracking""], ""CameraTracking""):
+        raise AssertionError(
+            ""Pipeline tracking does not have 'CameraTracking' attribute.""
+        )
+
+
+@pytest.mark.instantiation
 def test_experiment_creation(test_params, pipeline, experiment_creation):
     acquisition = pipeline[""acquisition""]
 
     experiment_name = test_params[""experiment_name""]
-    assert acquisition.Experiment.fetch1(""experiment_name"") == experiment_name
+    fetched_experiment_name = acquisition.Experiment.fetch1(""experiment_name"")",tests/dj_pipeline/test_pipeline_instantiation.py,2024-10-29 11:58:31+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,41,RIGHT,51,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820658854,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,26 +1,67 @@
-from pytest import mark
+""""""Tests for pipeline instantiation and experiment creation.""""""
 
+import datajoint as dj
+import pytest
 
-@mark.instantiation
+logger = dj.logger
+
+
+@pytest.mark.instantiation
 def test_pipeline_instantiation(pipeline):
-    assert hasattr(pipeline[""acquisition""], ""FoodPatchEvent"")
-    assert hasattr(pipeline[""lab""], ""Arena"")
-    assert hasattr(pipeline[""qc""], ""CameraQC"")
-    assert hasattr(pipeline[""report""], ""InArenaSummaryPlot"")
-    assert hasattr(pipeline[""subject""], ""Subject"")
-    assert hasattr(pipeline[""tracking""], ""CameraTracking"")
+    if not hasattr(pipeline[""acquisition""], ""FoodPatchEvent""):
+        raise AssertionError(
+            ""Pipeline acquisition does not have 'FoodPatchEvent' attribute.""
+        )
+
+    if not hasattr(pipeline[""lab""], ""Arena""):
+        raise AssertionError(""Pipeline lab does not have 'Arena' attribute."")
+
+    if not hasattr(pipeline[""qc""], ""CameraQC""):
+        raise AssertionError(""Pipeline qc does not have 'CameraQC' attribute."")
+
+    if not hasattr(pipeline[""report""], ""InArenaSummaryPlot""):
+        raise AssertionError(
+            ""Pipeline report does not have 'InArenaSummaryPlot' attribute.""
+        )
 
+    if not hasattr(pipeline[""subject""], ""Subject""):
+        raise AssertionError(""Pipeline subject does not have 'Subject' attribute."")
 
-@mark.instantiation
+    if not hasattr(pipeline[""tracking""], ""CameraTracking""):
+        raise AssertionError(
+            ""Pipeline tracking does not have 'CameraTracking' attribute.""
+        )
+
+
+@pytest.mark.instantiation
 def test_experiment_creation(test_params, pipeline, experiment_creation):
     acquisition = pipeline[""acquisition""]
 
     experiment_name = test_params[""experiment_name""]
-    assert acquisition.Experiment.fetch1(""experiment_name"") == experiment_name
+    fetched_experiment_name = acquisition.Experiment.fetch1(""experiment_name"")
+    if fetched_experiment_name != experiment_name:
+        raise AssertionError(
+            f""Expected experiment name '{experiment_name}', but got '{fetched_experiment_name}'.""
+        )
+
     raw_dir = (
-        acquisition.Experiment.Directory & {""experiment_name"": experiment_name, ""directory_type"": ""raw""}
+        acquisition.Experiment.Directory
+        & {""experiment_name"": experiment_name, ""directory_type"": ""raw""}
     ).fetch1(""directory_path"")
-    assert raw_dir == test_params[""raw_dir""]
-    exp_subjects = (acquisition.Experiment.Subject & {""experiment_name"": experiment_name}).fetch(""subject"")
-    assert len(exp_subjects) == test_params[""subject_count""]
-    assert ""BAA-1100701"" in exp_subjects
+    if raw_dir != test_params[""raw_dir""]:",tests/dj_pipeline/test_pipeline_instantiation.py,2024-10-29 11:58:38+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,51,RIGHT,66,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820659070,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,8 +1,19 @@
-from pytest import mark
+""""""Tests for the QC pipeline.""""""
 
+import datajoint as dj
+import pytest",tests/dj_pipeline/test_qc.py,2024-10-29 11:58:48+00:00,2024-10-29T12:00:51Z,fixed import pytest,,,,3.0,4,RIGHT,5,4.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820659201,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,8 +1,19 @@
-from pytest import mark
+""""""Tests for the QC pipeline.""""""
 
+import datajoint as dj
+import pytest
 
-@mark.qc
+logger = dj.logger
+
+
+@pytest.mark.qc
 def test_camera_qc_ingestion(test_params, pipeline, camera_qc_ingestion):
     qc = pipeline[""qc""]
 
-    assert len(qc.CameraQC()) == test_params[""camera_qc_count""]
+    camera_qc_count = len(qc.CameraQC())",tests/dj_pipeline/test_qc.py,2024-10-29 11:58:56+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,13,RIGHT,16,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820659832,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -33,32 +42,43 @@ def save_test_data(pipeline, test_params):
     return test_file
 
 
-@mark.ingestion
-@mark.tracking
+@pytest.mark.ingestion
+@pytest.mark.tracking
 def test_camera_tracking_ingestion(test_params, pipeline, camera_tracking_ingestion):
     tracking = pipeline[""tracking""]
 ",tests/dj_pipeline/test_tracking.py,2024-10-29 11:59:24+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,49.0,49,RIGHT,47,47.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820660235,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -33,32 +42,43 @@ def save_test_data(pipeline, test_params):
     return test_file
 
 
-@mark.ingestion
-@mark.tracking
+@pytest.mark.ingestion
+@pytest.mark.tracking
 def test_camera_tracking_ingestion(test_params, pipeline, camera_tracking_ingestion):
     tracking = pipeline[""tracking""]
 
-    assert len(tracking.CameraTracking.Object()) == test_params[""camera_tracking_object_count""]
+    camera_tracking_object_count = len(tracking.CameraTracking.Object())
+    if camera_tracking_object_count != test_params[""camera_tracking_object_count""]:
+        raise AssertionError(
+            f""Expected camera tracking object count {test_params['camera_tracking_object_count']},""
+            f""but got {camera_tracking_object_count}.""
+        )
 
     key = tracking.CameraTracking.Object().fetch(""KEY"")[index]
     file_name = (
         ""-"".join(
             [
-                v.strftime(""%Y%m%d%H%M%S"") if isinstance(v, datetime.datetime) else str(v)
+                (
+                    v.strftime(""%Y%m%d%H%M%S"")
+                    if isinstance(v, datetime.datetime)
+                    else str(v)
+                )
                 for v in key.values()
             ]
         )
         + "".npy""
     )
 
     test_file = pathlib.Path(test_params[""test_dir""] + ""/"" + file_name)
-    assert test_file.exists()
+    if not test_file.exists():",tests/dj_pipeline/test_tracking.py,2024-10-29 11:59:40+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,73,RIGHT,74,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820660381,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -33,32 +42,43 @@ def save_test_data(pipeline, test_params):
     return test_file
 
 
-@mark.ingestion
-@mark.tracking
+@pytest.mark.ingestion
+@pytest.mark.tracking
 def test_camera_tracking_ingestion(test_params, pipeline, camera_tracking_ingestion):
     tracking = pipeline[""tracking""]
 
-    assert len(tracking.CameraTracking.Object()) == test_params[""camera_tracking_object_count""]
+    camera_tracking_object_count = len(tracking.CameraTracking.Object())
+    if camera_tracking_object_count != test_params[""camera_tracking_object_count""]:
+        raise AssertionError(
+            f""Expected camera tracking object count {test_params['camera_tracking_object_count']},""
+            f""but got {camera_tracking_object_count}.""
+        )
 
     key = tracking.CameraTracking.Object().fetch(""KEY"")[index]
     file_name = (
         ""-"".join(
             [
-                v.strftime(""%Y%m%d%H%M%S"") if isinstance(v, datetime.datetime) else str(v)
+                (
+                    v.strftime(""%Y%m%d%H%M%S"")
+                    if isinstance(v, datetime.datetime)
+                    else str(v)
+                )
                 for v in key.values()
             ]
         )
         + "".npy""
     )
 
     test_file = pathlib.Path(test_params[""test_dir""] + ""/"" + file_name)
-    assert test_file.exists()
+    if not test_file.exists():
+        raise AssertionError(f""Test file '{test_file}' does not exist."")
 
     print(f""\nTesting {file_name}"")
 
     data = np.load(test_file)
-    assert np.allclose(
-        data,
-        (tracking.CameraTracking.Object() & key).fetch(column_name)[0],
-        equal_nan=True,
-    )
+    expected_data = (tracking.CameraTracking.Object() & key).fetch(column_name)[0]",tests/dj_pipeline/test_tracking.py,2024-10-29 11:59:47+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,79,RIGHT,85,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820660553,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -11,62 +12,95 @@
 monotonic_path = Path(__file__).parent.parent / ""data"" / ""monotonic""
 
 
-@mark.api
+@pytest.mark.api",tests/io/test_api.py,2024-10-29 11:59:55+00:00,2024-10-29T12:00:51Z,fixed import pytest,,,,16.0,15,RIGHT,16,19.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820660747,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -11,62 +12,95 @@
 monotonic_path = Path(__file__).parent.parent / ""data"" / ""monotonic""
 
 
-@mark.api
+@pytest.mark.api
 def test_load_start_only():
     data = aeon.load(
-        nonmonotonic_path, exp02.Patch2.Encoder, start=pd.Timestamp(""2022-06-06T13:00:49""), downsample=None
+        nonmonotonic_path,
+        exp02.Patch2.Encoder,
+        start=pd.Timestamp(""2022-06-06T13:00:49""),
+        downsample=None,
     )
-    assert len(data) > 0
+    if len(data) <= 0:",tests/io/test_api.py,2024-10-29 12:00:05+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,23,RIGHT,26,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820660979,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -11,62 +12,95 @@
 monotonic_path = Path(__file__).parent.parent / ""data"" / ""monotonic""
 
 
-@mark.api
+@pytest.mark.api
 def test_load_start_only():
     data = aeon.load(
-        nonmonotonic_path, exp02.Patch2.Encoder, start=pd.Timestamp(""2022-06-06T13:00:49""), downsample=None
+        nonmonotonic_path,
+        exp02.Patch2.Encoder,
+        start=pd.Timestamp(""2022-06-06T13:00:49""),
+        downsample=None,
     )
-    assert len(data) > 0
+    if len(data) <= 0:
+        raise AssertionError(""Loaded data is empty. Expected non-empty data."")
 
 
-@mark.api
+@pytest.mark.api
 def test_load_end_only():
     data = aeon.load(
-        nonmonotonic_path, exp02.Patch2.Encoder, end=pd.Timestamp(""2022-06-06T13:00:49""), downsample=None
+        nonmonotonic_path,
+        exp02.Patch2.Encoder,
+        end=pd.Timestamp(""2022-06-06T13:00:49""),
+        downsample=None,
     )
-    assert len(data) > 0
+    if len(data) <= 0:",tests/io/test_api.py,2024-10-29 12:00:16+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,35,RIGHT,41,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820661199,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -11,62 +12,95 @@
 monotonic_path = Path(__file__).parent.parent / ""data"" / ""monotonic""
 
 
-@mark.api
+@pytest.mark.api
 def test_load_start_only():
     data = aeon.load(
-        nonmonotonic_path, exp02.Patch2.Encoder, start=pd.Timestamp(""2022-06-06T13:00:49""), downsample=None
+        nonmonotonic_path,
+        exp02.Patch2.Encoder,
+        start=pd.Timestamp(""2022-06-06T13:00:49""),
+        downsample=None,
     )
-    assert len(data) > 0
+    if len(data) <= 0:
+        raise AssertionError(""Loaded data is empty. Expected non-empty data."")
 
 
-@mark.api
+@pytest.mark.api
 def test_load_end_only():
     data = aeon.load(
-        nonmonotonic_path, exp02.Patch2.Encoder, end=pd.Timestamp(""2022-06-06T13:00:49""), downsample=None
+        nonmonotonic_path,
+        exp02.Patch2.Encoder,
+        end=pd.Timestamp(""2022-06-06T13:00:49""),
+        downsample=None,
     )
-    assert len(data) > 0
+    if len(data) <= 0:
+        raise AssertionError(""Loaded data is empty. Expected non-empty data."")
 
 
-@mark.api
+@pytest.mark.api
 def test_load_filter_nonchunked():
-    data = aeon.load(nonmonotonic_path, exp02.Metadata, start=pd.Timestamp(""2022-06-06T09:00:00""))
-    assert len(data) > 0
+    data = aeon.load(
+        nonmonotonic_path, exp02.Metadata, start=pd.Timestamp(""2022-06-06T09:00:00"")
+    )
+    if len(data) <= 0:
+        raise AssertionError(""Loaded data is empty. Expected non-empty data."")
 
 
-@mark.api
+@pytest.mark.api
 def test_load_monotonic():
     data = aeon.load(monotonic_path, exp02.Patch2.Encoder, downsample=None)
-    assert len(data) > 0
-    assert data.index.is_monotonic_increasing
+    if len(data) <= 0:",tests/io/test_api.py,2024-10-29 12:00:26+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,51,RIGHT,63,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1820661356,MilagrosMarin,cc7e759625e0b1851032d4f686f6ace397ea66b2,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -11,62 +12,95 @@
 monotonic_path = Path(__file__).parent.parent / ""data"" / ""monotonic""
 
 
-@mark.api
+@pytest.mark.api
 def test_load_start_only():
     data = aeon.load(
-        nonmonotonic_path, exp02.Patch2.Encoder, start=pd.Timestamp(""2022-06-06T13:00:49""), downsample=None
+        nonmonotonic_path,
+        exp02.Patch2.Encoder,
+        start=pd.Timestamp(""2022-06-06T13:00:49""),
+        downsample=None,
     )
-    assert len(data) > 0
+    if len(data) <= 0:
+        raise AssertionError(""Loaded data is empty. Expected non-empty data."")
 
 
-@mark.api
+@pytest.mark.api
 def test_load_end_only():
     data = aeon.load(
-        nonmonotonic_path, exp02.Patch2.Encoder, end=pd.Timestamp(""2022-06-06T13:00:49""), downsample=None
+        nonmonotonic_path,
+        exp02.Patch2.Encoder,
+        end=pd.Timestamp(""2022-06-06T13:00:49""),
+        downsample=None,
     )
-    assert len(data) > 0
+    if len(data) <= 0:
+        raise AssertionError(""Loaded data is empty. Expected non-empty data."")
 
 
-@mark.api
+@pytest.mark.api
 def test_load_filter_nonchunked():
-    data = aeon.load(nonmonotonic_path, exp02.Metadata, start=pd.Timestamp(""2022-06-06T09:00:00""))
-    assert len(data) > 0
+    data = aeon.load(
+        nonmonotonic_path, exp02.Metadata, start=pd.Timestamp(""2022-06-06T09:00:00"")
+    )
+    if len(data) <= 0:
+        raise AssertionError(""Loaded data is empty. Expected non-empty data."")
 
 
-@mark.api
+@pytest.mark.api
 def test_load_monotonic():
     data = aeon.load(monotonic_path, exp02.Patch2.Encoder, downsample=None)
-    assert len(data) > 0
-    assert data.index.is_monotonic_increasing
+    if len(data) <= 0:
+        raise AssertionError(""Loaded data is empty. Expected non-empty data."")
+
+    if not data.index.is_monotonic_increasing:
+        raise AssertionError(""Data index is not monotonic increasing."")
 
 
-@mark.api
+@pytest.mark.api
 def test_load_nonmonotonic():
     data = aeon.load(nonmonotonic_path, exp02.Patch2.Encoder, downsample=None)
-    assert not data.index.is_monotonic_increasing
+    if data.index.is_monotonic_increasing:",tests/io/test_api.py,2024-10-29 12:00:35+00:00,2024-10-29T12:00:51Z,S101: Replaced assertions with exceptions,,,,,61,RIGHT,75,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1824905241,ttngu207,fc49b511a4cd1c4445e65c0aafe5c61901499f83,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -2,11 +2,11 @@
 #---- THIS FILE IS AUTO-GENERATED BY `streams_maker.py` ----
 
 import re
-import datajoint as dj
-import pandas as pd
 from uuid import UUID
 
 import aeon
+import datajoint as dj
+import pandas as pd",aeon/dj_pipeline/streams.py,2024-10-31 17:44:30+00:00,2024-10-31T17:44:37Z,@MilagrosMarin would you revert this change as well?,,8.0,RIGHT,,9,RIGHT,10,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826078933,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1 +1 @@
-#
+# README # noqa D100",aeon/README.md,2024-11-01 17:06:27+00:00,2024-11-05T15:26:48Z,"```suggestion
```
Ruff should only check python files. Did `ruff check` fail? ",,,,,1,RIGHT,2,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826121570,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -55,19 +59,21 @@ def conv2d(arr, kernel):
 
 def gen_subject_colors_dict(subject_names):
     """"""Generates a dictionary of subject colors based on a list of subjects.""""""
-    return {s: c for s, c in zip(subject_names, subject_colors)}
+    return dict(zip(subject_names, subject_colors, strict=False))
 
 
 def gen_patch_style_dict(patch_names):
-    """"""Based on a list of patches, generates a dictionary of:
+    """"""Based on a list of patches, generates a dictionary of the following items.
+
     - patch_colors_dict: patch name to color
     - patch_markers_dict: patch name to marker
     - patch_symbols_dict: patch name to symbol
     - patch_linestyles_dict: patch name to linestyle
+
     """"""",aeon/analysis/block_plotting.py,2024-11-01 17:47:14+00:00,2024-11-05T15:26:48Z,"```suggestion
    """"""
    Generates a dictionary of patch styles given a list of patch_names.

    The dictionary contains dictionaries which map patch names to their respective styles.
    Below are the keys for each nested dictionary and their contents:

    - colors: patch name to color
    - markers: patch name to marker
    - symbols: patch name to symbol
    - linestyles: patch name to linestyle
    """"""
```",,66.0,RIGHT,,73,RIGHT,42,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826162294,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -46,7 +50,12 @@ def fetch_stream(query, drop_pk=True):
     df.rename(columns={""timestamps"": ""time""}, inplace=True)
     df.set_index(""time"", inplace=True)
     df.sort_index(inplace=True)
-    df = df.convert_dtypes(convert_string=False, convert_integer=False, convert_boolean=False, convert_floating=False)
+    df = df.convert_dtypes(
+        convert_string=False,
+        convert_integer=False,
+        convert_boolean=False,
+        convert_floating=False,
+    )",aeon/dj_pipeline/__init__.py,2024-11-01 18:28:38+00:00,2024-11-05T15:26:48Z,"```suggestion
    df = df.convert_dtypes(
        convert_string=False, convert_integer=False, convert_boolean=False, convert_floating=False
    )
```",,53.0,RIGHT,,58,RIGHT,24,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826174458,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -279,7 +288,7 @@ class Meta(dj.Part):
         -> master
         ---
         bonsai_workflow: varchar(36)
-        commit: varchar(64)   # e.g. git commit hash of aeon_experiment used to generated this particular epoch
+        commit: varchar(64) # e.g., git commit hash of aeon_experiment used to generate this epoch",aeon/dj_pipeline/acquisition.py,2024-11-01 18:41:08+00:00,2024-11-05T15:26:48Z,"```suggestion
        commit: varchar(64) # e.g. git commit hash of aeon_experiment used to generate this epoch
```
Just to be consistent with the next line",,,,,291,RIGHT,108,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826178649,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -608,10 +621,13 @@ def make(self, key):
 
 
 def _get_all_chunks(experiment_name, device_name):
+    """"""Get all chunks for the specified ``experiment_name`` and ``device_name``.""""""
     directory_types = [""quality-control"", ""raw""]
     raw_data_dirs = {
         dir_type: Experiment.get_data_directory(
-            experiment_key={""experiment_name"": experiment_name}, directory_type=dir_type, as_posix=False
+            experiment_key={""experiment_name"": experiment_name},
+            directory_type=dir_type,
+            as_posix=False,",aeon/dj_pipeline/acquisition.py,2024-11-01 18:45:44+00:00,2024-11-05T15:26:48Z,"```suggestion
            experiment_key={""experiment_name"": experiment_name}, directory_type=dir_type, as_posix=False
```
Un-apply black (as ruff doesn't remove the last comma) ",,628.0,RIGHT,,630,RIGHT,155,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826186555,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -127,8 +129,7 @@ class BlockAnalysis(dj.Computed):
 
     @property
     def key_source(self):
-        # Ensure that the chunk ingestion has caught up with this block before processing
-        # (there exists a chunk that ends after the block end time)
+        """"""Ensure that the chunk ingestion has caught up with this block before processing (there exists a chunk that ends after the block end time).""""""  # noqa 501",aeon/dj_pipeline/analysis/block_analysis.py,2024-11-01 18:54:22+00:00,2024-11-05T15:26:48Z,"```suggestion
        """"""Ensures chunk ingestion is complete before processing the block.

        This is done by checking that there exists a chunk that ends after the block end time.
        """"""
```",,,,,132,RIGHT,17,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826199429,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -163,12 +164,14 @@ class Subject(dj.Part):
         """"""
 
     def make(self, key):
-        """"""Restrict, fetch and aggregate data from different streams to produce intermediate data products at a per-block level (for different patches and different subjects).
+        """"""
+        Restrict, fetch and aggregate data from different streams to produce intermediate data products at a per-block level (for different patches and different subjects).
+",aeon/dj_pipeline/analysis/block_analysis.py,2024-11-01 19:09:03+00:00,2024-11-05T15:26:48Z,"```suggestion
        """"""Collates data from various streams to produce per-block intermediate data products.

        The intermediate data products consist of data for each ``Patch``
        and each ``Subject`` within the  ``Block``.
        The steps to restrict, fetch, and aggregate data from various streams are as follows:

```",,167.0,RIGHT,,169,RIGHT,28,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826199873,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -163,12 +164,14 @@ class Subject(dj.Part):
         """"""
 
     def make(self, key):
-        """"""Restrict, fetch and aggregate data from different streams to produce intermediate data products at a per-block level (for different patches and different subjects).
+        """"""
+        Restrict, fetch and aggregate data from different streams to produce intermediate data products at a per-block level (for different patches and different subjects).
+
         1. Query data for all chunks within the block.
         2. Fetch streams, filter by maintenance period.
         3. Fetch subject position data (SLEAP).
         4. Aggregate and insert into the table.
-        """"""
+        """"""  # noqa 501",aeon/dj_pipeline/analysis/block_analysis.py,2024-11-01 19:09:31+00:00,2024-11-05T15:26:48Z,"```suggestion
        """"""
```",,,,,174,RIGHT,34,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826205598,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -373,7 +383,7 @@ class Patch(dj.Part):
         -> BlockAnalysis.Patch
         -> BlockAnalysis.Subject
         ---
-        in_patch_timestamps: longblob  # timestamps in which a particular subject is spending time at a particular patch
+        in_patch_timestamps: longblob # timestamps when a subject spends time at a specific patch",aeon/dj_pipeline/analysis/block_analysis.py,2024-11-01 19:15:48+00:00,2024-11-05T15:26:48Z,"```suggestion
        in_patch_timestamps: longblob # timestamps when a subject is at a specific patch
```",,,,,386,RIGHT,84,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826207148,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -932,7 +947,9 @@ def calculate_running_preference(group, pref_col, out_col):
             patch_pref.groupby(""subject_name"")
             .apply(
                 lambda group: calculate_running_preference(
-                    group, ""cumulative_preference_by_wheel"", ""running_preference_by_wheel""
+                    group,
+                    ""cumulative_preference_by_wheel"",
+                    ""running_preference_by_wheel"",",aeon/dj_pipeline/analysis/block_analysis.py,2024-11-01 19:17:46+00:00,2024-11-05T15:26:48Z,"```suggestion
                    group, ""cumulative_preference_by_wheel"", ""running_preference_by_wheel""
```
reverting black",,950.0,RIGHT,,952,RIGHT,127,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826208441,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1394,7 +1412,10 @@ def make(self, key):
             & ""attribute_name = 'Location'""
         )
         rfid_locs = dict(
-            zip(*rfid_location_query.fetch(""rfid_reader_name"", ""attribute_value""), strict=True)
+            zip(
+                *rfid_location_query.fetch(""rfid_reader_name"", ""attribute_value""),
+                strict=True,
+            )",aeon/dj_pipeline/analysis/block_analysis.py,2024-11-01 19:19:16+00:00,2024-11-05T15:26:48Z,"```suggestion
            zip(*rfid_location_query.fetch(""rfid_reader_name"", ""attribute_value""), strict=True)
```
reverting black",,1415.0,RIGHT,,1418,RIGHT,147,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1826216808,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1558,21 +1582,25 @@ def get_threshold_associated_pellets(patch_key, start, end):
     2. Get all pellet delivery timestamps (DeliverPellet): let's call these events ""B""
         - Find matching beam break timestamps within 1.2s after each pellet delivery
     3. For each event ""A"", find the nearest event ""B"" within 100ms before or after the event ""A""
-        - These are the pellet delivery events ""B"" associated with the previous threshold update event ""A""
-    4. Shift back the pellet delivery timestamps by 1 to match the pellet delivery with the previous threshold update
+        - These are the pellet delivery events ""B"" associated with the previous threshold update",aeon/dj_pipeline/analysis/block_analysis.py,2024-11-01 19:28:44+00:00,2024-11-05T15:26:48Z,"Full suggestion that gets rid of noqa 501. Note that bullet lists need to start after a linebreak. When breaking the bullet description into multiple lines, these need to align with the first line for the docs to render correctly.
```python
    """"""Gets pellet delivery timestamps for each patch threshold update within the specified time range.

    1. Get all patch state update timestamps (DepletionState): let's call these events ""A""

       - Remove all events within 1 second of each other
       - Remove all events without threshold value (NaN)
    2. Get all pellet delivery timestamps (DeliverPellet): let's call these events ""B""

       - Find matching beam break timestamps within 1.2s after each pellet delivery
    3. For each event ""A"", find the nearest event ""B"" within 100ms before or after the event ""A""

       - These are the pellet delivery events ""B"" associated with the previous threshold update event ""A""
    4. Shift back the pellet delivery timestamps by 1 to match the pellet delivery with the
       previous threshold update
    5. Remove all threshold updates events ""A"" without a corresponding pellet delivery event ""B""

    Args:
        patch_key (dict): primary key for the patch
        start (datetime): start timestamp
        end (datetime): end timestamp

    Returns:
        pd.DataFrame: DataFrame with the following columns:

        - threshold_update_timestamp (index)
        - pellet_timestamp
        - beam_break_timestamp
        - offset
        - rate
    """"""
```
",,,,,1585,RIGHT,181,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1827881697,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,13 +1,21 @@
-import datetime
+""""""Module for visit-related tables in the analysis schema.""""""
+
+from collections import deque
+from datetime import datetime, timezone
+
 import datajoint as dj
-import pandas as pd
 import numpy as np
-from collections import deque
+import pandas as pd
 
 from aeon.analysis import utils as analysis_utils
-
-from aeon.dj_pipeline import get_schema_name, fetch_stream
-from aeon.dj_pipeline import acquisition, lab, qc, tracking
+from aeon.dj_pipeline import (
+    acquisition,
+    fetch_stream,
+    get_schema_name,
+    lab,
+    qc,
+    tracking,",aeon/dj_pipeline/analysis/visit.py,2024-11-04 15:02:52+00:00,2024-11-05T15:26:48Z,Can we remove these? They don't seem to be used.,,15.0,RIGHT,,17,RIGHT,23,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1827947068,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -113,12 +123,16 @@ def make(self, key):
 
 
 def ingest_environment_visits(experiment_names: list | None = None):
-    """"""Function to populate into `Visit` and `VisitEnd` for specified experiments (default: 'exp0.2-r0'). This ingestion routine handles only those ""complete"" visits, not ingesting any ""on-going"" visits using ""analyze"" method: `aeon.analyze.utils.visits()`.
+    """"""Function to populate into `Visit` and `VisitEnd` for specified experiments (default: 'exp0.2-r0').
+
+    This ingestion routine handles only those ""complete"" visits,
+    not ingesting any ""on-going"" visits using ""analyze"" method:
+    `aeon.analyze.utils.visits()`.",aeon/dj_pipeline/analysis/visit.py,2024-11-04 15:42:30+00:00,2024-11-05T15:26:48Z,"```suggestion
    """"""Populates ``Visit`` and ``VisitEnd`` for the specified experiment names.

    This ingestion routine includes only ""complete"" visits and
    does not ingest any ""on-going"" visits.
    Visits are retrieved using :func:`aeon.analysis.utils.visits`.
```
The [`` :role:`target` `` syntax](https://www.sphinx-doc.org/en/master/usage/domains/python.html#cross-referencing-python-objects) will resolve into the correct URL in the API reference on the docs website.",,126.0,RIGHT,,130,RIGHT,51,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1827948943,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -113,12 +123,16 @@ def make(self, key):
 
 
 def ingest_environment_visits(experiment_names: list | None = None):
-    """"""Function to populate into `Visit` and `VisitEnd` for specified experiments (default: 'exp0.2-r0'). This ingestion routine handles only those ""complete"" visits, not ingesting any ""on-going"" visits using ""analyze"" method: `aeon.analyze.utils.visits()`.
+    """"""Function to populate into `Visit` and `VisitEnd` for specified experiments (default: 'exp0.2-r0').
+
+    This ingestion routine handles only those ""complete"" visits,
+    not ingesting any ""on-going"" visits using ""analyze"" method:
+    `aeon.analyze.utils.visits()`.
 
     Args:
-        experiment_names (list, optional): list of names of the experiment to populate into the Visit table. Defaults to None.
+        experiment_names (list, optional): list of names of the experiment
+        to populate into the Visit table. Defaults to None.",aeon/dj_pipeline/analysis/visit.py,2024-11-04 15:43:40+00:00,2024-11-05T15:26:48Z,"```suggestion
        experiment_names (list, optional): list of names of the experiment
            to populate into the ``Visit`` table.
            If unspecified, defaults to ``None`` and ``['exp0.2-r0']`` is used.
```
Need to indent subsequent lines for docs to render correctly.",,133.0,RIGHT,,134,RIGHT,56,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1827952244,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -150,7 +164,8 @@ def ingest_environment_visits(experiment_names: list | None = None):
                     ""enter_exit_time"",
                     ""event_type"",
                     order_by=""enter_exit_time"",
-                )
+                ),
+                strict=False,",aeon/dj_pipeline/analysis/visit.py,2024-11-04 15:45:52+00:00,2024-11-05T15:26:48Z,"```python
        enter_exit_df = pd.DataFrame(
            zip(
                *enter_exit_query.fetch(
                    ""subject"", ""enter_exit_time"", ""event_type"", order_by=""enter_exit_time""
                ),
                strict=False,
            )
        )
```

Revert black",,,,159.0,168,RIGHT,77,76.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828019583,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -190,17 +195,22 @@ def make(self, key):
 
     @classmethod
     def get_position(cls, visit_key=None, subject=None, start=None, end=None):
-        """"""Given a key to a single Visit, return a Pandas DataFrame for the position data of the subject for the specified Visit time period.""""""
+        """"""Return a Pandas df of the subject's position data for a specified Visit given its key.
+
+        Given a key to a single Visit, return a Pandas DataFrame for
+        the position data of the subject for the specified Visit time period.
+        """"""",aeon/dj_pipeline/analysis/visit_analysis.py,2024-11-04 16:26:43+00:00,2024-11-05T15:26:48Z,"```suggestion
        """"""Retrieves a Pandas DataFrame of a subject's position data for a specified ``Visit``.

        A ``Visit`` is specified by either a ``visit_key`` or 
        a combination of ``subject``, ``start``, and ``end``. 
        If all four arguments are provided, the ``visit_key`` is ignored.

        Args:
            visit_key (dict, optional): key to a single ``Visit``.
                Only required if ``subject``, ``start``, and ``end`` are not provided.
            subject (str, optional): subject name. 
                Only required if ``visit_key`` is not provided.
            start (datetime): start time of the period of interest.
                Only required if ``visit_key`` is not provided.
            end (datetime, optional): end time of the period of interest.
                Only required if ``visit_key`` is not provided.
        """"""
```",,198.0,RIGHT,,202,RIGHT,98,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828039232,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -513,7 +525,9 @@ def make(self, key):
 
 @schema
 class VisitForagingBout(dj.Computed):
-    definition = """""" # A time period spanning the time when the animal enters a food patch and moves the wheel to when it leaves the food patch
+    """"""Time period from when the animal enters to when it leaves a food patch while moving the wheel.""""""",aeon/dj_pipeline/analysis/visit_analysis.py,2024-11-04 16:39:27+00:00,2024-11-05T15:26:48Z,"```suggestion
    """"""Time period when a subject enters a food patch, moves the wheel, and then leaves the patch.""""""
```",,,,,528,RIGHT,183,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828077906,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -513,7 +525,9 @@ def make(self, key):
 
 @schema
 class VisitForagingBout(dj.Computed):
-    definition = """""" # A time period spanning the time when the animal enters a food patch and moves the wheel to when it leaves the food patch
+    """"""Time period from when the animal enters to when it leaves a food patch while moving the wheel.""""""
+
+    definition = """""" # Time from animal's entry to exit of a food patch while moving the wheel.",aeon/dj_pipeline/analysis/visit_analysis.py,2024-11-04 17:06:19+00:00,2024-11-05T15:26:48Z,"```suggestion
    definition = """""" # Time from subject's entry to exit of a food patch to interact with the wheel.
```",,,,,530,RIGHT,185,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828092409,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,3 +1,5 @@
+""""""Function to create new experiments for experiment0.2.""""""",aeon/dj_pipeline/create_experiments/create_experiment_02.py,2024-11-04 17:16:53+00:00,2024-11-05T15:26:48Z,"```suggestion
""""""Functions to create new experiments for experiment0.2.""""""
```
Same suggestion applies to all other `create_experiment` scripts",,,,,1,RIGHT,1,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828095075,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -52,7 +54,9 @@ def create_new_social_experiment(experiment_name):
         )
         acquisition.Experiment.Directory.insert(experiment_directories, skip_duplicates=True)
         acquisition.Experiment.DevicesSchema.insert1(
-            {""experiment_name"": experiment_name, ""devices_schema_name"": exp_name.replace(""."", """")},
+            {
+                ""experiment_name"": experiment_name,
+                ""devices_schema_name"": exp_name.replace(""."", """"),
+            },",aeon/dj_pipeline/create_experiments/create_socialexperiment.py,2024-11-04 17:19:00+00:00,2024-11-05T15:26:48Z,"```suggestion
            {""experiment_name"": experiment_name, ""devices_schema_name"": exp_name.replace(""."", """")},
```
Revert black",,57.0,RIGHT,,60,RIGHT,29,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828096882,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,13 +1,18 @@
+""""""Function to create new experiments for social0-r1.""""""
+
 import pathlib
 
 from aeon.dj_pipeline import acquisition, lab, subject
-from aeon.dj_pipeline.create_experiments.create_experiment_01 import ingest_exp01_metadata
+from aeon.dj_pipeline.create_experiments.create_experiment_01 import (
+    ingest_exp01_metadata,
+)",aeon/dj_pipeline/create_experiments/create_socialexperiment_0.py,2024-11-04 17:20:19+00:00,2024-11-05T15:26:48Z,"```suggestion
from aeon.dj_pipeline.create_experiments.create_experiment_01 import ingest_exp01_metadata
```
Revert black",,6.0,RIGHT,,8,RIGHT,9,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828112826,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,9 +1,14 @@
+""""""This module defines the workers for the AEON pipeline.""""""
+
 import datajoint as dj
-from datajoint_utilities.dj_worker import DataJointWorker, ErrorLog, WorkerLog, RegisteredWorker
+from datajoint_utilities.dj_worker import (
+    DataJointWorker,
+    ErrorLog,
+    WorkerLog,
+)",aeon/dj_pipeline/populate/worker.py,2024-11-04 17:29:01+00:00,2024-11-05T15:26:48Z,"```suggestion
from datajoint_utilities.dj_worker import DataJointWorker, ErrorLog, WorkerLog
```
Revert black",,4.0,RIGHT,,8,RIGHT,9,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828119342,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -15,7 +13,15 @@
 
 schema_name_mapper = {
     source_db_prefix + schema_name: target_db_prefix + schema_name
-    for schema_name in (""lab"", ""subject"", ""acquisition"", ""tracking"", ""qc"", ""report"", ""analysis"")
+    for schema_name in (
+        ""lab"",
+        ""subject"",
+        ""acquisition"",
+        ""tracking"",
+        ""qc"",
+        ""report"",
+        ""analysis"",
+    )",aeon/dj_pipeline/scripts/clone_and_freeze_exp01.py,2024-11-04 17:32:52+00:00,2024-11-05T15:26:48Z,"```suggestion
    for schema_name in (""lab"", ""subject"", ""acquisition"", ""tracking"", ""qc"", ""report"", ""analysis"")
```
Revert black",,16.0,RIGHT,,24,RIGHT,21,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828120642,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -19,7 +19,15 @@
 
 schema_name_mapper = {
     source_db_prefix + schema_name: target_db_prefix + schema_name
-    for schema_name in (""lab"", ""subject"", ""acquisition"", ""tracking"", ""qc"", ""analysis"", ""report"")
+    for schema_name in (
+        ""lab"",
+        ""subject"",
+        ""acquisition"",
+        ""tracking"",
+        ""qc"",
+        ""analysis"",
+        ""report"",
+    )",aeon/dj_pipeline/scripts/clone_and_freeze_exp02.py,2024-11-04 17:33:53+00:00,2024-11-05T15:26:48Z,"```suggestion
    for schema_name in (""lab"", ""subject"", ""acquisition"", ""tracking"", ""qc"", ""analysis"", ""report"")
```
Revert black",,22.0,RIGHT,,30,RIGHT,19,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828128411,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -96,7 +99,10 @@ def make(self, key):
             }
         )
         Strain.insert1(
-            {""strain_id"": animal_resp[""strain_id""], ""strain_name"": animal_resp[""strain_id""]},
+            {
+                ""strain_id"": animal_resp[""strain_id""],
+                ""strain_name"": animal_resp[""strain_id""],
+            },",aeon/dj_pipeline/subject.py,2024-11-04 17:39:54+00:00,2024-11-05T15:26:48Z,"```suggestion
            {""strain_id"": animal_resp[""strain_id""], ""strain_name"": animal_resp[""strain_id""]},
```
Revert black

Likewise the following dicts can fit in a single line
https://github.com/SainsburyWellcomeCentre/aeon_mecha/blob/48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b/aeon/dj_pipeline/subject.py#L74-L85",,102.0,RIGHT,,105,RIGHT,27,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828129894,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -108,7 +114,10 @@ def make(self, key):
         }
         if animal_resp[""gen_bg_id""] is not None:
             GeneticBackground.insert1(
-                {""gen_bg_id"": animal_resp[""gen_bg_id""], ""gen_bg"": animal_resp[""gen_bg""]},
+                {
+                    ""gen_bg_id"": animal_resp[""gen_bg_id""],
+                    ""gen_bg"": animal_resp[""gen_bg""],
+                },",aeon/dj_pipeline/subject.py,2024-11-04 17:40:42+00:00,2024-11-05T15:26:48Z,"```suggestion
                {""gen_bg_id"": animal_resp[""gen_bg_id""], ""gen_bg"": animal_resp[""gen_bg""]},
```
Revert black",,117.0,RIGHT,,120,RIGHT,39,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828135022,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,15 +1,22 @@
-from pathlib import Path
+""""""DataJoint schema for tracking data.""""""
 
 import datajoint as dj
 import matplotlib.path
 import numpy as np
 import pandas as pd
 
-from aeon.dj_pipeline import acquisition, dict_to_uuid, get_schema_name, lab, qc, streams
+from aeon.dj_pipeline import (
+    acquisition,
+    dict_to_uuid,
+    get_schema_name,
+    lab,
+    streams,
+)",aeon/dj_pipeline/tracking.py,2024-11-04 17:43:48+00:00,2024-11-05T15:26:48Z,"```suggestion
from aeon.dj_pipeline import acquisition, dict_to_uuid, get_schema_name, lab, streams
```
Revert black",,8.0,RIGHT,,14,RIGHT,16,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828143165,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -108,7 +116,14 @@ def insert_new_params(
 
 @schema
 class SLEAPTracking(dj.Imported):
-    definition = """"""  # Tracked objects position data from a particular VideoSource for multi-animal experiment using the SLEAP tracking method per chunk
+    """"""Tracking data from SLEAP for multi-animal experiments.
+
+    Tracked objects position data from a particular
+    VideoSource for multi-animal experiment using the SLEAP tracking
+    method per chunk.
+    """"""
+
+    definition = """"""",aeon/dj_pipeline/tracking.py,2024-11-04 17:49:42+00:00,2024-11-05T15:26:48Z,"```suggestion
    """"""Tracking data from SLEAP for multi-animal experiments.""""""

    definition = """""" # Tracked objects position data from a particular
VideoSource for multi-animal experiment using the SLEAP tracking method per chunk.
```
We can still keep the definition of the table right?",,119.0,RIGHT,,126,RIGHT,45,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828153409,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -226,13 +243,16 @@ def make(self, key):
 
 
 def compute_distance(position_df, target, xcol=""x"", ycol=""y""):
-    assert len(target) == 2
+    """"""Compute the distance of the position data from a target coordinate (X,Y).""""""",aeon/dj_pipeline/tracking.py,2024-11-04 17:54:21+00:00,2024-11-05T15:26:48Z,"```suggestion
    """"""Compute the distance between the position and the target.
    
    Args:
        position_df (pd.DataFrame): DataFrame containing the position data.
        target (tuple): Tuple of length 2 indicating the target x and y position.
        xcol (str): x column name in ``position_df``. Default is 'x'.
        ycol (str): y column name in ``position_df``. Default is 'y'.
    """"""
```",,,,,246,RIGHT,70,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828170826,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -226,13 +243,16 @@ def make(self, key):
 
 
 def compute_distance(position_df, target, xcol=""x"", ycol=""y""):
-    assert len(target) == 2
+    """"""Compute the distance of the position data from a target coordinate (X,Y).""""""
+    if len(target) != 2:  # noqa PLR2004
+        raise ValueError(""Target must be a list of tuple of length 2."")
     return np.sqrt(np.square(position_df[[xcol, ycol]] - target).sum(axis=1))
 
 
 def is_position_in_patch(
     position_df, patch_position, wheel_distance_travelled, patch_radius=0.2
 ) -> pd.Series:
+    """"""The function returns a boolean array indicating whether the position is inside the patch.""""""",aeon/dj_pipeline/tracking.py,2024-11-04 18:05:55+00:00,2024-11-05T15:26:48Z,"```suggestion
    """"""Returns a boolean array of whether a given position is inside the patch and the wheel is moving.

    Args:
        position_df (pd.DataFrame): DataFrame containing the position data.
        patch_position (tuple): Tuple of length 2 indicating the patch x and y position.
        wheel_distance_travelled (pd.Series): distance travelled by the wheel.
        patch_radius (float): Radius of the patch. Default is 0.2.
    """"""
```",,,,,255,RIGHT,79,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828182759,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -234,7 +242,11 @@ def ingest_epoch_metadata(experiment_name, devices_schema, metadata_yml_filepath
                     }
                 )
 
-            """"""Check if this device is currently installed. If the same device serial number is currently installed check for any changes in configuration. If not, skip this""""""
+            """"""
+            Check if this device is currently installed.
+            If the same device serial number is currently installed check for changes in configuration.
+            If not, skip this.
+            """"""",aeon/dj_pipeline/utils/load_metadata.py,2024-11-04 18:15:44+00:00,2024-11-05T15:26:48Z,"```suggestion
            # Check if this device is currently installed.
            # If the same device serial number is currently installed check for changes in configuration.
            # If not, skip this.
```",,245.0,RIGHT,,249,RIGHT,55,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828194747,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -44,14 +46,14 @@ def find_root_directory(
 
     Returns:
         pathlib.Path: The full path to the discovered root directory.
-    """"""
+    """"""  # noqa E501",aeon/dj_pipeline/utils/paths.py,2024-11-04 18:24:54+00:00,2024-11-05T15:26:48Z,"Suggested description that is within the allowed line length:
    """"""Finds the parent directory of a given full path among multiple potential root directories.
",,,,,49,RIGHT,11,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828208374,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -27,11 +29,12 @@ def plot_reward_rate_differences(subject_keys):
 
     Examples:
     ```
-    subject_keys = (acquisition.Experiment.Subject & 'experiment_name = ""exp0.1-r0""').fetch('KEY')
+    subject_keys =
+    (acquisition.Experiment.Subject & 'experiment_name = ""exp0.1-r0""').fetch('KEY')
 
     fig = plot_reward_rate_differences(subject_keys)
     ```
-    """"""
+    """"""  # noqa E501",aeon/dj_pipeline/utils/plotting.py,2024-11-04 18:35:54+00:00,2024-11-05T15:26:48Z,"Suggested docstring:
```python
    """"""Plots the reward rate differences between two food patches (Patch 2 - Patch 1).

    The reward rate differences between the two food patches are plotted
    for all sessions from all subjects in ``subject_keys``.

    Examples:
        >>> subject_keys = (
        ...     acquisition.Experiment.Subject 
        ...     & 'experiment_name = ""exp0.1-r0""').fetch('KEY')
        >>> fig = plot_reward_rate_differences(subject_keys)
    """"""
```",,,,,37,RIGHT,17,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828210090,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -98,7 +101,9 @@ def plot_wheel_travelled_distance(session_keys):
     distance_travelled_df[""in_arena""] = [
         f'{subj_name}_{sess_start.strftime(""%m/%d/%Y"")}'
         for subj_name, sess_start in zip(
-            distance_travelled_df.subject, distance_travelled_df.in_arena_start
+            distance_travelled_df.subject,
+            distance_travelled_df.in_arena_start,
+            strict=False,",aeon/dj_pipeline/utils/plotting.py,2024-11-04 18:37:13+00:00,2024-11-05T15:26:48Z,"```suggestion
            distance_travelled_df.subject, distance_travelled_df.in_arena_start, strict=False
```
Revert black",,104.0,RIGHT,,106,RIGHT,46,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828210498,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -124,6 +129,7 @@ def plot_wheel_travelled_distance(session_keys):
 
 
 def plot_average_time_distribution(session_keys):
+    """"""Plotting the average time spent in different regions.""""""",aeon/dj_pipeline/utils/plotting.py,2024-11-04 18:37:32+00:00,2024-11-05T15:26:48Z,"```suggestion
    """"""Plots the average time spent in different regions.""""""
```",,,,,132,RIGHT,54,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828226178,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -74,7 +77,7 @@ def plot_reward_rate_differences(subject_keys):
 
 
 def plot_wheel_travelled_distance(session_keys):
-    """"""Plotting the wheel travelled distance for different patches for all sessions specified in ""session_keys"".
+    """"""Plot wheel-travelled-distance for different patches for all sessions specified in session_keys.",aeon/dj_pipeline/utils/plotting.py,2024-11-04 18:50:42+00:00,2024-11-05T15:26:48Z,"Update examples:
```python
    """"""Plot wheel-travelled-distance for different patches for all sessions specified in session_keys.

    Examples:
        >>> session_keys = (
        ...     acquisition.Session
        ...     & acquisition.SessionEnd
        ...     & {""experiment_name"": ""exp0.1-r0"", ""subject"": ""BAA-1099794""}
        ... ).fetch(""KEY"")
        >>> fig = plot_wheel_travelled_distance(session_keys)
    """"""
```",,,,81.0,80,RIGHT,35,43.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828231455,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -205,16 +211,21 @@ def plot_visit_daily_summary(
 
     Args:
         visit_key (dict) : Key from the VisitSummary table
-        attr (str): Name of the attribute to plot (e.g., 'pellet_count', 'wheel_distance_travelled', 'total_distance_travelled')
-        per_food_patch (bool, optional): Separately plot results from different food patches. Defaults to False.
+        attr (str): Name of the attribute to plot (e.g., 'pellet_count',
+                    'wheel_distance_travelled', 'total_distance_travelled')
+        per_food_patch (bool, optional): Separately plot results from
+                    different food patches. Defaults to False.
 
     Returns:
         fig: Figure object
 
     Examples:
-        >>> fig = plot_visit_daily_summary(visit_key, attr='pellet_count', per_food_patch=True)
-        >>> fig = plot_visit_daily_summary(visit_key, attr='wheel_distance_travelled', per_food_patch=True)
-        >>> fig = plot_visit_daily_summary(visit_key, attr='total_distance_travelled')
+        >>> fig = plot_visit_daily_summary(visit_key, attr='pellet_count',
+        per_food_patch=True)
+        >>> fig = plot_visit_daily_summary(visit_key,
+        attr='wheel_distance_travelled', per_food_patch=True)
+        >>> fig = plot_visit_daily_summary(visit_key,
+        attr='total_distance_travelled')",aeon/dj_pipeline/utils/plotting.py,2024-11-04 18:55:06+00:00,2024-11-05T15:26:48Z,"```suggestion
        >>> fig = plot_visit_daily_summary(visit_key, attr='pellet_count', per_food_patch=True)
        >>> fig = plot_visit_daily_summary(
        ...    visit_key,
        ...    attr=""wheel_distance_travelled""
        ...    per_food_patch=True,
        ... )
        >>> fig = plot_visit_daily_summary(visit_key, attr='total_distance_travelled')
```",,223.0,RIGHT,,228,RIGHT,81,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828233187,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -292,7 +305,8 @@ def plot_foraging_bouts_count(
         fig: Figure object
 
     Examples:
-        >>> fig = plot_foraging_bouts_count(visit_key, freq=""D"", per_food_patch=True, min_bout_duration=1, min_wheel_dist=1)
+        >>> fig = plot_foraging_bouts_count(visit_key, freq=""D"",
+        per_food_patch=True, min_bout_duration=1, min_wheel_dist=1)",aeon/dj_pipeline/utils/plotting.py,2024-11-04 18:56:39+00:00,2024-11-05T15:26:48Z,"```suggestion
        >>> fig = plot_foraging_bouts_count(
        ...     visit_key,
        ...     freq=""D"",
        ...     per_food_patch=True,
        ...     min_bout_duration=1,
        ...     min_wheel_dist=1
        ... )
```",,308.0,RIGHT,,309,RIGHT,104,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828234991,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -449,7 +465,13 @@ def plot_foraging_bouts_distribution(
         width=700,
         height=400,
         template=""simple_white"",
-        legend={""orientation"": ""h"", ""yanchor"": ""bottom"", ""y"": 1, ""xanchor"": ""right"", ""x"": 1},
+        legend={
+            ""orientation"": ""h"",
+            ""yanchor"": ""bottom"",
+            ""y"": 1,
+            ""xanchor"": ""right"",
+            ""x"": 1,
+        },",aeon/dj_pipeline/utils/plotting.py,2024-11-04 18:58:05+00:00,2024-11-05T15:26:48Z,"```suggestion
        legend={""orientation"": ""h"", ""yanchor"": ""bottom"", ""y"": 1, ""xanchor"": ""right"", ""x"": 1},
```
Revert black",,468.0,RIGHT,,474,RIGHT,132,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1828244102,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -511,16 +534,20 @@ def plot_visit_time_distribution(visit_key, freq=""D""):
     return fig
 
 
-def _get_region_data(visit_key, attrs=[""in_nest"", ""in_arena"", ""in_corridor"", ""in_patch""]):
+def _get_region_data(visit_key, attrs=None):
     """"""Retrieve region data from VisitTimeDistribution tables.
 
     Args:
         visit_key (dict): Key from the Visit table
-        attrs (list, optional): List of column names (in VisitTimeDistribution tables) to retrieve. Defaults to all.
+        attrs (list, optional): List of column names (in VisitTimeDistribution tables) to retrieve.
+        Defaults is None, which will create a new list with the desired default values inside the function.",aeon/dj_pipeline/utils/plotting.py,2024-11-04 19:06:16+00:00,2024-11-05T15:26:48Z,"```suggestion
        attrs (list, optional): List of column names (in VisitTimeDistribution tables) to retrieve.
            If unspecified, defaults to `None` and ``[""in_nest"", ""in_arena"", ""in_corridor"", ""in_patch""]``
            is used.
```",,542.0,RIGHT,,543,RIGHT,158,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829153616,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -21,17 +23,23 @@
 
 
 class StreamType(dj.Lookup):
-    """"""Catalog of all steam types for the different device types used across Project Aeon. One StreamType corresponds to one reader class in `aeon.io.reader`. The combination of `stream_reader` and `stream_reader_kwargs` should fully specify the data loading routine for a particular device, using the `aeon.io.utils`.""""""
+    """"""Catalog of all stream types used across Project Aeon.
+
+    Catalog of all steam types for the different device types used across Project Aeon.
+    One StreamType corresponds to one reader class in `aeon.io.reader`.The
+    combination of `stream_reader` and `stream_reader_kwargs` should fully specify the data
+    loading routine for a particular device, using the `aeon.io.utils`.
+    """"""
 
-    definition = """"""  # Catalog of all stream types used across Project Aeon
+    definition = """""" # Catalog of all stream types used across Project Aeon
     stream_type          : varchar(20)
     ---
     stream_reader        : varchar(256)     # name of the reader class found in `aeon_mecha` package (e.g. aeon.io.reader.Video)",aeon/dj_pipeline/utils/streams_maker.py,2024-11-05 10:59:58+00:00,2024-11-05T15:26:48Z,"```suggestion
    stream_reader        : varchar(256) # reader class name in aeon.io.reader (e.g. aeon.io.reader.Video)
```
To get rid of noqa: E501",,,,,37,RIGHT,23,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829154021,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -21,17 +23,23 @@
 
 
 class StreamType(dj.Lookup):
-    """"""Catalog of all steam types for the different device types used across Project Aeon. One StreamType corresponds to one reader class in `aeon.io.reader`. The combination of `stream_reader` and `stream_reader_kwargs` should fully specify the data loading routine for a particular device, using the `aeon.io.utils`.""""""
+    """"""Catalog of all stream types used across Project Aeon.
+
+    Catalog of all steam types for the different device types used across Project Aeon.
+    One StreamType corresponds to one reader class in `aeon.io.reader`.The
+    combination of `stream_reader` and `stream_reader_kwargs` should fully specify the data
+    loading routine for a particular device, using the `aeon.io.utils`.
+    """"""
 
-    definition = """"""  # Catalog of all stream types used across Project Aeon
+    definition = """""" # Catalog of all stream types used across Project Aeon
     stream_type          : varchar(20)
     ---
     stream_reader        : varchar(256)     # name of the reader class found in `aeon_mecha` package (e.g. aeon.io.reader.Video)
     stream_reader_kwargs : longblob  # keyword arguments to instantiate the reader class
     stream_description='': varchar(256)
     stream_hash          : uuid    # hash of dict(stream_reader_kwargs, stream_reader=stream_reader)
     unique index (stream_hash)
-    """"""
+    """"""  # noqa: E501",aeon/dj_pipeline/utils/streams_maker.py,2024-11-05 11:00:18+00:00,2024-11-05T15:26:48Z,"```suggestion
    """"""
```
If you adopt the above suggestion, we could remove this",,,,,42,RIGHT,29,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829216684,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -67,22 +75,21 @@ def get_device_template(device_type: str):
     device_type = dj.utils.from_camel_case(device_type)
 
     class ExperimentDevice(dj.Manual):
-        definition = f""""""
-        # {device_title} placement and operation for a particular time period, at a certain location, for a given experiment (auto-generated with aeon_mecha-{aeon.__version__})
+        definition = f"""""" # {device_title} placement and operation for a particular time period, at a certain location, for a given experiment (auto-generated with aeon_mecha-{aeon.__version__})",aeon/dj_pipeline/utils/streams_maker.py,2024-11-05 11:49:22+00:00,2024-11-05T15:26:48Z,"```suggestion
        definition = f"""""" # {device_title} placement and operation for a particular time period, \
        at a certain location, for a given experiment (auto-generated with aeon_mecha-{aeon.__version__})
```
Could we split the definition over multiple lines, so we could drop noqa: E501? Would something like this work?
",,,,,78,RIGHT,39,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829238593,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -134,18 +142,20 @@ class DeviceDataStream(dj.Imported):
 
         @property
         def key_source(self):
-            f""""""
-            Only the combination of Chunk and {device_type} with overlapping time
+            f""""""Only the combination of Chunk and {device_type} with overlapping time.",aeon/dj_pipeline/utils/streams_maker.py,2024-11-05 12:06:27+00:00,2024-11-05T15:26:48Z,"```suggestion
            """"""Only the combination of Chunk and ``device_type`` with overlapping time.
```
Since this is just docstring we can just use monospace formatting and drop noqa: B021",,,,,145,RIGHT,93,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829239853,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -134,18 +142,20 @@ class DeviceDataStream(dj.Imported):
 
         @property
         def key_source(self):
-            f""""""
-            Only the combination of Chunk and {device_type} with overlapping time
+            f""""""Only the combination of Chunk and {device_type} with overlapping time.
+
             +  Chunk(s) that started after {device_type} install time and ended before {device_type} remove time
             +  Chunk(s) that started after {device_type} install time for {device_type} that are not yet removed
-            """"""
+            """"""  # noqa B021",aeon/dj_pipeline/utils/streams_maker.py,2024-11-05 12:07:28+00:00,2024-11-05T15:26:48Z,"```suggestion
            """"""
```
and change all `{device_type}` in docstring to use monospace formatting",,,,,149,RIGHT,98,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829244808,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -262,9 +273,15 @@ def main(create_tables=True):
             replacements = {
                 ""DeviceDataStream"": f""{device_type}{stream_type}"",
                 ""ExperimentDevice"": device_type,
-                'f""chunk_start >= {dj.utils.from_camel_case(device_type)}_install_time""': f""'chunk_start >= {dj.utils.from_camel_case(device_type)}_install_time'"",
-                """"""f'chunk_start < IFNULL({dj.utils.from_camel_case(device_type)}_removal_time, ""2200-01-01"")'"""""": f""""""'chunk_start < IFNULL({dj.utils.from_camel_case(device_type)}_removal_time, ""2200-01-01"")'"""""",
-                'f""{dj.utils.from_camel_case(device_type)}_name""': f""'{dj.utils.from_camel_case(device_type)}_name'"",
+                'f""chunk_start >= {dj.utils.from_camel_case(device_type)}_install_time""': (
+                    f""'chunk_start >= {dj.utils.from_camel_case(device_type)}_install_time'""
+                ),
+                """"""f'chunk_start < IFNULL({dj.utils.from_camel_case(device_type)}_removal_time, ""2200-01-01"")'"""""": (  # noqa E501
+                    f""""""'chunk_start < IFNULL({dj.utils.from_camel_case(device_type)}_removal_time,""2200-01-01"")'""""""  # noqa E501
+                ),
+                'f""{dj.utils.from_camel_case(device_type)}_name""': (
+                    f""'{dj.utils.from_camel_case(device_type)}_name'""",aeon/dj_pipeline/utils/streams_maker.py,2024-11-05 12:11:20+00:00,2024-11-05T15:26:48Z,We can refactor the repeated `dj.utils.from_camel_case(device_type)` as was done in L150,,,,,283,RIGHT,135,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829250184,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -147,11 +149,15 @@ def load(root, reader, start=None, end=None, time=None, tolerance=None, epoch=No
 
             if not data.index.has_duplicates:
                 warnings.warn(
-                    f""data index for {reader.pattern} contains out-of-order timestamps!"", stacklevel=2
+                    f""data index for {reader.pattern} contains out-of-order timestamps!"",
+                    stacklevel=2,",aeon/io/api.py,2024-11-05 12:15:07+00:00,2024-11-05T15:26:48Z,"```suggestion
                    f""data index for {reader.pattern} contains out-of-order timestamps!"", stacklevel=2
```
Revert black",,152.0,RIGHT,,153,RIGHT,12,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829251188,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -147,11 +149,15 @@ def load(root, reader, start=None, end=None, time=None, tolerance=None, epoch=No
 
             if not data.index.has_duplicates:
                 warnings.warn(
-                    f""data index for {reader.pattern} contains out-of-order timestamps!"", stacklevel=2
+                    f""data index for {reader.pattern} contains out-of-order timestamps!"",
+                    stacklevel=2,
                 )
                 data = data.sort_index()
             else:
-                warnings.warn(f""data index for {reader.pattern} contains duplicate keys!"", stacklevel=2)
+                warnings.warn(
+                    f""data index for {reader.pattern} contains duplicate keys!"",
+                    stacklevel=2,
+                )",aeon/io/api.py,2024-11-05 12:15:52+00:00,2024-11-05T15:26:48Z,"```suggestion
                warnings.warn(f""data index for {reader.pattern} contains duplicate keys!"", stacklevel=2)
```
Revert black",,157.0,RIGHT,,160,RIGHT,20,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829256566,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -70,7 +74,11 @@ def read(self, file):
         ticks = np.ndarray(length, dtype=np.uint16, buffer=data, offset=9, strides=stride)
         seconds = ticks * _SECONDS_PER_TICK + seconds
         payload = np.ndarray(
-            payloadshape, dtype=payloadtype, buffer=data, offset=11, strides=(stride, elementsize)
+            payloadshape,
+            dtype=payloadtype,
+            buffer=data,
+            offset=11,
+            strides=(stride, elementsize),",aeon/io/reader.py,2024-11-05 12:19:48+00:00,2024-11-05T15:26:48Z,"```suggestion
            payloadshape, dtype=payloadtype, buffer=data, offset=11, strides=(stride, elementsize)
```
Revert black",,77.0,RIGHT,,81,RIGHT,31,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829277659,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -50,81 +54,93 @@ class _Weight(_reader.Harp):
     """"""
 
     def __init__(self, pattern):
+        """"""Initializes  the Weight class.""""""",aeon/schema/foraging.py,2024-11-05 12:34:52+00:00,2024-11-05T15:26:48Z,"```suggestion
        """"""Initializes the Weight class.""""""
```",,,,,57,RIGHT,26,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829317530,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -138,22 +149,21 @@ def read(self, file):
 
 
 class JsonList(Reader):
-    """"""Extracts data from json list (.jsonl) files, where the key ""seconds""
-    stores the Aeon timestamp, in seconds.
-    """"""
+    """"""Extracts data from .jsonl files, where the key ""seconds"" stores the Aeon timestamp (s).""""""
 
     def __init__(self, pattern, columns=(), root_key=""value"", extension=""jsonl""):
+        """"""Initialize the object with the specified pattern, columns, and root key.""""""
         super().__init__(pattern, columns, extension)
         self.columns = columns
         self.root_key = root_key
 
     def read(self, file):
         """"""Reads data from the specified jsonl file.""""""
-        with open(file, ""r"") as f:
+        with open(file) as f:
             df = pd.read_json(f, lines=True)
         df.set_index(""seconds"", inplace=True)
         for column in self.columns:
-            df[column] = df[self.root_key].apply(lambda x: x[column])
+            df[column] = df[self.root_key].apply(lambda x: x[column])  # noqa B023",aeon/io/reader.py,2024-11-05 13:03:38+00:00,2024-11-05T15:26:48Z,"Or
```suggestion
            df[column] = df[self.root_key].apply(lambda x, col=column: x[col])
```",,,,164.0,166,RIGHT,82,93.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829318550,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -384,11 +402,18 @@ def read(self, file: Path) -> pd.DataFrame:
             if bonsai_sleap_v == BONSAI_SLEAP_V3:
                 # combine all identity_likelihood cols into a single col as dict
                 part_data[""identity_likelihood""] = part_data.apply(
-                    lambda row: {identity: row[f""{identity}_likelihood""] for identity in identities}, axis=1
+                    lambda row: {identity: row[f""{identity}_likelihood""] for identity in identities},
+                    axis=1,",aeon/io/reader.py,2024-11-05 13:04:22+00:00,2024-11-05T15:26:48Z,"```suggestion
                    lambda row: {identity: row[f""{identity}_likelihood""] for identity in identities}, axis=1
```
Revert black",413.0,405.0,RIGHT,414.0,406,RIGHT,156,334.0,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829319469,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -384,11 +402,18 @@ def read(self, file: Path) -> pd.DataFrame:
             if bonsai_sleap_v == BONSAI_SLEAP_V3:
                 # combine all identity_likelihood cols into a single col as dict
                 part_data[""identity_likelihood""] = part_data.apply(
-                    lambda row: {identity: row[f""{identity}_likelihood""] for identity in identities}, axis=1
+                    lambda row: {identity: row[f""{identity}_likelihood""] for identity in identities},
+                    axis=1,
                 )
                 part_data.drop(columns=columns[1 : (len(identities) + 1)], inplace=True)
                 part_data = part_data[  # reorder columns
-                    [""identity"", ""identity_likelihood"", f""{part}_x"", f""{part}_y"", f""{part}_likelihood""]
+                    [
+                        ""identity"",
+                        ""identity_likelihood"",
+                        f""{part}_x"",
+                        f""{part}_y"",
+                        f""{part}_likelihood"",
+                    ]",aeon/io/reader.py,2024-11-05 13:05:02+00:00,2024-11-05T15:26:48Z,"```suggestion
                    [""identity"", ""identity_likelihood"", f""{part}_x"", f""{part}_y"", f""{part}_likelihood""]
```
Revert black",,410.0,RIGHT,,416,RIGHT,167,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829467328,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,42 +1,58 @@
+""""""Octagon schema definition.""""""
+
 import aeon.io.reader as _reader
 from aeon.schema.streams import Stream, StreamGroup
 
 
 class Photodiode(Stream):
     def __init__(self, path):
+        """"""Initializes the Photodiode stream.""""""
         super().__init__(_reader.Harp(f""{path}_44_*"", columns=[""adc"", ""encoder""]))
 
 
 class OSC(StreamGroup):
     def __init__(self, path):
+        """"""Initializes the OSC stream group.""""""
         super().__init__(path)
 
     class BackgroundColor(Stream):
         def __init__(self, pattern):
+            """"""Initializes the BackgroundColor stream.""""""
             super().__init__(
-                _reader.Csv(f""{pattern}_backgroundcolor_*"", columns=[""typetag"", ""r"", ""g"", ""b"", ""a""])
+                _reader.Csv(
+                    f""{pattern}_backgroundcolor_*"",
+                    columns=[""typetag"", ""r"", ""g"", ""b"", ""a""],
+                )",aeon/schema/octagon.py,2024-11-05 14:36:27+00:00,2024-11-05T15:26:48Z,"```suggestion
                _reader.Csv(f""{pattern}_backgroundcolor_*"", columns=[""typetag"", ""r"", ""g"", ""b"", ""a""])
```
Revert black",,22.0,RIGHT,,25,RIGHT,26,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829478079,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -72,14 +89,17 @@ def __init__(self, pattern):
 
     class Response(Stream):
         def __init__(self, pattern):
+            """"""Initialises the Response class.""""""
             super().__init__(
                 _reader.Csv(
-                    f""{pattern}_response_*"", columns=[""typetag"", ""wall_id"", ""poke_id"", ""response_time""]
+                    f""{pattern}_response_*"",
+                    columns=[""typetag"", ""wall_id"", ""poke_id"", ""response_time""],",aeon/schema/octagon.py,2024-11-05 14:42:12+00:00,2024-11-05T15:26:48Z,"```suggestion
                    f""{pattern}_response_*"", columns=[""typetag"", ""wall_id"", ""poke_id"", ""response_time""]
```
Revert black",,95.0,RIGHT,,96,RIGHT,79,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829487358,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -174,4 +186,12 @@
 )
 
 
-__all__ = [""exp01"", ""exp02"", ""octagon01"", ""social01"", ""social02"", ""social03"", ""social04""]
+__all__ = [
+    ""exp01"",
+    ""exp02"",
+    ""octagon01"",
+    ""social01"",
+    ""social02"",
+    ""social03"",
+    ""social04"",
+]",aeon/schema/schemas.py,2024-11-05 14:47:13+00:00,2024-11-05T15:26:48Z,"```suggestion
__all__ = [""exp01"", ""exp02"", ""octagon01"", ""social01"", ""social02"", ""social03"", ""social04""]
```
Revert black",,189.0,RIGHT,,197,RIGHT,47,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829489211,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -1,69 +1,87 @@
+""""""This module defines the schema for the social_02 dataset.""""""
+
 import aeon.io.reader as _reader
 from aeon.schema import core, foraging
 from aeon.schema.streams import Stream, StreamGroup
 
 
 class Environment(StreamGroup):
     def __init__(self, path):
+        """"""Initializes the Environment stream group.""""""
         super().__init__(path)
 
     EnvironmentState = core.EnvironmentState
 
     class BlockState(Stream):
         def __init__(self, path):
+            """"""Initializes the BlockState stream.""""""
             super().__init__(
-                _reader.Csv(f""{path}_BlockState_*"", columns=[""pellet_ct"", ""pellet_ct_thresh"", ""due_time""])
+                _reader.Csv(
+                    f""{path}_BlockState_*"",
+                    columns=[""pellet_ct"", ""pellet_ct_thresh"", ""due_time""],
+                )",aeon/schema/social_02.py,2024-11-05 14:48:15+00:00,2024-11-05T15:26:49Z,"```suggestion
                _reader.Csv(f""{path}_BlockState_*"", columns=[""pellet_ct"", ""pellet_ct_thresh"", ""due_time""])
```
Revert black",,19.0,RIGHT,,22,RIGHT,23,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/comments/1829515344,lochhh,48493cbc0de8b6e2a5e20bcebc0f30f3f7e6719b,886b6e007a72edbc0e8801cda882762d82fd60ab,"@@ -97,22 +97,12 @@ lint.select = [
 ]
 line-length = 108
 lint.ignore = [
-  ""D100"",    # skip adding docstrings for module
-  ""D104"",    # ignore missing docstring in public package
-  ""D105"",    # skip adding docstrings for magic methods
-  ""D107"",    # skip adding docstrings for __init__
-  ""E201"",
-  ""E202"",
-  ""E203"",
-  ""E231"",
   ""E731"",
-  ""E702"",
-  ""S101"",
-  ""PT004"",  # Rule `PT004` is deprecated and will be removed in a future release.
-  ""PT013"",
-  ""PLR0912"",
+  ""PT004"",  # Deprecated and will be removed in a future release.
+  ""PLR0912"", 
   ""PLR0913"",
   ""PLR0915"",
+  ""UP017""  # skip `datetime.UTC` alias",pyproject.toml,2024-11-05 15:02:52+00:00,2024-11-05T15:26:49Z,Remove this as project requires python >= 3.11 we can use the `datetime.UTC` alias,,,,,105,RIGHT,22,,line,https://api.github.com/repos/SainsburyWellcomeCentre/aeon_mecha/pulls/443,SainsburyWellcomeCentre/aeon_mecha,9be1f8eafe59d9db06cd9d4b11d7cace799d8343
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1804413477,Pefington,fb9cb401dac354221e97fa956328e7d7faf74e2d,0c192a2aa6be09d349ae4000174e6c5165b71b62,"@@ -0,0 +1,42 @@
+try:
+    from urllib.error import URLError
+    from urllib.request import Request, urlopen
+except ImportError:
+    from urllib2 import Request, URLError, urlopen  # type: ignore
+from ssl import SSLError
+
+
+def verify_token(token, license_key, is_stream=True):
+    if not token or not license_key:
+        raise ValueError(""API token and license key is required."")
+
+    path = ""stream/license"" if is_stream else ""sdk-webhooks""
+    try:
+        req = Request(
+            ""https://api.platerecognizer.com/v1/{}/{}/"".format(
+                path, license_key.strip()
+            )
",docker/dd-extension/backend/utils.py,2024-10-17 09:17:48+00:00,2024-10-17T11:39:05Z,"```suggestion
            f""https://api.platerecognizer.com/v1/{path}/{license_key.strip()}/""
```",,16.0,RIGHT,,18,RIGHT,18,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,parkpow/deep-license-plate-recognition,39eb3e9a4e416dc5bd5d6a6e92ac6c285281cf58
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1804554056,Pefington,cdeab34e2877bcfaee8a115b76be392fb33058cb,0c192a2aa6be09d349ae4000174e6c5165b71b62,"@@ -0,0 +1,195 @@
+import {
+  Container,
+  Row,
+  Col,
+  Card,
+  Button,
+  Alert,
+  Navbar,
+  Nav,
+} from ""react-bootstrap"";
+import React, { useState } from ""react"";
+
+import { useDockerDesktopClient } from ""../hooks/useDockerDesktopClient"";
+
+import Form from ""react-bootstrap/Form"";
+import Uninstall from ""./Uninstall"";
+import Update from ""./Update"";
+
+import { openBrowserUrl } from ""../helpers"";
+import ShowCommand from ""./ShowCommand"";
+import Loader from ""./Loader"";
+
+export default function Stream() {
+  const STREAM_IMAGE = ""platerecognizer/alpr-stream"";
+  const [command, setCommand] = useState<string>("""");
+  const [license, setLicense] = useState<string>("""");
+  const [tokenValidated, setTokenValidated] = useState(false);
+  const [isLoading, setLoading] = useState(false);
+
+  const ddClient = useDockerDesktopClient();
+
+  const handleLinkClick = (e: any) => {
+    e.preventDefault();
+    openBrowserUrl(ddClient, e.target.href);
+  };
+
+  const handleConfigureClick = (e: any) => {
+    if (license) {
+      const url = ""https://app.platerecognizer.com/stream-config/"" + license;
+      openBrowserUrl(ddClient, url);
+    } else {
+      ddClient.desktopUI.toast.error(""License Key is required"");
+    }
+  };
+  const handleInputChange = (e: any) => {
+    const { name, value } = e.target;
+    if (name == ""license"") {
+      setLicense(value);
+    }
+    setTokenValidated(false);
+  };
+
+  const handleSubmit = async (event: React.SyntheticEvent) => {
+    event.preventDefault();
+    const form: any = event.target;
+    const formData = new FormData(form);
+
+    const data: any = Object.fromEntries(formData.entries());
+    // console.log(data);
+    setLoading(true);
+    ddClient.extension.vm?.service
+      ?.post(""/verify-token"", data)
+      .then((res: any) => {
+        console.debug(res);
+        const valid = res[""valid""];
+        const message = res[""message""];
+        if (valid) {
+          // Pull image and update
+          ddClient.docker.cli.exec(""pull"", [STREAM_IMAGE]).then((result) => {
+            const autoBoot = data.startOnBoot
+              ? "" --restart unless-stopped""
+              : ""--rm"";
+            const command = `docker run ${autoBoot} -t -v ${data.streamPath}:/user-data/ -e LICENSE_KEY=${data.license} -e TOKEN=${data.token} ${STREAM_IMAGE}`;
+            setCommand(command);
+            setTokenValidated(valid);
+            setLoading(false);
+          });
+        } else {
+          setLoading(false);
+          ddClient.desktopUI.toast.error(`Verify Token: ${message}`);
+        }
+      });
+  };
+
+  return (
+    <Form onSubmit={handleSubmit}>
+      <Loader isLoading={isLoading} />
+      <Form.Group as={Row} className=""mb-3"" controlId=""streamToken"">
+        <Form.Label column sm={4}>
+          Please enter your Plate Recognizer{"" ""}
+          <a
+            href=""https://app.platerecognizer.com/accounts/plan/#sdk/?utm_source=dd-extension&utm_medium=app""
",docker/dd-extension/ui/src/components/Stream.tsx,2024-10-17 10:55:35+00:00,2024-10-17T11:39:05Z,"```suggestion
            href=""https://app.platerecognizer.com/service/stream/""
```",,,,,92,RIGHT,92,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,parkpow/deep-license-plate-recognition,39eb3e9a4e416dc5bd5d6a6e92ac6c285281cf58
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1804555158,Pefington,cdeab34e2877bcfaee8a115b76be392fb33058cb,0c192a2aa6be09d349ae4000174e6c5165b71b62,"@@ -0,0 +1,195 @@
+import {
+  Container,
+  Row,
+  Col,
+  Card,
+  Button,
+  Alert,
+  Navbar,
+  Nav,
+} from ""react-bootstrap"";
+import React, { useState } from ""react"";
+
+import { useDockerDesktopClient } from ""../hooks/useDockerDesktopClient"";
+
+import Form from ""react-bootstrap/Form"";
+import Uninstall from ""./Uninstall"";
+import Update from ""./Update"";
+
+import { openBrowserUrl } from ""../helpers"";
+import ShowCommand from ""./ShowCommand"";
+import Loader from ""./Loader"";
+
+export default function Stream() {
+  const STREAM_IMAGE = ""platerecognizer/alpr-stream"";
+  const [command, setCommand] = useState<string>("""");
+  const [license, setLicense] = useState<string>("""");
+  const [tokenValidated, setTokenValidated] = useState(false);
+  const [isLoading, setLoading] = useState(false);
+
+  const ddClient = useDockerDesktopClient();
+
+  const handleLinkClick = (e: any) => {
+    e.preventDefault();
+    openBrowserUrl(ddClient, e.target.href);
+  };
+
+  const handleConfigureClick = (e: any) => {
+    if (license) {
+      const url = ""https://app.platerecognizer.com/stream-config/"" + license;
+      openBrowserUrl(ddClient, url);
+    } else {
+      ddClient.desktopUI.toast.error(""License Key is required"");
+    }
+  };
+  const handleInputChange = (e: any) => {
+    const { name, value } = e.target;
+    if (name == ""license"") {
+      setLicense(value);
+    }
+    setTokenValidated(false);
+  };
+
+  const handleSubmit = async (event: React.SyntheticEvent) => {
+    event.preventDefault();
+    const form: any = event.target;
+    const formData = new FormData(form);
+
+    const data: any = Object.fromEntries(formData.entries());
+    // console.log(data);
+    setLoading(true);
+    ddClient.extension.vm?.service
+      ?.post(""/verify-token"", data)
+      .then((res: any) => {
+        console.debug(res);
+        const valid = res[""valid""];
+        const message = res[""message""];
+        if (valid) {
+          // Pull image and update
+          ddClient.docker.cli.exec(""pull"", [STREAM_IMAGE]).then((result) => {
+            const autoBoot = data.startOnBoot
+              ? "" --restart unless-stopped""
+              : ""--rm"";
+            const command = `docker run ${autoBoot} -t -v ${data.streamPath}:/user-data/ -e LICENSE_KEY=${data.license} -e TOKEN=${data.token} ${STREAM_IMAGE}`;
+            setCommand(command);
+            setTokenValidated(valid);
+            setLoading(false);
+          });
+        } else {
+          setLoading(false);
+          ddClient.desktopUI.toast.error(`Verify Token: ${message}`);
+        }
+      });
+  };
+
+  return (
+    <Form onSubmit={handleSubmit}>
+      <Loader isLoading={isLoading} />
+      <Form.Group as={Row} className=""mb-3"" controlId=""streamToken"">
+        <Form.Label column sm={4}>
+          Please enter your Plate Recognizer{"" ""}
+          <a
+            href=""https://app.platerecognizer.com/accounts/plan/#sdk/?utm_source=dd-extension&utm_medium=app""
+            onClick={handleLinkClick}
+          >
+            API Token
+          </a>
+          :
+        </Form.Label>
+        <Col sm={8}>
+          <Form.Control
+            type=""text""
+            placeholder=""Token""
+            required
+            name=""token""
+            onChange={handleInputChange}
+          />
+        </Col>
+      </Form.Group>
+
+      <Form.Group as={Row} className=""mb-3"" controlId=""streamLicense"">
+        <Form.Label column sm={4}>
+          Please enter your{"" ""}
+          <a
+            href=""https://app.platerecognizer.com/accounts/plan/#sdk/?utm_source=dd-extension&utm_medium=app""
",docker/dd-extension/ui/src/components/Stream.tsx,2024-10-17 10:56:25+00:00,2024-10-17T11:39:05Z,"
```suggestion
            href=""https://app.platerecognizer.com/service/stream/""
```",,,,,114,RIGHT,114,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,parkpow/deep-license-plate-recognition,39eb3e9a4e416dc5bd5d6a6e92ac6c285281cf58
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1804565898,Pefington,cdeab34e2877bcfaee8a115b76be392fb33058cb,0c192a2aa6be09d349ae4000174e6c5165b71b62,"@@ -0,0 +1,4 @@
+[ZoneTransfer]
",docker/dd-extension/logo.svg:Zone.Identifier,2024-10-17 11:04:48+00:00,2024-10-17T11:39:05Z,"You can remove this file, it's windows metadata dumped when copying from NTFS to an other filesystem.",,,,,1,RIGHT,1,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,parkpow/deep-license-plate-recognition,39eb3e9a4e416dc5bd5d6a6e92ac6c285281cf58
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1804572792,Pefington,cdeab34e2877bcfaee8a115b76be392fb33058cb,0c192a2aa6be09d349ae4000174e6c5165b71b62,"@@ -0,0 +1,245 @@
+import {
+  Container,
+  Row,
+  Col,
+  Card,
+  Button,
+  Alert,
+  Navbar,
+  Nav,
+} from ""react-bootstrap"";
+
+import Form from ""react-bootstrap/Form"";
+
+// import { verifyToken } from ""./helpers"";
+import React, { useState } from ""react"";
+import { useDockerDesktopClient } from ""../hooks/useDockerDesktopClient"";
+import Loader from ""./Loader"";
+import Uninstall from ""./Uninstall"";
+import Update from ""./Update"";
+import ShowCommand from ""./ShowCommand"";
+import {openBrowserUrl} from '../helpers'
+
+
+const snapshotImageOptions = [
+  {
+    label: ""Intel CPU"",
+    value: ""platerecognizer/alpr:latest"",
+    uninstall: true,
+  },
+  {
+    label: ""Raspberry"",
+    value: ""platerecognizer/alpr-raspberry-pi:latest"",
+    uninstall: false,
+  },
+  {
+    label: ""GPU (Nvidia Only)"",
+    value: ""platerecognizer/alpr-gpu:latest"",
+    uninstall: false,
+  },
+  {
+    label: ""Jetson Nano"",
+    value: ""platerecognizer/alpr-jetson:latest"",
+    uninstall: true,
+  },
+  {
+    label: ""ZCU104"",
+    value: ""platerecognizer/alpr-zcu104:latest"",
+    uninstall: false,
+  },
+  {
+    label: ""Thailand"",
+    value: ""platerecognizer/alpr:thailand"",
+    uninstall: false,
+  },
+];
+
+const DEFAULT_SNAPSHOT_IMAGE = snapshotImageOptions[0][""value""];
+
+export default function Snapshot() {
+  const [tokenValidated, setTokenValidated] = useState(false);
+  const [uninstall, setUninstall] = useState(true);
+  const [isLoading, setLoading] = useState(false);
+  const [command, setCommand] = useState<string>("""");
+  const [curlPort, setCurlPort] = useState("""");
+  const [image, setImage] = useState(DEFAULT_SNAPSHOT_IMAGE);
+  const ddClient = useDockerDesktopClient();
+
+  const handleInputChange = (e: any) => {
+    setTokenValidated(false);
+  };
+
+  const handleImageChange = (e: any) => {
+    setTokenValidated(false);
+    let image: string = e.target.value;
+    setImage(image);
+    const snapshotImageOption: any = snapshotImageOptions.find((element) => {
+      return element.value === image;
+    });
+    setUninstall(snapshotImageOption.uninstall);
+  };
+
+  interface SnapshotData {
+    port: string;
+    license: string;
+    token: string;
+    image: string;
+  }
+
+  const handleSubmit = async (event: React.SyntheticEvent) => {
+    event.preventDefault();
+    const form: any = event.target;
+    const formData = new FormData(form);
+
+    const data: any = Object.fromEntries(formData.entries());
+    // console.log(data);
+    setCurlPort(data.port);
+    setLoading(true);
+
+    ddClient.extension.vm?.service
+      ?.post(""/verify-token"", data)
+      .then((res: any) => {
+        console.debug(res);
+        const valid = res[""valid""];
+        const message = res[""message""];
+        if (valid) {
+          // Pull image and update
+          ddClient.docker.cli.exec(""pull"", [data.image]).then((result) => {
+            const autoBoot = data.startOnBoot
+              ? "" --restart unless-stopped""
+              : ""--rm"";
+            const gpus = data.image.includes(""gpu"") ? "" --gpus all"" : """";
+            const nvidia = data.image.includes(""jetson"")
+              ? "" --runtime nvidia""
+              : """";
+            const command = `docker run${gpus}${nvidia}${autoBoot} -t -p ${data.port}:8080 -v license:/license -e LICENSE_KEY=${data.license} -e TOKEN=${data.token} ${data.image}`;
+            setCommand(command);
+            setTokenValidated(valid);
+            setLoading(false);
+          });
+        } else {
+          setLoading(false);
+          ddClient.desktopUI.toast.error(`Verify Token: ${message}`);
+        }
+      });
+  };
+
+  const handleLinkClick = (e: any) => {
+    e.preventDefault();
+    openBrowserUrl(ddClient, e.target.href);
+  };
+  return (
+    <Form onSubmit={handleSubmit}>
+      <Loader isLoading={isLoading} />
+
+      <Form.Group as={Row} className=""mb-3"" controlId=""snapshotToken"">
+        <Form.Label column sm={4}>
+          Please enter your Plate Recognizer{"" ""}
+          <a href=""https://app.platerecognizer.com/accounts/plan/#sdk/?utm_source=dd-extension&utm_medium=app"" onClick={handleLinkClick}>
",docker/dd-extension/ui/src/components/Snapshot.tsx,2024-10-17 11:10:33+00:00,2024-10-17T11:39:05Z,"```suggestion
          <a href=""https://app.platerecognizer.com/service/snapshot-sdk/"" onClick={handleLinkClick}>
```",,,,,138,RIGHT,138,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,parkpow/deep-license-plate-recognition,39eb3e9a4e416dc5bd5d6a6e92ac6c285281cf58
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1804583111,Pefington,cdeab34e2877bcfaee8a115b76be392fb33058cb,0c192a2aa6be09d349ae4000174e6c5165b71b62,"@@ -0,0 +1,245 @@
+import {
+  Container,
+  Row,
+  Col,
+  Card,
+  Button,
+  Alert,
+  Navbar,
+  Nav,
+} from ""react-bootstrap"";
+
+import Form from ""react-bootstrap/Form"";
+
+// import { verifyToken } from ""./helpers"";
+import React, { useState } from ""react"";
+import { useDockerDesktopClient } from ""../hooks/useDockerDesktopClient"";
+import Loader from ""./Loader"";
+import Uninstall from ""./Uninstall"";
+import Update from ""./Update"";
+import ShowCommand from ""./ShowCommand"";
+import {openBrowserUrl} from '../helpers'
+
+
+const snapshotImageOptions = [
+  {
+    label: ""Intel CPU"",
+    value: ""platerecognizer/alpr:latest"",
+    uninstall: true,
+  },
+  {
+    label: ""Raspberry"",
+    value: ""platerecognizer/alpr-raspberry-pi:latest"",
+    uninstall: false,
+  },
+  {
+    label: ""GPU (Nvidia Only)"",
+    value: ""platerecognizer/alpr-gpu:latest"",
+    uninstall: false,
+  },
+  {
+    label: ""Jetson Nano"",
+    value: ""platerecognizer/alpr-jetson:latest"",
+    uninstall: true,
+  },
+  {
+    label: ""ZCU104"",
+    value: ""platerecognizer/alpr-zcu104:latest"",
+    uninstall: false,
+  },
+  {
+    label: ""Thailand"",
+    value: ""platerecognizer/alpr:thailand"",
+    uninstall: false,
+  },
+];
+
+const DEFAULT_SNAPSHOT_IMAGE = snapshotImageOptions[0][""value""];
+
+export default function Snapshot() {
+  const [tokenValidated, setTokenValidated] = useState(false);
+  const [uninstall, setUninstall] = useState(true);
+  const [isLoading, setLoading] = useState(false);
+  const [command, setCommand] = useState<string>("""");
+  const [curlPort, setCurlPort] = useState("""");
+  const [image, setImage] = useState(DEFAULT_SNAPSHOT_IMAGE);
+  const ddClient = useDockerDesktopClient();
+
+  const handleInputChange = (e: any) => {
+    setTokenValidated(false);
+  };
+
+  const handleImageChange = (e: any) => {
+    setTokenValidated(false);
+    let image: string = e.target.value;
+    setImage(image);
+    const snapshotImageOption: any = snapshotImageOptions.find((element) => {
+      return element.value === image;
+    });
+    setUninstall(snapshotImageOption.uninstall);
+  };
+
+  interface SnapshotData {
+    port: string;
+    license: string;
+    token: string;
+    image: string;
+  }
+
+  const handleSubmit = async (event: React.SyntheticEvent) => {
+    event.preventDefault();
+    const form: any = event.target;
+    const formData = new FormData(form);
+
+    const data: any = Object.fromEntries(formData.entries());
+    // console.log(data);
+    setCurlPort(data.port);
+    setLoading(true);
+
+    ddClient.extension.vm?.service
+      ?.post(""/verify-token"", data)
+      .then((res: any) => {
+        console.debug(res);
+        const valid = res[""valid""];
+        const message = res[""message""];
+        if (valid) {
+          // Pull image and update
+          ddClient.docker.cli.exec(""pull"", [data.image]).then((result) => {
+            const autoBoot = data.startOnBoot
+              ? "" --restart unless-stopped""
+              : ""--rm"";
+            const gpus = data.image.includes(""gpu"") ? "" --gpus all"" : """";
+            const nvidia = data.image.includes(""jetson"")
+              ? "" --runtime nvidia""
+              : """";
+            const command = `docker run${gpus}${nvidia}${autoBoot} -t -p ${data.port}:8080 -v license:/license -e LICENSE_KEY=${data.license} -e TOKEN=${data.token} ${data.image}`;
+            setCommand(command);
+            setTokenValidated(valid);
+            setLoading(false);
+          });
+        } else {
+          setLoading(false);
+          ddClient.desktopUI.toast.error(`Verify Token: ${message}`);
+        }
+      });
+  };
+
+  const handleLinkClick = (e: any) => {
+    e.preventDefault();
+    openBrowserUrl(ddClient, e.target.href);
+  };
+  return (
+    <Form onSubmit={handleSubmit}>
+      <Loader isLoading={isLoading} />
+
+      <Form.Group as={Row} className=""mb-3"" controlId=""snapshotToken"">
+        <Form.Label column sm={4}>
+          Please enter your Plate Recognizer{"" ""}
+          <a href=""https://app.platerecognizer.com/accounts/plan/#sdk/?utm_source=dd-extension&utm_medium=app"" onClick={handleLinkClick}>
+            API Token
+          </a>
+          :
+        </Form.Label>
+        <Col sm={8}>
+          <Form.Control
+            type=""text""
+            placeholder=""Token""
+            required
+            name=""token""
+            onChange={handleInputChange}
+          />
+        </Col>
+      </Form.Group>
+
+      <Form.Group as={Row} className=""mb-3"" controlId=""snapshotLicense"">
+        <Form.Label column sm={4}>
+          Please enter your{"" ""}
+          <a href=""https://app.platerecognizer.com/accounts/plan/#sdk/?utm_source=dd-extension&utm_medium=app"" onClick={handleLinkClick}>
",docker/dd-extension/ui/src/components/Snapshot.tsx,2024-10-17 11:19:02+00:00,2024-10-17T11:39:05Z,"```suggestion
          <a href=""https://app.platerecognizer.com/service/snapshot-sdk/"" onClick={handleLinkClick}>
```",,,,,157,RIGHT,157,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,parkpow/deep-license-plate-recognition,39eb3e9a4e416dc5bd5d6a6e92ac6c285281cf58
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1804590059,Pefington,cdeab34e2877bcfaee8a115b76be392fb33058cb,0c192a2aa6be09d349ae4000174e6c5165b71b62,"@@ -0,0 +1,245 @@
+import {
+  Container,
+  Row,
+  Col,
+  Card,
+  Button,
+  Alert,
+  Navbar,
+  Nav,
+} from ""react-bootstrap"";
+
+import Form from ""react-bootstrap/Form"";
+
+// import { verifyToken } from ""./helpers"";
+import React, { useState } from ""react"";
+import { useDockerDesktopClient } from ""../hooks/useDockerDesktopClient"";
+import Loader from ""./Loader"";
+import Uninstall from ""./Uninstall"";
+import Update from ""./Update"";
+import ShowCommand from ""./ShowCommand"";
+import {openBrowserUrl} from '../helpers'
+
+
+const snapshotImageOptions = [
+  {
+    label: ""Intel CPU"",
+    value: ""platerecognizer/alpr:latest"",
+    uninstall: true,
+  },
+  {
+    label: ""Raspberry"",
+    value: ""platerecognizer/alpr-raspberry-pi:latest"",
+    uninstall: false,
+  },
+  {
+    label: ""GPU (Nvidia Only)"",
+    value: ""platerecognizer/alpr-gpu:latest"",
+    uninstall: false,
+  },
+  {
+    label: ""Jetson Nano"",
+    value: ""platerecognizer/alpr-jetson:latest"",
+    uninstall: true,
+  },
+  {
+    label: ""ZCU104"",
+    value: ""platerecognizer/alpr-zcu104:latest"",
+    uninstall: false,
+  },
+  {
+    label: ""Thailand"",
+    value: ""platerecognizer/alpr:thailand"",
+    uninstall: false,
+  },
+];
+
+const DEFAULT_SNAPSHOT_IMAGE = snapshotImageOptions[0][""value""];
+
+export default function Snapshot() {
+  const [tokenValidated, setTokenValidated] = useState(false);
+  const [uninstall, setUninstall] = useState(true);
+  const [isLoading, setLoading] = useState(false);
+  const [command, setCommand] = useState<string>("""");
+  const [curlPort, setCurlPort] = useState("""");
+  const [image, setImage] = useState(DEFAULT_SNAPSHOT_IMAGE);
+  const ddClient = useDockerDesktopClient();
+
+  const handleInputChange = (e: any) => {
+    setTokenValidated(false);
+  };
+
+  const handleImageChange = (e: any) => {
+    setTokenValidated(false);
+    let image: string = e.target.value;
+    setImage(image);
+    const snapshotImageOption: any = snapshotImageOptions.find((element) => {
+      return element.value === image;
+    });
+    setUninstall(snapshotImageOption.uninstall);
+  };
+
+  interface SnapshotData {
+    port: string;
+    license: string;
+    token: string;
+    image: string;
+  }
+
+  const handleSubmit = async (event: React.SyntheticEvent) => {
+    event.preventDefault();
+    const form: any = event.target;
+    const formData = new FormData(form);
+
+    const data: any = Object.fromEntries(formData.entries());
+    // console.log(data);
+    setCurlPort(data.port);
+    setLoading(true);
+
+    ddClient.extension.vm?.service
+      ?.post(""/verify-token"", data)
+      .then((res: any) => {
+        console.debug(res);
+        const valid = res[""valid""];
+        const message = res[""message""];
+        if (valid) {
+          // Pull image and update
+          ddClient.docker.cli.exec(""pull"", [data.image]).then((result) => {
+            const autoBoot = data.startOnBoot
+              ? "" --restart unless-stopped""
+              : ""--rm"";
+            const gpus = data.image.includes(""gpu"") ? "" --gpus all"" : """";
+            const nvidia = data.image.includes(""jetson"")
+              ? "" --runtime nvidia""
+              : """";
+            const command = `docker run${gpus}${nvidia}${autoBoot} -t -p ${data.port}:8080 -v license:/license -e LICENSE_KEY=${data.license} -e TOKEN=${data.token} ${data.image}`;
+            setCommand(command);
+            setTokenValidated(valid);
+            setLoading(false);
+          });
+        } else {
+          setLoading(false);
+          ddClient.desktopUI.toast.error(`Verify Token: ${message}`);
+        }
+      });
+  };
+
+  const handleLinkClick = (e: any) => {
+    e.preventDefault();
+    openBrowserUrl(ddClient, e.target.href);
+  };
+  return (
+    <Form onSubmit={handleSubmit}>
+      <Loader isLoading={isLoading} />
+
+      <Form.Group as={Row} className=""mb-3"" controlId=""snapshotToken"">
+        <Form.Label column sm={4}>
+          Please enter your Plate Recognizer{"" ""}
+          <a href=""https://app.platerecognizer.com/accounts/plan/#sdk/?utm_source=dd-extension&utm_medium=app"" onClick={handleLinkClick}>
+            API Token
+          </a>
+          :
+        </Form.Label>
+        <Col sm={8}>
+          <Form.Control
+            type=""text""
+            placeholder=""Token""
+            required
+            name=""token""
+            onChange={handleInputChange}
+          />
+        </Col>
+      </Form.Group>
+
+      <Form.Group as={Row} className=""mb-3"" controlId=""snapshotLicense"">
+        <Form.Label column sm={4}>
+          Please enter your{"" ""}
+          <a href=""https://app.platerecognizer.com/accounts/plan/#sdk/?utm_source=dd-extension&utm_medium=app"" onClick={handleLinkClick}>
+            Snapshot License Key
+          </a>
+          :
+        </Form.Label>
+        <Col sm={8}>
+          <Form.Control
+            type=""text""
+            placeholder=""License Key""
+            required
+            name=""license""
+            onChange={handleInputChange}
+          />
+        </Col>
+      </Form.Group>
+
+      <Form.Group as={Row} className=""mb-3"" controlId=""snapshotRestartPolicy"">
+        <Form.Label column sm={4}>
+          Start Snapshot automatically on system startup?
+        </Form.Label>
+        <Col sm={8} className=""mt-2"">
+          <Form.Check
+            type=""switch""
+            name=""startOnBoot""
+            onChange={handleInputChange}
+          />
+        </Col>
+      </Form.Group>
+
+      <Form.Group as={Row} className=""mb-3"" controlId=""snapshotPort"">
+        <Form.Label column sm={4}>
+          Set the container port (default is 8080):
+        </Form.Label>
+        <Col sm={8}>
+          <Form.Control
+            type=""number""
+            min=""0""
+            max=""65535""
+            placeholder=""Port""
+            name=""port""
+            required
+            defaultValue={8080}
+            onChange={handleInputChange}
+          />
+        </Col>
+      </Form.Group>
+
+      <Form.Group as={Row} className=""mb-3"" controlId=""snapshotDockerImage"">
",docker/dd-extension/ui/src/components/Snapshot.tsx,2024-10-17 11:24:51+00:00,2024-10-17T11:39:05Z,"Could you make two separate dropdowns?
- One for the country
- One for the architecture
Up to date reference: https://guides.platerecognizer.com/docs/snapshot/manual-install/",,,,269.0,268,RIGHT,204,269.0,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/218,parkpow/deep-license-plate-recognition,39eb3e9a4e416dc5bd5d6a6e92ac6c285281cf58
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/226,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1932756839,adolfoarmas,1ca4b4c9bb53a69bcb5b1214bc919ccb5ab8ae34,8b68557a7b084b95d8c8c372e0c7eb848c1c3950,"@@ -41,6 +47,8 @@ def process_request(
     response = requests.post(os.getenv(""WEBHOOK_URL"", """"), data=data, files=files)
 
     if response.status_code == 200:
+        logging.info(""Webhook request sent successfully."")
         return ""Webhook request sent successfully."", response.status_code
     else:
+        logging.error(f""Webhook request failed. Response code: {response.status_code}"")
         return ""Webhook request failed."", response.status_code",webhooks/middleware/protocols/crop_plate.py,2025-01-28 19:39:08+00:00,2025-01-28T19:44:46Z,"```suggestion
    try:
        response = requests.post(os.getenv(""WEBHOOK_URL"", """"), data=data, files=files)
        response.raise_for_status()
        logging.info(f""Vehicle: {plate}. Request was successful."")
        return ""Request was successful"", response.status_code
    except requests.exceptions.RequestException as err:
        logging.error(f""Vehicle: {plate}. Error processing the request: {err}"")
        return f""Failed to process the request: {err}"", response.status_code
```",,47.0,RIGHT,,54,RIGHT,33,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/226,parkpow/deep-license-plate-recognition,f832a1a7d88de4a14d653c43c0ef513fa4d46b22
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/226,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1932757941,adolfoarmas,1ca4b4c9bb53a69bcb5b1214bc919ccb5ab8ae34,8b68557a7b084b95d8c8c372e0c7eb848c1c3950,"@@ -19,6 +24,7 @@ def process_request(
     json_data: dict[str, Any], upload_file: bytes | None = None
 ) -> tuple[str, int]:
     if not upload_file:
+        logging.error(""No file uploaded."")
         return ""No file uploaded."", 400
 
     data = json_data[""data""][""results""][0]",webhooks/middleware/protocols/crop_plate.py,2025-01-28 19:40:04+00:00,2025-01-28T19:44:46Z,"```suggestion
    data = json_data[""data""][""results""][0]
    plate = data.get(""plate"")
```",,,,30.0,30,RIGHT,24,24.0,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/226,parkpow/deep-license-plate-recognition,f832a1a7d88de4a14d653c43c0ef513fa4d46b22
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/226,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1932762312,adolfoarmas,1ca4b4c9bb53a69bcb5b1214bc919ccb5ab8ae34,8b68557a7b084b95d8c8c372e0c7eb848c1c3950,"@@ -69,6 +69,7 @@ def process_request(
                 username, password, vms_api_url, camera_uid, camera_id, plate, timestamp
             )",webhooks/middleware/protocols/salient.py,2025-01-28 19:43:36+00:00,2025-01-28T19:44:46Z,"```suggestion
            )
            logging.info(f""Vehicle: {plate}. Request was successful."")
```",,,,70.0,70,RIGHT,20,21.0,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/226,parkpow/deep-license-plate-recognition,f832a1a7d88de4a14d653c43c0ef513fa4d46b22
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/220,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1830736049,marcbelmont,8220ac607bb1dc8df6b523d421b24731e3ccc010,f260ffb739b2ace865400d5bdf6bea4d74a7772e,"@@ -1,252 +1,3 @@
-# Webhooks Receiver
+## Webhook Integrations
 
-Plate Recognizer lets you forward the inference results to a third party. Here are examples for how to use our [webhook API](http://docs.platerecognizer.com/#webhooks).
-
-- [Webhooks Receiver](#webhooks-receiver)
-  - [Sample Code](#sample-code)
-    - [Python Without Dependencies](#python-without-dependencies)
-    - [Python and Flask](#python-and-flask)
-    - [Javascript / Node](#javascript--node)
-    - [C# / .Net Framework v4.8:](#c--net-framework-v48)
-  - [Sending Data to the Webhook Receiver](#sending-data-to-the-webhook-receiver)
-  - [Home Assistant](#home-assistant)
-  - [Stream and OpenEye](#stream-and-openeye)
-    - [Start the Webhook Server](#start-the-webhook-server)
-    - [Start Stream](#start-stream)
-  - [Receive and Forward Webhook data to a SOAP service](#receive-and-forward-webhook-data-to-a-soap-service)
-    - [Required Parameters](#required-parameters)
-    - [Command Execution Format](#command-execution-format)
-    - [Stream Webhook Configuration](#stream-webhook-configuration)
-    - [Snapshot Webhook Configuration](#snapshot-webhook-configuration)
-  - [Forward Stream Webhook Events to Synology API](#forward-stream-webhook-events-to-synology-api)
-  - [Extract license plate image from webhook and forward to another endpoint](#extract-license-plate-image-from-webhook-and-forward-to-another-endpoint)
-  - [Webhook via AWS Lambda](#webhook-via-aws-lambda)
-
-## Sample Code
-
-After starting the receiver, configure Snapshot or Stream webhooks in Plate Recognizer with the URL http://<your-machine-ip>:8001/.
-
-### Python Without Dependencies
-
-```shell
-python3 webhook_reader.py
-```
-
-### Python and Flask
-
-```shell
-pip install Flask==1.1.2
-python3 webhook_reader_flask.py
-```
-
-### Javascript / Node
-
-```shell
-npm install
-node webhook_reader.js
-```
-
-### C# / .Net Framework v4.8:
-
-Install [this NuGet package](https://github.com/Http-Multipart-Data-Parser/Http-Multipart-Data-Parser) required for MultiPart Parsing
-
-```shell
-Install-Package HttpMultipartParser
-```
-
-Build Solution and Run WebhookReader.exe as a Console Application
-
-## Sending Data to the Webhook Receiver
-
-1. Find your machine local IP for example 192.168.0.206. You can use `ifconfig` to get it.
-2. Send an example webhook to the server. If it is running correctly, it should exit without an error.
-3. Optionally, you can send an authentication token with `-e TOKEN=XXX` or a camera with `-e CAMERA=XXX` to identify the webhook source.
-
-```shell
-docker run -e URL=http://MY_IP_ADDRESS:8001 platerecognizer/webhook-tester
-```
-
-3. Configure the webhook on Platerecognizer.
-   - In Stream, edit your `config.ini`, add the following to a camera: `webhook_target = http://MY_IP_ADDRESS:8001/`
-   - For Snapshot, open [Webhooks Configuration](https://app.platerecognizer.com/service/snapshot-cloud/webhooks/).
-
-## Home Assistant
-
-[This project](https://github.com/adamjernst/plate-handler) uses Stream webhooks to send license plate data to a home automation server. Form there, it will send a notification.
-
-## Stream and OpenEye
-
-Use Stream webhooks to send license plate data to a OpenEye. Follow the procedure below to start the webhook.
-
-### Start the Webhook Server
-
-Install dependencies
-```bash
-pip install Flask
-pip install requests
-```
-
-Start the server
-```bash
-python3 webhook_alerts_OpenEye.py --port=5000 --host==0.0.0.0 --aki_token=abcdefg --aks_token=abcdefghijklmnopqrstuvxz
-```
-
-Optional parameters:
-- --port
-- --debug
-
-Required parameters:
-- --aki_token
-- --aks_token
-
-For external access:
-- --host=0.0.0.0
-
-### Start Stream
-
-- Set the [Camera-ID](https://guides.platerecognizer.com/docs/stream/configuration#hierarchical-configuration), present in the config.ini configuration file, equal to the Camera External_ID parameter provided by OpenEye.
-- Set the parameter webhook_targets in config.ini to the host and port of your webhook.
-
-```ini
-# List of TZ names on https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
-timezone = UTC
-
-[cameras]
-  # Full list of regions: http://docs.platerecognizer.com/#countries
-  regions = gb
-  image_format = $(camera)_screenshots/%y-%m-%d/%H-%M-%S.%f.jpg
-
-  webhook_targets = http://192.168.5.10:5000
-
-  [[ExternalCameraId-OpenEye01]]
-    active = yes
-    url = rtsp://192.168.0.110:8080/video/h264
-  [[ExternalCameraId-OpenEye...N]]
-    active = yes
-    url = rtsp://192.168.0.120:8080/video/h264
-```
-
-The example above shows the config.ini set up with the previously running webhook and two cameras with their respective RTSP links and their External camera ID. This same configuration can be used for N_Cameras.
-
-After modifying the config.ini, restart the Stream container.
-
-## Receive and Forward Webhook data to a SOAP service
-
-[This middleware example](https://github.com/parkpow/deep-license-plate-recognition/blob/master/webhooks/webhook_soap/middleware_webhook_soap.py) forwards the data coming from Stream or Snapshot SDK to a SOAP service that waits for `date`, `plate`, `score`, `image` fields and `user`/`password` for service authentication.
-
-### Required Parameters
-
-- `--soap-service-url`
-- `--user` (service authentication user name)
-- `--service-key` (service authentication user key)
-
-### Command Execution Format
-
-```
-python3 /path/to/script/middleware_webhook_soap.py \
---soap-service-url https://<SOAP_SERVICE_URL>?WSDL \
---user <SOAP_SERVICE_ACCESS_USER_NAME> \
---service-key <SOAP_SERVICE_KEY>
-```
-
-[Note that the webhook receiver listens on port 8002.](https://github.com/parkpow/deep-license-plate-recognition/blob/b2eca9ea39ab73ea6d49328bbde4f44a59c1e2e8/webhooks/webhook_soap/middleware_webhook_soap.py#L135C30-L135C34)
-
-### Stream Webhook Configuration
-
-- Set the parameter `webhook_targets` in `config.ini` to the host and port of your webhook.
-
-```
-# List of TZ names on https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
-timezone = UTC
-[cameras]
-  #...
-  # your global cameras configuration
-  #...
-  [[camera-1]]
-    active = yes
-    url = rtsp://192.168.0.108:8080/video/h264
-    webhook_targets = webhook-to-SOAP
-    #...
-    # your camera configuration
-    #...
-
-  # Webhook targets and their parameters
-    [webhooks]
-    caching = yes
-    [[webhook-to-SOAP]]
-      url = http://192.168.0.180:8002
-      image = yes
-      image_type = vehicle, plate
-      request_timeout = 30
-  ```
-
-### Snapshot Webhook Configuration
-
-Follow the instructions [here](https://guides.platerecognizer.com/docs/snapshot/api-reference#webhooks) to configure the webhook middleware URL as the target in Plate Recognizer [webhooks settings](https://app.platerecognizer.com/service/snapshot-cloud/webhooks/) (e.g.: `http://192.168.0.180:8002`).
-
-## Forward Stream Webhook Events to Synology API
-
-[This example](Synology/) is based on a Dockerized middleware webhook forwarder to Synology Surveillance Station API. Make sure to clone the entire folder.
-
-### Setup
-1. Build the image
-``` bash
-docker build -t=""platerecognizer/stream-svs-notifier"" .
-```
-
-2. Run Image on Port 8002
-``` bash
-docker run --rm -t \
-    -p 8002:8002 \
-    -e REST_SERVICE_URL=[SVS_webhook_URL]?token=[API_TOKEN] \
-    platerecognizer/stream-svs-notifier
-
-
-# Example
-docker run --rm -t \
-    -p 8002:8002 \
-    -e REST_SERVICE_URL=http://220.123.123.123:31000/webapi/SurveillanceStation/Webhook/Incoming/v1?token=aaa \
-    platerecognizer/stream-svs-notifier
-```
-
-3. Configure Stream Webhook Targets
-``` bash
-  webhook_targets = http://[stream-svs-notifier IP]:8002
-```
-> [Restart Stream after config changes](https://guides.platerecognizer.com/docs/stream/configuration). `stream-svs-notifier IP` is the IP address of the server or computer running stream-svs-notifier.
-
-## Extract license plate image from webhook and forward to another endpoint
-
-[This webhook middleware example](webhooks/webhook_crop_plate_and_forward) receives a webhook request from [Snapshot SDK](https://guides.platerecognizer.com/docs/snapshot/api-reference#example-of-post-payload) and [Stream](https://guides.platerecognizer.com/docs/stream/results#receiving-webhook-data), uses the original or vehicle image incoming in the request, and crops the plate based on `box` object that contains the bounding box coordinates in such incoming images.
-
-Note that Stream has a built-in solution to send license plate image, it must be configured, see: https://guides.platerecognizer.com/docs/stream/configuration#image_type
-
-### Using Snapshot? Register this middleware url as a Webhook receiver in PaterRecognizer platform
-
-Follow the steps shown [here](https://guides.platerecognizer.com/docs/snapshot/api-reference#webhooks) to register this middleware URL.
-
-### Install Requirements
-
-Install libraries `Pillow` and `requests` executing `pip install <library_name>` in your console.
-If you are using virtual environment, make sure to have it activated.
-
-### Running the middleware:
-
-Format:
-
-`python3 webhook_crop_image_middleware.py --webhook-url https://your-webhook-url.com/endpoint`
-
-Example:
-
-`python3 webhook_crop_image_middleware.py --webhook-url https://your-webhook-url.com/endpoint](https://webhook.site/f510622a-07e9-4d9f-bc0c-4a57c4196039`
-
-## Stream to Nx Witness, Wisenet Wave or DW Spectrum
-
-[This project](Webhook_nx/README.md) uses Stream webhooks to send license plate data to your NX-based VMS.
-You can also use the `mail.py` file as a foundation for integrating other information into the VMS Bookmark, such as GPS data.
-
-## Webhook via AWS Lambda
-[This guide](webhook_lambda/) aims to provide you with a minimum sample to receive webhook data from Snapshot/Stream on your AWS Lambda instance.
-
-## Webhook Salient CompleteView
-[This project](webhook_salient/README.md) uses Stream webhooks to send license plate data to your CompleteView VMS.
+[This article](https://guides.platerecognizer.com/docs/stream/integrations#custom-integrations) will  help you to get started with the custom webhook integrations.",webhooks/README.md,2024-11-06 10:16:13+00:00,2024-11-06T10:16:13Z,update this link,,,,,3,RIGHT,254,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/220,parkpow/deep-license-plate-recognition,3bb1f59ee42f6e3418caf9fb261b0ff24414a9f3
https://api.github.com/repos/xun082/create-neat/pulls/59,https://api.github.com/repos/xun082/create-neat/pulls/comments/1528641886,uaenaTzx,ce23fa78dfaf11626f80f5749501257e98004738,9f01ac5c577a52b7eac9c3b13f36532b1ed04cff,"@@ -15,7 +15,8 @@
     ""directory"": ""packages/core""
   },
   ""bin"": {
-    ""create-neat"": ""./dist/index.js""
+    ""create-neat"": ""./dist/index.js"",
+    ""c"": ""./dist/index.js""",packages/core/package.json,2024-03-18 14:09:56+00:00,2024-03-18T14:10:22Z,what,,,,,19,RIGHT,6,,line,https://api.github.com/repos/xun082/create-neat/pulls/59,xun082/create-neat,f805998e76fda454324dcbbc4daed50fbf7352f7
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/227,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1933605254,marcbelmont,137777db7209447e06bb0774098773f391d4455b,4af432552320e6035668870d66cbcccc7d94f0a5,"@@ -0,0 +1,17 @@
+# Stream Slight Update
+1. Install requirements
+```shell
+pip install -r requirements.txt
+```
+2. On machine 1 that is online, run a script to extract the models and code from the Docker image.
+```shell
+python main.py extract -i platerecognizer/alpr-stream:1.53.0 -o /tmp/extracted_content
+```
+You will now have `app.tar`, `dist-packages.tar` and `site-packages.tar` in `/tmp/extracted_content`
+3. Copy `/tmp/extracted_content` to machine 2 that is offline.
+4. On machine 2, run a script to restore the content and create a new Docker image.
+```shell
+python main.py restore -i platerecognizer/alpr-stream:1.52.0 -o /tmp/extracted_content -t latest3",stream/slight-update/README.md,2025-01-29 10:14:54+00:00,2025-01-29T10:14:54Z,what's the total zip size in this example?,,,,,14,RIGHT,14,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/227,parkpow/deep-license-plate-recognition,b0ae987b6165ba3f82d32313a8165eb516e35c64
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/227,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1942545997,dibonjohnseron,0f4cc914a1a010ac4215157b05980d4cda094290,4af432552320e6035668870d66cbcccc7d94f0a5,"@@ -0,0 +1,181 @@
+import argparse
+import hashlib
+import tarfile
+import tempfile
+from pathlib import Path
+
+from docker.client import DockerClient
+
+client = DockerClient.from_env()
+
+paths_to_copy = [
+    Path(""/app""),
+    Path(""/usr/local/lib/python3.8/site-packages/""),
+    Path(""/usr/local/lib/python3.8/dist-packages/""),
+]
+
+
+def get_python_version(image):
+    config = client.api.inspect_image(image)[""Config""]
+    for env in config[""Env""]:
+        name, value = env.split(""="", maxsplit=1)
+        if name == ""PYTHON_VERSION"":
+            return value
+
+
+def archive_image_updates(image, output) -> str | None:
+    container = None
+    try:
+        container = client.containers.run(
+            image, command=""/bin/bash"", tty=True, detach=True, remove=True
+        )
+
+        for path in paths_to_copy:
+            zip_file = f""{output}/{path.name}.tar""
+            with open(zip_file, ""wb"") as fp:
+                bits, stat = container.get_archive(path)
+                print(stat)
+                for chunk in bits:
+                    fp.write(chunk)
+            print(f""Successfully created {zip_file}"")
+        return get_python_version(image)
+    except Exception as e:
+        print(f""An error occurred: {e}"")
+        raise
+    finally:
+        if container is not None:
+            container.stop()
+
+
+def hash_file(filepath):
+    """"""Calculate the SHA256 hash of a file.""""""
+    hasher = hashlib.sha256()
+    with open(filepath, ""rb"") as f:
+        while chunk := f.read(8192):
+            hasher.update(chunk)
+    return hasher.hexdigest()
+
+
+def extract_tar(tar_path: Path, extract_to: Path):
+    """"""Extract tar file to a specified directory.""""""
+    with tarfile.open(tar_path, ""r"") as tar:
+        tar.extractall(extract_to)
+
+
+def create_diff_tar(source_tar, destination_tar, output_tar):
+    """"""Create a tar file containing only new or updated files from source_tar compared to destination_tar.""""""
+    with tempfile.TemporaryDirectory() as tmpdirname:
+        temp_dir = Path(tmpdirname)
+        source_dir = temp_dir / ""source""
+        source_dir.mkdir(exist_ok=True)
+        destination_dir = temp_dir / ""destination""
+        destination_dir.mkdir(exist_ok=True)
+
+        extract_tar(source_tar, source_dir)
+        extract_tar(destination_tar, destination_dir)
+
+        diff_files = []
+
+        for root, _, files in source_dir.walk(on_error=print):
+            for file in files:
+                source_file_path = root / file
+                relative_path = source_file_path.relative_to(source_dir)
+                destination_file_path = destination_dir / relative_path
+
+                if not destination_file_path.exists() or hash_file(
+                    source_file_path
+                ) != hash_file(destination_file_path):
+                    diff_files.append(relative_path)
+
+        with tarfile.open(output_tar, ""w"") as tar:
+            for file in diff_files:
+                full_path = source_dir / file
+                tar.add(full_path, arcname=file)
+
+
+def extract_updates(args):
+    source_image_fs = args.output / ""source""
+    dest_image_fs = args.output / ""dest""
+    source_image_fs.mkdir(exist_ok=True)",stream/slight-update/main.py,2025-02-05 09:44:02+00:00,2025-02-05T09:44:02Z,".mkdir(parents=True, exist_ok=True)
Incase args.output does not exist yet it also creates it as well. Same goes for all others in the script. ",,,,,99,RIGHT,99,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/227,parkpow/deep-license-plate-recognition,b0ae987b6165ba3f82d32313a8165eb516e35c64
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/227,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1944053141,marcbelmont,6497dc03ca7d304ef0eb7a10ca1ae87f38ecf9de,4af432552320e6035668870d66cbcccc7d94f0a5,"@@ -0,0 +1,37 @@
+# Stream Slight Update",stream/slight-update/README.md,2025-02-06 03:42:59+00:00,2025-02-06T03:47:23Z,Can you rename the title Stream Light Update? Same thing for the directory name.,,,,,1,RIGHT,1,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/227,parkpow/deep-license-plate-recognition,b0ae987b6165ba3f82d32313a8165eb516e35c64
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/227,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1944055213,marcbelmont,6497dc03ca7d304ef0eb7a10ca1ae87f38ecf9de,4af432552320e6035668870d66cbcccc7d94f0a5,"@@ -0,0 +1,37 @@
+# Stream Slight Update
+1. Install requirements
+```shell
+pip install -r requirements.txt
+```
+2. On machine 1 that is online, run script to **extract** the models and code from the Docker image.
+```shell
+python main.py extract -s platerecognizer/alpr-stream:1.53.0 -d platerecognizer/alpr-stream:1.52.0 -o /tmp/extracted_content
+```
+
+You will now have the following folder structure in `/tmp/extracted_content`
+```shell
+/tmp/extracted_content",stream/slight-update/README.md,2025-02-06 03:47:02+00:00,2025-02-06T03:47:23Z,"By default, let's save only the diff as `./update_1.52.0_to_1.53.0`. Other directories aren't needed by the end user. That's more explicit.",,,,,13,RIGHT,13,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/227,parkpow/deep-license-plate-recognition,b0ae987b6165ba3f82d32313a8165eb516e35c64
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/219,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1808594788,Pefington,810055517fbd417e34f2e6f832f3812d2c4640b4,fe87f558ac7c2b5f7c41842556dd674406165e74,"@@ -0,0 +1,107 @@
+import { fetchWithRetry } from ""./utils"";
+import ErrorStackParser from ""error-stack-parser"";
+
+const rollbarUrl = `https://api.rollbar.com/api/1/item/`;
+
+const Frame = ({ fileName, lineNumber, columnNumber, functionName, args }) => {
+	const data = {};
+	data.filename = fileName;
+	data.lineno = lineNumber;
+	data.colno = columnNumber;
+	data.method = functionName;
+	data.args = args;
+	return data;
+};
+
+var Rollbar = class {",snapshot-middleware/src/rollbar.js,2024-10-21 11:20:08+00:00,2024-10-21T13:53:58Z,"
```suggestion
class Rollbar {
```",,,,,16,RIGHT,16,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/219,parkpow/deep-license-plate-recognition,7645a7ff134a797c1d8f5a6fa166a00bcf62b8fe
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/219,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1808856253,Pefington,941a042b9b77a4ccc2552ed13d147c354efbd643,fe87f558ac7c2b5f7c41842556dd674406165e74,"@@ -0,0 +1,28 @@
+import {
+	env,
+	createExecutionContext,
+	waitOnExecutionContext,
+	SELF,
+} from ""cloudflare:test"";
+import { describe, it, expect } from ""vitest"";
+import worker from ""../src"";
+
+describe(""Hello World worker"", () => {",snapshot-middleware/test/index.spec.js,2024-10-21 13:44:45+00:00,2024-10-21T13:53:58Z,"This fails:
Expected: """"Hello World!""""
Received: """"Error - Required POST""""",,,,10.0,10,RIGHT,10,10.0,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/219,parkpow/deep-license-plate-recognition,7645a7ff134a797c1d8f5a6fa166a00bcf62b8fe
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/219,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1808863270,Pefington,941a042b9b77a4ccc2552ed13d147c354efbd643,fe87f558ac7c2b5f7c41842556dd674406165e74,"@@ -0,0 +1,61 @@
+# Snapshot Middleware
+Format external requests into expected format by Snapshot then forward
+
+Supported Source:
+- Survision Camera
+- Genetec Camera
+
+## Deployment steps
+> The cloudflare account needs to have a paid plan for workers to be able to create queues
+
+1. Create a [Cloudflare queue](https://developers.cloudflare.com/queues/get-started/#3-create-a-queue) that will hold messages.
+Can be done by using below command or manually in the dashboard
+```shell
+npx wrangler queues create snapshot-middleware
+```
+
+2. Deploy the worker by running below command
+> this will prompt you to login using your web browser the first time.
+
+A url will be generated to be used as the webhook target on source such as a camera settings page
+```shell
+npm run deploy
+# Deploy with a custom name
+npm run deploy -- --name reimaginedparking-middleware
+```
+To login again `wrangler login`, Logout using `wrangler logout` or delete `.wrangler` folder
+
+3. Update the application env variables with the following values
+> This will redeploy the worker and persist any future deployments
+> For added security, Click on the Encrypt button on each variable
+
+```shell
+# Snapshot Cloud Token - Find it here https://app.platerecognizer.com/service/snapshot-cloud/
+SNAPSHOT_TOKEN=
+# Snapshot API URL - Optional (You don't need to define it if you use Snapshot Cloud
+SNAPSHOT_URL=
+```
+
+5. To log errors with Rollbar, Deploy the tail worker
+```shell
+npm run deploy:rollbar
+```
+The set this env variable
+```shell
+# Rollbar Token for Error logging
+ROLLBAR_TOKEN=
+```
+
+6. Run below command to get realtime logs
+```shell
+npm run logs
+```
+
+## Local development
+- Create a `.dev.vars` with the env variables required",snapshot-middleware/README.md,2024-10-21 13:48:21+00:00,2024-10-21T13:53:58Z,Which ones?,,,,,55,RIGHT,55,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/219,parkpow/deep-license-plate-recognition,7645a7ff134a797c1d8f5a6fa166a00bcf62b8fe
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/219,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1808867833,Pefington,941a042b9b77a4ccc2552ed13d147c354efbd643,fe87f558ac7c2b5f7c41842556dd674406165e74,"@@ -0,0 +1,2848 @@
+{
+  ""name"": ""snapshot-middleware"",
+  ""version"": ""0.0.1"",
+  ""lockfileVersion"": 3,
+  ""requires"": true,
+  ""packages"": {
+    """": {
+      ""name"": ""snapshot-middleware"",
+      ""version"": ""0.0.1"",
+      ""dependencies"": {
+        ""error-stack-parser"": ""^2.1.4""
+      },
+      ""devDependencies"": {
+        ""@cloudflare/vitest-pool-workers"": ""^0.5.2"",
+        ""vitest"": ""2.0.5"",
+        ""wrangler"": ""^3.81.0""
+      }
+    },
+    ""node_modules/@ampproject/remapping"": {
+      ""version"": ""2.3.0"",
+      ""resolved"": ""https://registry.npmjs.org/@ampproject/remapping/-/remapping-2.3.0.tgz"",
+      ""integrity"": ""sha512-30iZtAPgz+LTIYoeivqYo853f02jBYSd5uGnGpkFV0M3xOt9aN73erkgYAmZU43x4VfqcnLxW9Kpg3R5LC4YYw=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""@jridgewell/gen-mapping"": ""^0.3.5"",
+        ""@jridgewell/trace-mapping"": ""^0.3.24""
+      },
+      ""engines"": {
+        ""node"": "">=6.0.0""
+      }
+    },
+    ""node_modules/@ampproject/remapping/node_modules/@jridgewell/trace-mapping"": {
+      ""version"": ""0.3.25"",
+      ""resolved"": ""https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.25.tgz"",
+      ""integrity"": ""sha512-vNk6aEwybGtawWmy/PzwnGDOjCkLWSD2wqvjGGAgOAwCGWySYXfYoxt00IJkTF+8Lb57DwOb3Aa0o9CApepiYQ=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""@jridgewell/resolve-uri"": ""^3.1.0"",
+        ""@jridgewell/sourcemap-codec"": ""^1.4.14""
+      }
+    },
+    ""node_modules/@cloudflare/kv-asset-handler"": {
+      ""version"": ""0.3.4"",
+      ""resolved"": ""https://registry.npmjs.org/@cloudflare/kv-asset-handler/-/kv-asset-handler-0.3.4.tgz"",
+      ""integrity"": ""sha512-YLPHc8yASwjNkmcDMQMY35yiWjoKAKnhUbPRszBRS0YgH+IXtsMp61j+yTcnCE3oO2DgP0U3iejLC8FTtKDC8Q=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""mime"": ""^3.0.0""
+      },
+      ""engines"": {
+        ""node"": "">=16.13""
+      }
+    },
+    ""node_modules/@cloudflare/vitest-pool-workers"": {
+      ""version"": ""0.5.20"",
+      ""resolved"": ""https://registry.npmjs.org/@cloudflare/vitest-pool-workers/-/vitest-pool-workers-0.5.20.tgz"",
+      ""integrity"": ""sha512-azNr2+lQaoGoUul678tEIX/Ptj38M+AlUqKac1gMAsVGozexr6F5/CuIoz1I355hXumlEE/nqKl9VlhiqArJtQ=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""birpc"": ""0.2.14"",
+        ""cjs-module-lexer"": ""^1.2.3"",
+        ""devalue"": ""^4.3.0"",
+        ""esbuild"": ""0.17.19"",
+        ""miniflare"": ""3.20241011.0"",
+        ""semver"": ""^7.5.1"",
+        ""wrangler"": ""3.81.0"",
+        ""zod"": ""^3.22.3""
+      },
+      ""peerDependencies"": {
+        ""@vitest/runner"": ""2.0.x - 2.1.x"",
+        ""@vitest/snapshot"": ""2.0.x - 2.1.x"",
+        ""vitest"": ""2.0.x - 2.1.x""
+      }
+    },
+    ""node_modules/@cloudflare/workerd-darwin-64"": {
+      ""version"": ""1.20241011.1"",
+      ""resolved"": ""https://registry.npmjs.org/@cloudflare/workerd-darwin-64/-/workerd-darwin-64-1.20241011.1.tgz"",
+      ""integrity"": ""sha512-gZ2PrMCQ4WdDCB+V6vsB2U2SyYcmgaGMEa3GGjcUfC79L/8so3Vp/bO0eCoLmvttRs39wascZ+JiWL0HpcZUgA=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""darwin""
+      ],
+      ""engines"": {
+        ""node"": "">=16""
+      }
+    },
+    ""node_modules/@cloudflare/workerd-darwin-arm64"": {
+      ""version"": ""1.20241011.1"",
+      ""resolved"": ""https://registry.npmjs.org/@cloudflare/workerd-darwin-arm64/-/workerd-darwin-arm64-1.20241011.1.tgz"",
+      ""integrity"": ""sha512-c26TYtS0e3WZ09nL/a8YaEqveCsTlgDm12ehPMNua9u68sh1KzETMl2G45O934m8UrI3Rhpv2TTecO0S5b9exA=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""darwin""
+      ],
+      ""engines"": {
+        ""node"": "">=16""
+      }
+    },
+    ""node_modules/@cloudflare/workerd-linux-64"": {
+      ""version"": ""1.20241011.1"",
+      ""resolved"": ""https://registry.npmjs.org/@cloudflare/workerd-linux-64/-/workerd-linux-64-1.20241011.1.tgz"",
+      ""integrity"": ""sha512-pl4xvHNXnm3cYh5GwHadOTQRWt4Ih/gzCOb6RW4n78oNQQydFvpwqYAjbYk32y485feLhdTKXut/MgZAyWnKyQ=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ],
+      ""engines"": {
+        ""node"": "">=16""
+      }
+    },
+    ""node_modules/@cloudflare/workerd-linux-arm64"": {
+      ""version"": ""1.20241011.1"",
+      ""resolved"": ""https://registry.npmjs.org/@cloudflare/workerd-linux-arm64/-/workerd-linux-arm64-1.20241011.1.tgz"",
+      ""integrity"": ""sha512-I4HAF2Qe8xgIjAdE53viT2fDdHXkrb3Be0L3eWeeP5SEkOtQ4cHLqsOV7yhUWOJpHiI1XCDcf+wdfn0PB/EngQ=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ],
+      ""engines"": {
+        ""node"": "">=16""
+      }
+    },
+    ""node_modules/@cloudflare/workerd-windows-64"": {
+      ""version"": ""1.20241011.1"",
+      ""resolved"": ""https://registry.npmjs.org/@cloudflare/workerd-windows-64/-/workerd-windows-64-1.20241011.1.tgz"",
+      ""integrity"": ""sha512-oVr1Cb7NkDpukd7v68FdxOH8vaHRSzHkX9uE/IttHd2yPK6mwOS220nIxK9UMcx5CwZmrgphRwtZwSYVk/lREQ=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""win32""
+      ],
+      ""engines"": {
+        ""node"": "">=16""
+      }
+    },
+    ""node_modules/@cloudflare/workers-shared"": {
+      ""version"": ""0.6.0"",
+      ""resolved"": ""https://registry.npmjs.org/@cloudflare/workers-shared/-/workers-shared-0.6.0.tgz"",
+      ""integrity"": ""sha512-rfUCvb3hx4AsvdUZsxgk9lmgEnQehqV3jdtXLP/Xr0+P56n11T/0nXNMzmn7Nnv+IJFOV6X9NmFhuMz4sBPw7w=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""mime"": ""^3.0.0"",
+        ""zod"": ""^3.22.3""
+      },
+      ""engines"": {
+        ""node"": "">=16.7.0""
+      }
+    },
+    ""node_modules/@cspotcode/source-map-support"": {
+      ""version"": ""0.8.1"",
+      ""resolved"": ""https://registry.npmjs.org/@cspotcode/source-map-support/-/source-map-support-0.8.1.tgz"",
+      ""integrity"": ""sha512-IchNf6dN4tHoMFIn/7OE8LWZ19Y6q/67Bmf6vnGREv8RSbBVb9LPJxEcnwrcwX6ixSvaiGoomAUvu4YSxXrVgw=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""@jridgewell/trace-mapping"": ""0.3.9""
+      },
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild-plugins/node-globals-polyfill"": {
+      ""version"": ""0.2.3"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild-plugins/node-globals-polyfill/-/node-globals-polyfill-0.2.3.tgz"",
+      ""integrity"": ""sha512-r3MIryXDeXDOZh7ih1l/yE9ZLORCd5e8vWg02azWRGj5SPTuoh69A2AIyn0Z31V/kHBfZ4HgWJ+OK3GTTwLmnw=="",
+      ""dev"": true,
+      ""peerDependencies"": {
+        ""esbuild"": ""*""
+      }
+    },
+    ""node_modules/@esbuild-plugins/node-modules-polyfill"": {
+      ""version"": ""0.2.2"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild-plugins/node-modules-polyfill/-/node-modules-polyfill-0.2.2.tgz"",
+      ""integrity"": ""sha512-LXV7QsWJxRuMYvKbiznh+U1ilIop3g2TeKRzUxOG5X3YITc8JyyTa90BmLwqqv0YnX4v32CSlG+vsziZp9dMvA=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""escape-string-regexp"": ""^4.0.0"",
+        ""rollup-plugin-node-polyfills"": ""^0.2.1""
+      },
+      ""peerDependencies"": {
+        ""esbuild"": ""*""
+      }
+    },
+    ""node_modules/@esbuild/aix-ppc64"": {
+      ""version"": ""0.21.5"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/aix-ppc64/-/aix-ppc64-0.21.5.tgz"",
+      ""integrity"": ""sha512-1SDgH6ZSPTlggy1yI6+Dbkiz8xzpHJEVAlF/AM1tHPLsf5STom9rwtjE4hKAF20FfXXNTFqEYXyJNWh1GiZedQ=="",
+      ""cpu"": [
+        ""ppc64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""aix""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/android-arm"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/android-arm/-/android-arm-0.17.19.tgz"",
+      ""integrity"": ""sha512-rIKddzqhmav7MSmoFCmDIb6e2W57geRsM94gV2l38fzhXMwq7hZoClug9USI2pFRGL06f4IOPHHpFNOkWieR8A=="",
+      ""cpu"": [
+        ""arm""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""android""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/android-arm64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/android-arm64/-/android-arm64-0.17.19.tgz"",
+      ""integrity"": ""sha512-KBMWvEZooR7+kzY0BtbTQn0OAYY7CsiydT63pVEaPtVYF0hXbUaOyZog37DKxK7NF3XacBJOpYT4adIJh+avxA=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""android""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/android-x64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/android-x64/-/android-x64-0.17.19.tgz"",
+      ""integrity"": ""sha512-uUTTc4xGNDT7YSArp/zbtmbhO0uEEK9/ETW29Wk1thYUJBz3IVnvgEiEwEa9IeLyvnpKrWK64Utw2bgUmDveww=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""android""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/darwin-arm64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/darwin-arm64/-/darwin-arm64-0.17.19.tgz"",
+      ""integrity"": ""sha512-80wEoCfF/hFKM6WE1FyBHc9SfUblloAWx6FJkFWTWiCoht9Mc0ARGEM47e67W9rI09YoUxJL68WHfDRYEAvOhg=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""darwin""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/darwin-x64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/darwin-x64/-/darwin-x64-0.17.19.tgz"",
+      ""integrity"": ""sha512-IJM4JJsLhRYr9xdtLytPLSH9k/oxR3boaUIYiHkAawtwNOXKE8KoU8tMvryogdcT8AU+Bflmh81Xn6Q0vTZbQw=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""darwin""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/freebsd-arm64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/freebsd-arm64/-/freebsd-arm64-0.17.19.tgz"",
+      ""integrity"": ""sha512-pBwbc7DufluUeGdjSU5Si+P3SoMF5DQ/F/UmTSb8HXO80ZEAJmrykPyzo1IfNbAoaqw48YRpv8shwd1NoI0jcQ=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""freebsd""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/freebsd-x64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/freebsd-x64/-/freebsd-x64-0.17.19.tgz"",
+      ""integrity"": ""sha512-4lu+n8Wk0XlajEhbEffdy2xy53dpR06SlzvhGByyg36qJw6Kpfk7cp45DR/62aPH9mtJRmIyrXAS5UWBrJT6TQ=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""freebsd""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/linux-arm"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/linux-arm/-/linux-arm-0.17.19.tgz"",
+      ""integrity"": ""sha512-cdmT3KxjlOQ/gZ2cjfrQOtmhG4HJs6hhvm3mWSRDPtZ/lP5oe8FWceS10JaSJC13GBd4eH/haHnqf7hhGNLerA=="",
+      ""cpu"": [
+        ""arm""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/linux-arm64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/linux-arm64/-/linux-arm64-0.17.19.tgz"",
+      ""integrity"": ""sha512-ct1Tg3WGwd3P+oZYqic+YZF4snNl2bsnMKRkb3ozHmnM0dGWuxcPTTntAF6bOP0Sp4x0PjSF+4uHQ1xvxfRKqg=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/linux-ia32"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/linux-ia32/-/linux-ia32-0.17.19.tgz"",
+      ""integrity"": ""sha512-w4IRhSy1VbsNxHRQpeGCHEmibqdTUx61Vc38APcsRbuVgK0OPEnQ0YD39Brymn96mOx48Y2laBQGqgZ0j9w6SQ=="",
+      ""cpu"": [
+        ""ia32""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/linux-loong64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/linux-loong64/-/linux-loong64-0.17.19.tgz"",
+      ""integrity"": ""sha512-2iAngUbBPMq439a+z//gE+9WBldoMp1s5GWsUSgqHLzLJ9WoZLZhpwWuym0u0u/4XmZ3gpHmzV84PonE+9IIdQ=="",
+      ""cpu"": [
+        ""loong64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/linux-mips64el"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/linux-mips64el/-/linux-mips64el-0.17.19.tgz"",
+      ""integrity"": ""sha512-LKJltc4LVdMKHsrFe4MGNPp0hqDFA1Wpt3jE1gEyM3nKUvOiO//9PheZZHfYRfYl6AwdTH4aTcXSqBerX0ml4A=="",
+      ""cpu"": [
+        ""mips64el""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/linux-ppc64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/linux-ppc64/-/linux-ppc64-0.17.19.tgz"",
+      ""integrity"": ""sha512-/c/DGybs95WXNS8y3Ti/ytqETiW7EU44MEKuCAcpPto3YjQbyK3IQVKfF6nbghD7EcLUGl0NbiL5Rt5DMhn5tg=="",
+      ""cpu"": [
+        ""ppc64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/linux-riscv64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/linux-riscv64/-/linux-riscv64-0.17.19.tgz"",
+      ""integrity"": ""sha512-FC3nUAWhvFoutlhAkgHf8f5HwFWUL6bYdvLc/TTuxKlvLi3+pPzdZiFKSWz/PF30TB1K19SuCxDTI5KcqASJqA=="",
+      ""cpu"": [
+        ""riscv64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/linux-s390x"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/linux-s390x/-/linux-s390x-0.17.19.tgz"",
+      ""integrity"": ""sha512-IbFsFbxMWLuKEbH+7sTkKzL6NJmG2vRyy6K7JJo55w+8xDk7RElYn6xvXtDW8HCfoKBFK69f3pgBJSUSQPr+4Q=="",
+      ""cpu"": [
+        ""s390x""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/linux-x64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/linux-x64/-/linux-x64-0.17.19.tgz"",
+      ""integrity"": ""sha512-68ngA9lg2H6zkZcyp22tsVt38mlhWde8l3eJLWkyLrp4HwMUr3c1s/M2t7+kHIhvMjglIBrFpncX1SzMckomGw=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/netbsd-x64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/netbsd-x64/-/netbsd-x64-0.17.19.tgz"",
+      ""integrity"": ""sha512-CwFq42rXCR8TYIjIfpXCbRX0rp1jo6cPIUPSaWwzbVI4aOfX96OXY8M6KNmtPcg7QjYeDmN+DD0Wp3LaBOLf4Q=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""netbsd""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/openbsd-x64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/openbsd-x64/-/openbsd-x64-0.17.19.tgz"",
+      ""integrity"": ""sha512-cnq5brJYrSZ2CF6c35eCmviIN3k3RczmHz8eYaVlNasVqsNY+JKohZU5MKmaOI+KkllCdzOKKdPs762VCPC20g=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""openbsd""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/sunos-x64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/sunos-x64/-/sunos-x64-0.17.19.tgz"",
+      ""integrity"": ""sha512-vCRT7yP3zX+bKWFeP/zdS6SqdWB8OIpaRq/mbXQxTGHnIxspRtigpkUcDMlSCOejlHowLqII7K2JKevwyRP2rg=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""sunos""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/win32-arm64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/win32-arm64/-/win32-arm64-0.17.19.tgz"",
+      ""integrity"": ""sha512-yYx+8jwowUstVdorcMdNlzklLYhPxjniHWFKgRqH7IFlUEa0Umu3KuYplf1HUZZ422e3NU9F4LGb+4O0Kdcaag=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""win32""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/win32-ia32"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/win32-ia32/-/win32-ia32-0.17.19.tgz"",
+      ""integrity"": ""sha512-eggDKanJszUtCdlVs0RB+h35wNlb5v4TWEkq4vZcmVt5u/HiDZrTXe2bWFQUez3RgNHwx/x4sk5++4NSSicKkw=="",
+      ""cpu"": [
+        ""ia32""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""win32""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@esbuild/win32-x64"": {
+      ""version"": ""0.17.19"",
+      ""resolved"": ""https://registry.npmjs.org/@esbuild/win32-x64/-/win32-x64-0.17.19.tgz"",
+      ""integrity"": ""sha512-lAhycmKnVOuRYNtRtatQR1LPQf2oYCkRGkSFnseDAKPl8lu5SOsK/e1sXe5a0Pc5kHIHe6P2I/ilntNv2xf3cA=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""win32""
+      ],
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/@fastify/busboy"": {
+      ""version"": ""2.1.1"",
+      ""resolved"": ""https://registry.npmjs.org/@fastify/busboy/-/busboy-2.1.1.tgz"",
+      ""integrity"": ""sha512-vBZP4NlzfOlerQTnba4aqZoMhE/a9HY7HRqoOPaETQcSQuWEIyZMHGfVu6w9wGtGK5fED5qRs2DteVCjOH60sA=="",
+      ""dev"": true,
+      ""engines"": {
+        ""node"": "">=14""
+      }
+    },
+    ""node_modules/@jridgewell/gen-mapping"": {
+      ""version"": ""0.3.5"",
+      ""resolved"": ""https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.5.tgz"",
+      ""integrity"": ""sha512-IzL8ZoEDIBRWEzlCcRhOaCupYyN5gdIK+Q6fbFdPDg6HqX6jpkItn7DFIpW9LQzXG6Df9sA7+OKnq0qlz/GaQg=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""@jridgewell/set-array"": ""^1.2.1"",
+        ""@jridgewell/sourcemap-codec"": ""^1.4.10"",
+        ""@jridgewell/trace-mapping"": ""^0.3.24""
+      },
+      ""engines"": {
+        ""node"": "">=6.0.0""
+      }
+    },
+    ""node_modules/@jridgewell/gen-mapping/node_modules/@jridgewell/trace-mapping"": {
+      ""version"": ""0.3.25"",
+      ""resolved"": ""https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.25.tgz"",
+      ""integrity"": ""sha512-vNk6aEwybGtawWmy/PzwnGDOjCkLWSD2wqvjGGAgOAwCGWySYXfYoxt00IJkTF+8Lb57DwOb3Aa0o9CApepiYQ=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""@jridgewell/resolve-uri"": ""^3.1.0"",
+        ""@jridgewell/sourcemap-codec"": ""^1.4.14""
+      }
+    },
+    ""node_modules/@jridgewell/resolve-uri"": {
+      ""version"": ""3.1.2"",
+      ""resolved"": ""https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz"",
+      ""integrity"": ""sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw=="",
+      ""dev"": true,
+      ""engines"": {
+        ""node"": "">=6.0.0""
+      }
+    },
+    ""node_modules/@jridgewell/set-array"": {
+      ""version"": ""1.2.1"",
+      ""resolved"": ""https://registry.npmjs.org/@jridgewell/set-array/-/set-array-1.2.1.tgz"",
+      ""integrity"": ""sha512-R8gLRTZeyp03ymzP/6Lil/28tGeGEzhx1q2k703KGWRAI1VdvPIXdG70VJc2pAMw3NA6JKL5hhFu1sJX0Mnn/A=="",
+      ""dev"": true,
+      ""engines"": {
+        ""node"": "">=6.0.0""
+      }
+    },
+    ""node_modules/@jridgewell/sourcemap-codec"": {
+      ""version"": ""1.5.0"",
+      ""resolved"": ""https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.0.tgz"",
+      ""integrity"": ""sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ=="",
+      ""dev"": true
+    },
+    ""node_modules/@jridgewell/trace-mapping"": {
+      ""version"": ""0.3.9"",
+      ""resolved"": ""https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.9.tgz"",
+      ""integrity"": ""sha512-3Belt6tdc8bPgAtbcmdtNJlirVoTmEb5e2gC94PnkwEW9jI6CAHUeoG85tjWP5WquqfavoMtMwiG4P926ZKKuQ=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""@jridgewell/resolve-uri"": ""^3.0.3"",
+        ""@jridgewell/sourcemap-codec"": ""^1.4.10""
+      }
+    },
+    ""node_modules/@rollup/rollup-android-arm-eabi"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-android-arm-eabi/-/rollup-android-arm-eabi-4.24.0.tgz"",
+      ""integrity"": ""sha512-Q6HJd7Y6xdB48x8ZNVDOqsbh2uByBhgK8PiQgPhwkIw/HC/YX5Ghq2mQY5sRMZWHb3VsFkWooUVOZHKr7DmDIA=="",
+      ""cpu"": [
+        ""arm""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""android""
+      ]
+    },
+    ""node_modules/@rollup/rollup-android-arm64"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-android-arm64/-/rollup-android-arm64-4.24.0.tgz"",
+      ""integrity"": ""sha512-ijLnS1qFId8xhKjT81uBHuuJp2lU4x2yxa4ctFPtG+MqEE6+C5f/+X/bStmxapgmwLwiL3ih122xv8kVARNAZA=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""android""
+      ]
+    },
+    ""node_modules/@rollup/rollup-darwin-arm64"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-darwin-arm64/-/rollup-darwin-arm64-4.24.0.tgz"",
+      ""integrity"": ""sha512-bIv+X9xeSs1XCk6DVvkO+S/z8/2AMt/2lMqdQbMrmVpgFvXlmde9mLcbQpztXm1tajC3raFDqegsH18HQPMYtA=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""darwin""
+      ]
+    },
+    ""node_modules/@rollup/rollup-darwin-x64"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-darwin-x64/-/rollup-darwin-x64-4.24.0.tgz"",
+      ""integrity"": ""sha512-X6/nOwoFN7RT2svEQWUsW/5C/fYMBe4fnLK9DQk4SX4mgVBiTA9h64kjUYPvGQ0F/9xwJ5U5UfTbl6BEjaQdBQ=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""darwin""
+      ]
+    },
+    ""node_modules/@rollup/rollup-linux-arm-gnueabihf"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-linux-arm-gnueabihf/-/rollup-linux-arm-gnueabihf-4.24.0.tgz"",
+      ""integrity"": ""sha512-0KXvIJQMOImLCVCz9uvvdPgfyWo93aHHp8ui3FrtOP57svqrF/roSSR5pjqL2hcMp0ljeGlU4q9o/rQaAQ3AYA=="",
+      ""cpu"": [
+        ""arm""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ]
+    },
+    ""node_modules/@rollup/rollup-linux-arm-musleabihf"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-linux-arm-musleabihf/-/rollup-linux-arm-musleabihf-4.24.0.tgz"",
+      ""integrity"": ""sha512-it2BW6kKFVh8xk/BnHfakEeoLPv8STIISekpoF+nBgWM4d55CZKc7T4Dx1pEbTnYm/xEKMgy1MNtYuoA8RFIWw=="",
+      ""cpu"": [
+        ""arm""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ]
+    },
+    ""node_modules/@rollup/rollup-linux-arm64-gnu"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-linux-arm64-gnu/-/rollup-linux-arm64-gnu-4.24.0.tgz"",
+      ""integrity"": ""sha512-i0xTLXjqap2eRfulFVlSnM5dEbTVque/3Pi4g2y7cxrs7+a9De42z4XxKLYJ7+OhE3IgxvfQM7vQc43bwTgPwA=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ]
+    },
+    ""node_modules/@rollup/rollup-linux-arm64-musl"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-linux-arm64-musl/-/rollup-linux-arm64-musl-4.24.0.tgz"",
+      ""integrity"": ""sha512-9E6MKUJhDuDh604Qco5yP/3qn3y7SLXYuiC0Rpr89aMScS2UAmK1wHP2b7KAa1nSjWJc/f/Lc0Wl1L47qjiyQw=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ]
+    },
+    ""node_modules/@rollup/rollup-linux-powerpc64le-gnu"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-linux-powerpc64le-gnu/-/rollup-linux-powerpc64le-gnu-4.24.0.tgz"",
+      ""integrity"": ""sha512-2XFFPJ2XMEiF5Zi2EBf4h73oR1V/lycirxZxHZNc93SqDN/IWhYYSYj8I9381ikUFXZrz2v7r2tOVk2NBwxrWw=="",
+      ""cpu"": [
+        ""ppc64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ]
+    },
+    ""node_modules/@rollup/rollup-linux-riscv64-gnu"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-linux-riscv64-gnu/-/rollup-linux-riscv64-gnu-4.24.0.tgz"",
+      ""integrity"": ""sha512-M3Dg4hlwuntUCdzU7KjYqbbd+BLq3JMAOhCKdBE3TcMGMZbKkDdJ5ivNdehOssMCIokNHFOsv7DO4rlEOfyKpg=="",
+      ""cpu"": [
+        ""riscv64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ]
+    },
+    ""node_modules/@rollup/rollup-linux-s390x-gnu"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-linux-s390x-gnu/-/rollup-linux-s390x-gnu-4.24.0.tgz"",
+      ""integrity"": ""sha512-mjBaoo4ocxJppTorZVKWFpy1bfFj9FeCMJqzlMQGjpNPY9JwQi7OuS1axzNIk0nMX6jSgy6ZURDZ2w0QW6D56g=="",
+      ""cpu"": [
+        ""s390x""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ]
+    },
+    ""node_modules/@rollup/rollup-linux-x64-gnu"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-linux-x64-gnu/-/rollup-linux-x64-gnu-4.24.0.tgz"",
+      ""integrity"": ""sha512-ZXFk7M72R0YYFN5q13niV0B7G8/5dcQ9JDp8keJSfr3GoZeXEoMHP/HlvqROA3OMbMdfr19IjCeNAnPUG93b6A=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ]
+    },
+    ""node_modules/@rollup/rollup-linux-x64-musl"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-linux-x64-musl/-/rollup-linux-x64-musl-4.24.0.tgz"",
+      ""integrity"": ""sha512-w1i+L7kAXZNdYl+vFvzSZy8Y1arS7vMgIy8wusXJzRrPyof5LAb02KGr1PD2EkRcl73kHulIID0M501lN+vobQ=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""linux""
+      ]
+    },
+    ""node_modules/@rollup/rollup-win32-arm64-msvc"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-win32-arm64-msvc/-/rollup-win32-arm64-msvc-4.24.0.tgz"",
+      ""integrity"": ""sha512-VXBrnPWgBpVDCVY6XF3LEW0pOU51KbaHhccHw6AS6vBWIC60eqsH19DAeeObl+g8nKAz04QFdl/Cefta0xQtUQ=="",
+      ""cpu"": [
+        ""arm64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""win32""
+      ]
+    },
+    ""node_modules/@rollup/rollup-win32-ia32-msvc"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-win32-ia32-msvc/-/rollup-win32-ia32-msvc-4.24.0.tgz"",
+      ""integrity"": ""sha512-xrNcGDU0OxVcPTH/8n/ShH4UevZxKIO6HJFK0e15XItZP2UcaiLFd5kiX7hJnqCbSztUF8Qot+JWBC/QXRPYWQ=="",
+      ""cpu"": [
+        ""ia32""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""win32""
+      ]
+    },
+    ""node_modules/@rollup/rollup-win32-x64-msvc"": {
+      ""version"": ""4.24.0"",
+      ""resolved"": ""https://registry.npmjs.org/@rollup/rollup-win32-x64-msvc/-/rollup-win32-x64-msvc-4.24.0.tgz"",
+      ""integrity"": ""sha512-fbMkAF7fufku0N2dE5TBXcNlg0pt0cJue4xBRE2Qc5Vqikxr4VCgKj/ht6SMdFcOacVA9rqF70APJ8RN/4vMJw=="",
+      ""cpu"": [
+        ""x64""
+      ],
+      ""dev"": true,
+      ""optional"": true,
+      ""os"": [
+        ""win32""
+      ]
+    },
+    ""node_modules/@types/estree"": {
+      ""version"": ""1.0.6"",
+      ""resolved"": ""https://registry.npmjs.org/@types/estree/-/estree-1.0.6.tgz"",
+      ""integrity"": ""sha512-AYnb1nQyY49te+VRAVgmzfcgjYS91mY5P0TKUDCLEM+gNnA+3T6rWITXRLYCpahpqSQbN5cE+gHpnPyXjHWxcw=="",
+      ""dev"": true
+    },
+    ""node_modules/@types/node"": {
+      ""version"": ""20.12.7"",
+      ""resolved"": ""https://registry.npmjs.org/@types/node/-/node-20.12.7.tgz"",
+      ""integrity"": ""sha512-wq0cICSkRLVaf3UGLMGItu/PtdY7oaXaI/RVU+xliKVOtRna3PRY57ZDfztpDL0n11vfymMUnXv8QwYCO7L1wg=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""undici-types"": ""~5.26.4""
+      }
+    },
+    ""node_modules/@types/node-forge"": {
+      ""version"": ""1.3.11"",
+      ""resolved"": ""https://registry.npmjs.org/@types/node-forge/-/node-forge-1.3.11.tgz"",
+      ""integrity"": ""sha512-FQx220y22OKNTqaByeBGqHWYz4cl94tpcxeFdvBo3wjG6XPBuZ0BNgNZRV5J5TFmmcsJ4IzsLkmGRiQbnYsBEQ=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""@types/node"": ""*""
+      }
+    },
+    ""node_modules/@vitest/expect"": {
+      ""version"": ""2.0.5"",
+      ""resolved"": ""https://registry.npmjs.org/@vitest/expect/-/expect-2.0.5.tgz"",
+      ""integrity"": ""sha512-yHZtwuP7JZivj65Gxoi8upUN2OzHTi3zVfjwdpu2WrvCZPLwsJ2Ey5ILIPccoW23dd/zQBlJ4/dhi7DWNyXCpA=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""@vitest/spy"": ""2.0.5"",
+        ""@vitest/utils"": ""2.0.5"",
+        ""chai"": ""^5.1.1"",
+        ""tinyrainbow"": ""^1.2.0""
+      },
+      ""funding"": {
+        ""url"": ""https://opencollective.com/vitest""
+      }
+    },
+    ""node_modules/@vitest/expect/node_modules/@vitest/pretty-format"": {
+      ""version"": ""2.0.5"",
+      ""resolved"": ""https://registry.npmjs.org/@vitest/pretty-format/-/pretty-format-2.0.5.tgz"",
+      ""integrity"": ""sha512-h8k+1oWHfwTkyTkb9egzwNMfJAEx4veaPSnMeKbVSjp4euqGSbQlm5+6VHwTr7u4FJslVVsUG5nopCaAYdOmSQ=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""tinyrainbow"": ""^1.2.0""
+      },
+      ""funding"": {
+        ""url"": ""https://opencollective.com/vitest""
+      }
+    },
+    ""node_modules/@vitest/expect/node_modules/@vitest/utils"": {
+      ""version"": ""2.0.5"",
+      ""resolved"": ""https://registry.npmjs.org/@vitest/utils/-/utils-2.0.5.tgz"",
+      ""integrity"": ""sha512-d8HKbqIcya+GR67mkZbrzhS5kKhtp8dQLcmRZLGTscGVg7yImT82cIrhtn2L8+VujWcy6KZweApgNmPsTAO/UQ=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""@vitest/pretty-format"": ""2.0.5"",
+        ""estree-walker"": ""^3.0.3"",
+        ""loupe"": ""^3.1.1"",
+        ""tinyrainbow"": ""^1.2.0""
+      },
+      ""funding"": {
+        ""url"": ""https://opencollective.com/vitest""
+      }
+    },
+    ""node_modules/@vitest/expect/node_modules/estree-walker"": {
+      ""version"": ""3.0.3"",
+      ""resolved"": ""https://registry.npmjs.org/estree-walker/-/estree-walker-3.0.3.tgz"",
+      ""integrity"": ""sha512-7RUKfXgSMMkzt6ZuXmqapOurLGPPfgj6l9uRZ7lRGolvk0y2yocc35LdcxKC5PQZdn2DMqioAQ2NoWcrTKmm6g=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""@types/estree"": ""^1.0.0""
+      }
+    },
+    ""node_modules/@vitest/pretty-format"": {
+      ""version"": ""2.1.3"",
+      ""resolved"": ""https://registry.npmjs.org/@vitest/pretty-format/-/pretty-format-2.1.3.tgz"",
+      ""integrity"": ""sha512-XH1XdtoLZCpqV59KRbPrIhFCOO0hErxrQCMcvnQete3Vibb9UeIOX02uFPfVn3Z9ZXsq78etlfyhnkmIZSzIwQ=="",
+      ""dev"": true,
+      ""peer"": true,
+      ""dependencies"": {
+        ""tinyrainbow"": ""^1.2.0""
+      },
+      ""funding"": {
+        ""url"": ""https://opencollective.com/vitest""
+      }
+    },
+    ""node_modules/@vitest/runner"": {
+      ""version"": ""2.1.3"",
+      ""resolved"": ""https://registry.npmjs.org/@vitest/runner/-/runner-2.1.3.tgz"",
+      ""integrity"": ""sha512-JGzpWqmFJ4fq5ZKHtVO3Xuy1iF2rHGV4d/pdzgkYHm1+gOzNZtqjvyiaDGJytRyMU54qkxpNzCx+PErzJ1/JqQ=="",
+      ""dev"": true,
+      ""peer"": true,
+      ""dependencies"": {
+        ""@vitest/utils"": ""2.1.3"",
+        ""pathe"": ""^1.1.2""
+      },
+      ""funding"": {
+        ""url"": ""https://opencollective.com/vitest""
+      }
+    },
+    ""node_modules/@vitest/snapshot"": {
+      ""version"": ""2.1.3"",
+      ""resolved"": ""https://registry.npmjs.org/@vitest/snapshot/-/snapshot-2.1.3.tgz"",
+      ""integrity"": ""sha512-qWC2mWc7VAXmjAkEKxrScWHWFyCQx/cmiZtuGqMi+WwqQJ2iURsVY4ZfAK6dVo6K2smKRU6l3BPwqEBvhnpQGg=="",
+      ""dev"": true,
+      ""peer"": true,
+      ""dependencies"": {
+        ""@vitest/pretty-format"": ""2.1.3"",
+        ""magic-string"": ""^0.30.11"",
+        ""pathe"": ""^1.1.2""
+      },
+      ""funding"": {
+        ""url"": ""https://opencollective.com/vitest""
+      }
+    },
+    ""node_modules/@vitest/snapshot/node_modules/magic-string"": {
+      ""version"": ""0.30.12"",
+      ""resolved"": ""https://registry.npmjs.org/magic-string/-/magic-string-0.30.12.tgz"",
+      ""integrity"": ""sha512-Ea8I3sQMVXr8JhN4z+H/d8zwo+tYDgHE9+5G4Wnrwhs0gaK9fXTKx0Tw5Xwsd/bCPTTZNRAdpyzvoeORe9LYpw=="",
+      ""dev"": true,
+      ""peer"": true,
+      ""dependencies"": {
+        ""@jridgewell/sourcemap-codec"": ""^1.5.0""
+      }
+    },
+    ""node_modules/@vitest/spy"": {
+      ""version"": ""2.0.5"",
+      ""resolved"": ""https://registry.npmjs.org/@vitest/spy/-/spy-2.0.5.tgz"",
+      ""integrity"": ""sha512-c/jdthAhvJdpfVuaexSrnawxZz6pywlTPe84LUB2m/4t3rl2fTo9NFGBG4oWgaD+FTgDDV8hJ/nibT7IfH3JfA=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""tinyspy"": ""^3.0.0""
+      },
+      ""funding"": {
+        ""url"": ""https://opencollective.com/vitest""
+      }
+    },
+    ""node_modules/@vitest/utils"": {
+      ""version"": ""2.1.3"",
+      ""resolved"": ""https://registry.npmjs.org/@vitest/utils/-/utils-2.1.3.tgz"",
+      ""integrity"": ""sha512-xpiVfDSg1RrYT0tX6czgerkpcKFmFOF/gCr30+Mve5V2kewCy4Prn1/NDMSRwaSmT7PRaOF83wu+bEtsY1wrvA=="",
+      ""dev"": true,
+      ""peer"": true,
+      ""dependencies"": {
+        ""@vitest/pretty-format"": ""2.1.3"",
+        ""loupe"": ""^3.1.1"",
+        ""tinyrainbow"": ""^1.2.0""
+      },
+      ""funding"": {
+        ""url"": ""https://opencollective.com/vitest""
+      }
+    },
+    ""node_modules/acorn"": {
+      ""version"": ""8.13.0"",
+      ""resolved"": ""https://registry.npmjs.org/acorn/-/acorn-8.13.0.tgz"",
+      ""integrity"": ""sha512-8zSiw54Oxrdym50NlZ9sUusyO1Z1ZchgRLWRaK6c86XJFClyCgFKetdowBg5bKxyp/u+CDBJG4Mpp0m3HLZl9w=="",
+      ""dev"": true,
+      ""bin"": {
+        ""acorn"": ""bin/acorn""
+      },
+      ""engines"": {
+        ""node"": "">=0.4.0""
+      }
+    },
+    ""node_modules/acorn-walk"": {
+      ""version"": ""8.3.4"",
+      ""resolved"": ""https://registry.npmjs.org/acorn-walk/-/acorn-walk-8.3.4.tgz"",
+      ""integrity"": ""sha512-ueEepnujpqee2o5aIYnvHU6C0A42MNdsIDeqy5BydrkuC5R1ZuUFnm27EeFJGoEHJQgn3uleRvmTXaJgfXbt4g=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""acorn"": ""^8.11.0""
+      },
+      ""engines"": {
+        ""node"": "">=0.4.0""
+      }
+    },
+    ""node_modules/anymatch"": {
+      ""version"": ""3.1.3"",
+      ""resolved"": ""https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz"",
+      ""integrity"": ""sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""normalize-path"": ""^3.0.0"",
+        ""picomatch"": ""^2.0.4""
+      },
+      ""engines"": {
+        ""node"": "">= 8""
+      }
+    },
+    ""node_modules/as-table"": {
+      ""version"": ""1.0.55"",
+      ""resolved"": ""https://registry.npmjs.org/as-table/-/as-table-1.0.55.tgz"",
+      ""integrity"": ""sha512-xvsWESUJn0JN421Xb9MQw6AsMHRCUknCe0Wjlxvjud80mU4E6hQf1A6NzQKcYNmYw62MfzEtXc+badstZP3JpQ=="",
+      ""dev"": true,
+      ""dependencies"": {
+        ""printable-characters"": ""^1.0.42""
+      }
+    },
+    ""node_modules/assertion-error"": {
+      ""version"": ""2.0.1"",
+      ""resolved"": ""https://registry.npmjs.org/assertion-error/-/assertion-error-2.0.1.tgz"",
+      ""integrity"": ""sha512-Izi8RQcffqCeNVgFigKli1ssklIbpHnCYc6AknXGYoB6grJqyeby7jv12JUQgmTAnIDnbck1uxksT4dzN3PWBA=="",
+      ""dev"": true,
+      ""engines"": {
+        ""node"": "">=12""
+      }
+    },
+    ""node_modules/binary-extensions"": {
+      ""version"": ""2.3.0"",
+      ""resolved"": ""https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz"",
+      ""integrity"": ""sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw=="",
+      ""dev"": true,
+      ""engines"": {
+        ""node"": "">=8""
+      },
+      ""funding"": {
+        ""url"": ""https://github.com/sponsors/sindresorhus""
+      }
+    },
+    ""node_modules/birpc"": {
+      ""version"": ""0.2.14"",
+      ""resolved"": ""https://registry.npmjs.org/birpc/-/birpc-0.2.14.tgz"",
+      ""integrity"": ""sha512-37FHE8rqsYM5JEKCnXFyHpBCzvgHEExwVVTq+nUmloInU7l8ezD1TpOhKpS8oe1DTYFqEK27rFZVKG43oTqXRA=="",
+      ""dev"": true,
+      ""funding"": {
+        ""url"": ""https://github.com/sponsors/antfu""
+      }
+    },
+    ""node_modules/blake3-wasm"": {
+      ""version"": ""2.1.5"",
+      ""resolved"": ""https://registry.npmjs.org/blake3-wasm/-/blake3-wasm-2.1.5.tgz"",
+      ""integrity"": ""sha512-F1+K8EbfOZE49dtoPtmxUQrpXaBIl3ICvasLh+nJta0xkz+9kF/7uet9fLnwKqhDrmj6g+6K3Tw9yQPUg2ka5g=="",
+      ""dev"": true
+    },
+    ""node_modules/braces"": {
+      ""version"": ""3.0.2"",",snapshot-middleware/package-lock.json,2024-10-21 13:50:55+00:00,2024-10-21T13:53:58Z,Could you run `npm audit fix` to bump this package version? (security),,,,,1082,RIGHT,1082,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/219,parkpow/deep-license-plate-recognition,7645a7ff134a797c1d8f5a6fa166a00bcf62b8fe
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/219,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1808868798,Pefington,941a042b9b77a4ccc2552ed13d147c354efbd643,fe87f558ac7c2b5f7c41842556dd674406165e74,"@@ -0,0 +1,61 @@
+# Snapshot Middleware
+Format external requests into expected format by Snapshot then forward
+
+Supported Source:
+- Survision Camera
+- Genetec Camera
+
+## Deployment steps
+> The cloudflare account needs to have a paid plan for workers to be able to create queues
+
+1. Create a [Cloudflare queue](https://developers.cloudflare.com/queues/get-started/#3-create-a-queue) that will hold messages.
+Can be done by using below command or manually in the dashboard
+```shell
+npx wrangler queues create snapshot-middleware
+```
+
+2. Deploy the worker by running below command
+> this will prompt you to login using your web browser the first time.
+
+A url will be generated to be used as the webhook target on source such as a camera settings page
+```shell
+npm run deploy
+# Deploy with a custom name
+npm run deploy -- --name reimaginedparking-middleware
+```
+To login again `wrangler login`, Logout using `wrangler logout` or delete `.wrangler` folder
+
+3. Update the application env variables with the following values
+> This will redeploy the worker and persist any future deployments
+> For added security, Click on the Encrypt button on each variable
+
+```shell
+# Snapshot Cloud Token - Find it here https://app.platerecognizer.com/service/snapshot-cloud/
+SNAPSHOT_TOKEN=
+# Snapshot API URL - Optional (You don't need to define it if you use Snapshot Cloud
+SNAPSHOT_URL=
+```
+
+5. To log errors with Rollbar, Deploy the tail worker
+```shell
+npm run deploy:rollbar
+```
+The set this env variable
+```shell
+# Rollbar Token for Error logging
+ROLLBAR_TOKEN=
+```
+
+6. Run below command to get realtime logs
+```shell
+npm run logs
+```
+
+## Local development
+- Create a `.dev.vars` with the env variables required
+- Run `npm run dev` in your terminal to start a development server
+- Open a browser tab at http://localhost:8787/ to see your worker in action
+- Test with curl
+    ```shell
+  	curl -vX POST http://localhost:8787/ -d @Survision.txt --header ""Content-Type: application/json"" --header ""survision-serial-number: sv1-searial-1""",snapshot-middleware/README.md,2024-10-21 13:51:28+00:00,2024-10-21T13:58:49Z,"I can't test, as I don't have Survision.txt, and this triggers a 500
```suggestion
  	curl -v http://localhost:8787/ -d @Survision.txt --header ""Content-Type: application/json"" --header ""survision-serial-number: sv1-searial-1""
```
Is `searial` a typo?",,,,65.0,60,RIGHT,60,65.0,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/219,parkpow/deep-license-plate-recognition,7645a7ff134a797c1d8f5a6fa166a00bcf62b8fe
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/225,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1906709003,marcbelmont,95d04ed7e2449ec3732881a6cff35e91ea579dd5,0521c5e068eb6c95e82455ebbc638e08283794a8,"@@ -0,0 +1,260 @@
+import argparse
+import cgi
+import json
+import logging
+import os
+import sys
+import threading
+import urllib.parse
+from concurrent.futures import ThreadPoolExecutor
+from datetime import datetime, timezone
+from functools import partial
+from http.server import BaseHTTPRequestHandler, HTTPServer
+from queue import Queue
+
+import urllib3
+from api import ParkPowApi, Snapshot
+
+urllib3.disable_warnings()
+
+LOG_LEVEL = os.environ.get(""LOGGING"", ""INFO"").upper()
+
+logging.basicConfig(
+    stream=sys.stdout,
+    level=LOG_LEVEL,
+    style=""{"",
+    format=""{asctime} {levelname} {name} {threadName} : {message}"",
+)
+
+lgr = logging.getLogger(__name__)
+
+
+def confidence_score(value: str):
+    return int(value) / 100
+
+
+class WebhookQueue:
+    def __init__(self, api, max_workers=4):
+        self.queue = Queue()
+        self.api = api
+        self.executor = ThreadPoolExecutor(max_workers=max_workers)
+
+    def enqueue(self, data, params):
+        camera_id = data[""CameraName""]
+        image_base_64 = data[""ContextImage""]
+        # ""10/01/2022"", Format DD/MM/YYYY
+        month, day, year = data[""DateUtc""].split(""/"")
+        lgr.debug([month, day, year])
+        #  ""11:49:22"", Format HH/MM/SS
+        hour, minute, second = data[""TimeUtc""].split("":"")
+        lgr.debug([hour, minute, second])
+        created_date = datetime(",parkpow/genetec/main.py,2025-01-08 08:18:44+00:00,2025-01-08T08:22:56Z,nit: isn't datetime.strptime better for this?,,,,,51,RIGHT,51,,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/225,parkpow/deep-license-plate-recognition,f636f5a1ebc8b3c649f79342a8077ff2cd257386
https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/225,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/comments/1906720994,marcbelmont,95d04ed7e2449ec3732881a6cff35e91ea579dd5,0521c5e068eb6c95e82455ebbc638e08283794a8,"@@ -0,0 +1,260 @@
+import argparse
+import cgi
+import json
+import logging
+import os
+import sys
+import threading
+import urllib.parse
+from concurrent.futures import ThreadPoolExecutor
+from datetime import datetime, timezone
+from functools import partial
+from http.server import BaseHTTPRequestHandler, HTTPServer
+from queue import Queue
+
+import urllib3
+from api import ParkPowApi, Snapshot
+
+urllib3.disable_warnings()
+
+LOG_LEVEL = os.environ.get(""LOGGING"", ""INFO"").upper()
+
+logging.basicConfig(
+    stream=sys.stdout,
+    level=LOG_LEVEL,
+    style=""{"",
+    format=""{asctime} {levelname} {name} {threadName} : {message}"",
+)
+
+lgr = logging.getLogger(__name__)
+
+
+def confidence_score(value: str):
+    return int(value) / 100
+
+
+class WebhookQueue:
+    def __init__(self, api, max_workers=4):
+        self.queue = Queue()
+        self.api = api
+        self.executor = ThreadPoolExecutor(max_workers=max_workers)
+
+    def enqueue(self, data, params):
+        camera_id = data[""CameraName""]
+        image_base_64 = data[""ContextImage""]
+        # ""10/01/2022"", Format DD/MM/YYYY
+        month, day, year = data[""DateUtc""].split(""/"")
+        lgr.debug([month, day, year])
+        #  ""11:49:22"", Format HH/MM/SS
+        hour, minute, second = data[""TimeUtc""].split("":"")
+        lgr.debug([hour, minute, second])
+        created_date = datetime(
+            int(year),
+            int(month),
+            int(day),
+            int(hour),
+            int(minute),
+            int(second),
+            tzinfo=timezone.utc,
+        )
+        # created_date = datetime.now() uncomment for testing
+        if isinstance(self.api, ParkPowApi):
+            v_attrs = data[""Attributes""]
+            plate_confidence = confidence_score(data[""ConfidenceScore""])
+            event_data = {
+                ""camera"": camera_id,
+                ""image"": image_base_64,
+                ""results"": [
+                    {
+                        ""plate"": {
+                            ""score"": plate_confidence,
+                            ""type"": ""Plate"",
+                            ""props"": {
+                                ""plate"": [
+                                    {""value"": data[""Plate""], ""score"": plate_confidence}
+                                ],
+                                ""region"": [
+                                    {
+                                        ""value"": data[""State""],
+                                        ""score"": confidence_score(
+                                            v_attrs[""State Name Confidence Score""]
+                                        ),
+                                    }
+                                ],
+                            },
+                        },
+                        ""vehicle"": {
+                            ""score"": confidence_score(v_attrs[""Confidence Score""]),
+                            # ""type"": ""Sedan"", Todo map ['Vehicle Type'] to PP vehicle types
+                            ""props"": {
+                                ""color"": [
+                                    {
+                                        ""score"": confidence_score(
+                                            v_attrs[""State Name Confidence Score""]
+                                        ),
+                                        ""value"": v_attrs[
+                                            ""Vehicle Color""
+                                        ],  # Todo map ['Vehicle Color'] to PP color types
+                                    }
+                                ],
+                                ""orientation"": [
+                                    {
+                                        ""score"": 1,
+                                        ""value"": ""Rear""
+                                        if v_attrs[""Relative Motion""] == ""Moving Away""
+                                        else ""Front"",
+                                    }
+                                ],
+                                ""make_model"": [
+                                    {
+                                        ""make"": v_attrs[""Vehicle Make""],
+                                        ""score"": 1,
+                                        ""model"": v_attrs[""Vehicle Model""],
+                                    }
+                                ],
+                            },
+                        },
+                    }
+                ],
+                ""time"": created_date.strftime(""%Y-%m-%d %H:%M:%S.%f%z""),
+            }
+
+        elif isinstance(self.api, Snapshot):
+            event_data = {
+                ""upload"": image_base_64,
+                ""timestamp"": created_date.isoformat(),
+            }
+            # include extra params in URL
+            if ""camera_id"" in params:
+                event_data[""camera_id""] = params[""camera_id""][0]
+            else:
+                event_data[""camera_id""] = camera_id
+            if ""mmc"" in params:
+                event_data[""mmc""] = params[""mmc""][0]
+            else:
+                event_data[""mmc""] = ""true""
+            if ""regions"" in params:
+                event_data[""regions""] = params[""regions""][0]
+
+            if ""config"" in params:
+                event_data[""config""] = params[""config""][0]
+
+        else:
+            # should never happen
+            raise NotImplementedError
+
+        lgr.debug(""send to queue"")
+        self.queue.put(event_data)
+
+    def process(self):
+        while True:
+            data = self.queue.get()
+            lgr.debug(f""Processing message: {data}"")
+            if isinstance(self.api, ParkPowApi):
+                self.api.log_vehicle(data)
+            elif isinstance(self.api, Snapshot):
+                self.api.recognition(data)
+            else:
+                # should never happen
+                raise NotImplementedError
+
+
+class Genetec:
+    @staticmethod
+    def validate(data) -> bool:
+        required_keys = (""CameraName"", ""ContextImage"", ""DateUtc"", ""TimeUtc"")
+        return all(k in data for k in required_keys)
+
+
+class RequestHandler(BaseHTTPRequestHandler):",parkpow/genetec/main.py,2025-01-08 08:22:44+00:00,2025-01-08T08:22:56Z,"For future scripts, let's use Flask when we need a web server.",,,,160.0,169,RIGHT,169,160.0,line,https://api.github.com/repos/parkpow/deep-license-plate-recognition/pulls/225,parkpow/deep-license-plate-recognition,f636f5a1ebc8b3c649f79342a8077ff2cd257386
